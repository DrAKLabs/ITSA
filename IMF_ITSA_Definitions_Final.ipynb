{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Users only need to make changes to the drive variable in the functions \"writetofolder\" and \"writetag\". \n",
    "#### Remaining definitions require no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import all libraries needed\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom as dicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.bool = np.bool_ \n",
    "np.float = np.float_\n",
    "import SimpleITK as sitk\n",
    "import sys\n",
    "import skimage\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage import data, io, img_as_ubyte,filters\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_otsu, threshold_multiotsu\n",
    "from scipy.ndimage import binary_dilation\n",
    "import matplotlib as mpl\n",
    "import imutils \n",
    "from typing import Any, Dict\n",
    "from typing import Tuple, List\n",
    "from PIL import ImageEnhance \n",
    "from PIL import Image\n",
    "import math \n",
    "%matplotlib inline\n",
    "mpl.rc('image', interpolation='none')\n",
    "plt.rcParams['figure.figsize'] = (7.0, 7.0)\n",
    "from astropy.table import QTable \n",
    "from tabulate import tabulate\n",
    "from statistics import mean \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import *\n",
    "import pydicom\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getimages(image):\n",
    "    \"\"\"\n",
    "    This function takes simpleITK images and converts to np array that is then normalized  \n",
    "    \"\"\"\n",
    "    Ivol=sitk.GetArrayFromImage(image[:image.GetSize()[0]//2,:,:])#get all slices #left, right, top, top-bottom \n",
    "    Ivol8=np.zeros([Ivol.shape[0], Ivol.shape[1], Ivol.shape[2]], dtype='uint8') \n",
    "    for i in range(Ivol.shape[0]):\n",
    "        Ivol8[i]=cv2.normalize(src=Ivol[i], dst=None, alpha=0.0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    j=Ivol8[0].shape\n",
    "    plotx=5\n",
    "    return Ivol8,j,plotx\n",
    "            \n",
    "def stackimages(image, x=0, y=0): \n",
    "    \"\"\"\n",
    "    This function displays all 15 slices at once (5 by 3)\n",
    "    \"\"\"\n",
    "    plotx = 5\n",
    "    fig, axs = plt.subplots ((j//plotx), plotx, figsize=(20,10)) \n",
    "    for i in range(j):\n",
    "        axs[y, x].imshow(image[i], cmap='bone')\n",
    "        axs[y, x].set_title(f\"slice {i+1}\", fontsize=12) \n",
    "        axs[y,x].axis(\"off\")\n",
    "        if x <(plotx-1):\n",
    "            x+=1\n",
    "        else:\n",
    "            x=0\n",
    "            y+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackimages_w_filename(image, x=0, y=0):\n",
    "    \"\"\"\n",
    "    This function displays all 15 slices at once with the corresponding filename (5 by 3)\n",
    "    \"\"\"\n",
    "    plotx = 5\n",
    "    fig, axs = plt.subplots ((j//plotx), plotx, figsize=(20,10)) \n",
    "    for i in range(j):\n",
    "        axs[y, x].imshow(image[i], cmap='bone')\n",
    "        axs[y, x].set_title(f\"{files}: slice {i+1}\", fontsize=12)\n",
    "        axs[y,x].axis(\"off\")\n",
    "        if x <(plotx-1):\n",
    "            x+=1\n",
    "        else:\n",
    "            x=0\n",
    "            y+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Inhomogeneity Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions for image correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get_numpy_DICOM_volume\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_numpy_DICOM_volume\u001b[39m(image_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray:\n\u001b[0;32m      3\u001b[0m     file_names \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(image_path)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Load DICOM images and extract z-coordinates\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# get_numpy_DICOM_volume\n",
    "def get_numpy_DICOM_volume(image_path: str) -> np.array:\n",
    "    file_names = os.listdir(image_path)\n",
    "\n",
    "    # Load DICOM images and extract z-coordinates\n",
    "    slices = []\n",
    "    for file_name in file_names:\n",
    "        ds = pydicom.dcmread(os.path.join(image_path, file_name))\n",
    "        slices.append((ds.ImagePositionPatient[2], ds.pixel_array))\n",
    "\n",
    "    # Sort slices by z-coordinate\n",
    "    slices.sort()\n",
    "\n",
    "    # Stack 2D pixel arrays into 3D numpy array\n",
    "    volume = np.stack([slice[1] for slice in slices], axis=-1)\n",
    "    return volume\n",
    "\n",
    "# show_diff\n",
    "def show_diff(orig_read_data: Any, alt_read_data: Any, show_image: bool = True, show_hist: bool = False) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    This function shows the differences between 2 images in terms of removed pixels (painted black), added pixels (black pixels painted some grey scale)\n",
    "    and shifted pixels (greyscale pixels whos value changes)    \n",
    "    \"\"\"\n",
    "    if type(orig_read_data) is str:\n",
    "        ds_orig = pydicom.dcmread(orig_read_data).pixel_array\n",
    "    else:\n",
    "        ds_orig = orig_read_data\n",
    "    if type(alt_read_data) is str:\n",
    "        ds_alt = pydicom.dcmread(alt_read_data).pixel_array\n",
    "    else:\n",
    "        ds_alt = alt_read_data\n",
    "    \n",
    "    orig_img = Image.fromarray(ds_orig)\n",
    "    alt_img = Image.fromarray(ds_alt)\n",
    "    alt_img = alt_img.convert(\"L\")\n",
    "    orig_img = orig_img.convert(\"L\")\n",
    "\n",
    "    orig_numpydata = np.asarray(orig_img)\n",
    "    alt_numpydata = np.asarray(alt_img)\n",
    "    diff_array = np.zeros(\n",
    "        (orig_numpydata.shape[0], orig_numpydata.shape[1], 3))\n",
    "    color_counts = {\"Red\": 0, \"Green\": 0, \"Yellow\": 0}\n",
    "\n",
    "    for i in range(orig_numpydata.shape[0]):\n",
    "        for j in range(orig_numpydata.shape[1]):\n",
    "            if orig_numpydata[i, j] == alt_numpydata[i, j]:  \n",
    "                diff_array[i, j] = [0, 0, 0]\n",
    "            # non-black pixel was painted black (removed)\n",
    "            elif (orig_numpydata[i, j]) != 0 and (alt_numpydata[i, j]) == 0:\n",
    "                diff_array[i, j] = [255, 0, 0]\n",
    "                color_counts[\"Red\"] += 1\n",
    "            # pixel color was changed (altered)\n",
    "            elif (orig_numpydata[i, j]) != 0 and (alt_numpydata[i, j]) != 0:\n",
    "                diff_array[i, j] = [255, 255, 0]\n",
    "                color_counts[\"Yellow\"] += 1\n",
    "            # black pixel was painted a differnt color (added)\n",
    "            elif (orig_numpydata[i, j]) == 0 and (alt_numpydata[i, j]) != 0:\n",
    "                diff_array[i, j] = [0, 255, 0]\n",
    "                color_counts[\"Green\"] += 1\n",
    "    txt = \"Red: pixel value became 0 (black),\\n Green: pixel 0 (black) changed to some greyscale value > 0,\\n Yellow: one non-0 (non-black) greyscale value changed to another non-0 (non-black) greyscale value\"\n",
    "    if show_image:\n",
    "        overlay = np.ma.masked_where(diff_array == 0, diff_array)\n",
    "        plt.figtext(0.5, 0.01, txt, wrap=True,\n",
    "                    horizontalalignment='center', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(orig_img, cmap=\"bone\", vmin=0, vmax=2200)\n",
    "        plt.imshow(overlay, vmin=1, vmax=10, alpha=0.5)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    if show_hist:\n",
    "        colors = list(color_counts.keys())\n",
    "        values = list(color_counts.values())\n",
    "        # creating the bar plot\n",
    "        plt.bar(colors, values, color=colors,\n",
    "                width=0.4)\n",
    "\n",
    "        plt.xlabel(txt, wrap=True, fontsize=8)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    return color_counts\n",
    "\n",
    "\n",
    "def DICOM_volume_to_numpy(folder_path: str) -> Tuple[np.array, List[str]]:\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError\n",
    "    slices = []\n",
    "    file_names = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        full_path = os.path.join(folder_path, file)\n",
    "        if os.path.isdir(full_path) or file.lower().endswith((\".nrrd\", \".ds_store\")): # skip nested folders or nrrd files\n",
    "            continue\n",
    "        else:\n",
    "            ds = pydicom.dcmread(full_path)\n",
    "            slices.append((ds.ImagePositionPatient[2], ds.pixel_array))\n",
    "            file_names.append(file)\n",
    "\n",
    "    # Stack 2D pixel arrays into 3D numpy array\n",
    "    volume = np.stack([slice[1] for slice in slices], axis=-1)\n",
    "    return (volume, file_names)\n",
    "                    \n",
    "# inhomogeneity_correction - using only N4bias correction - not used \n",
    "\n",
    "def inhomogeneity_correction(read_data: Any, filename: str, save_path: str = None, mask_array = None, show_images: bool = False) -> Tuple[np.array, str]:\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions corrects image inhomogeneity by means of using N4 bias field correction, this function is slow and not reccomended as \n",
    "    the brightness correction function does a much better and faster job.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "        \n",
    "    image = sitk.GetImageFromArray(read_data)\n",
    "    image = sitk.Cast(image, sitk.sitkFloat32)\n",
    "    if mask_array is None:\n",
    "        maskImage = sitk.OtsuThreshold(image, 0, 1, 200)\n",
    "    else:\n",
    "        mask_image = sitk.GetImageFromArray(mask_image)\n",
    "\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected_image = corrector.Execute(image, maskImage)\n",
    "    corrected_image = sitk.GetArrayFromImage(corrected_image)\n",
    "\n",
    "    log_bias_field = corrector.GetLogBiasFieldAsImage(image)\n",
    "\n",
    "    corrected_image_full_resolution = image / sitk.Exp(log_bias_field)\n",
    "    corrected_image = sitk.GetArrayFromImage(corrected_image_full_resolution)\n",
    "    corrected_image = cv2.normalize(src=corrected_image, dst=None, alpha=0.0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_16U)\n",
    "    \n",
    "    if show_images:\n",
    "        plt.imshow(corrected_image, cmap='bone')\n",
    "        plt.show()\n",
    "\n",
    "    return (corrected_image, f\"i_c-{filename}\")\n",
    "\n",
    "\n",
    "def sharpen1(read_data: Any, filename: str = None, save_path: str = None, mode: str = \"e_e\", show_images: bool = False) -> Tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    Function that applies 3 different kernels that sharpen an image\n",
    "    show_images defaults to False, setting to True will display the result.\n",
    "\n",
    "    Supports modes: \"s\", \"e_s\", \"e_e\"\n",
    "    These modes corrsepond to sharpening, exessive sharpening, edge enhancement respectivley. \"e_e\" is applied by default\n",
    "    \"\"\"\n",
    "    # Retrieved from https://subscription.packtpub.com/book/application-development/9781785283932/2/ch02lvl1sec22/sharpening\n",
    "\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "    if mode == \"s\":\n",
    "        # generating the kernels\n",
    "        kernel_sharpen_1 = np.array([[-1, -1, -1],\n",
    "                                    [-1, 9, -1],\n",
    "                                    [-1, -1, -1]])\n",
    "        output = cv2.filter2D(read_data, -1, kernel_sharpen_1)\n",
    "    elif mode == \"e_s\":\n",
    "        kernel_sharpen_2 = np.array([[1, 1, 1],\n",
    "                                    [1, -7, 1],\n",
    "                                    [1, 1, 1]])\n",
    "        output = cv2.filter2D(read_data, -1, kernel_sharpen_2)\n",
    "    elif mode == \"e_e\":\n",
    "        kernel_sharpen_3 = np.array([[-1, -1, -1, -1, -1],\n",
    "                                    [-1, 2, 2, 2, -1],\n",
    "                                    [-1, 2, 100, 2, -1],\n",
    "                                    [-1, 2, 2, 2, -1],\n",
    "                                    [-1, -1, -1, -1, -1]]) / 2\n",
    "        output = cv2.filter2D(read_data, -1, kernel_sharpen_3)\n",
    "  \n",
    "    if show_images:\n",
    "        plt.imshow(output, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (output, f\"{mode}-{filename}\")\n",
    "\n",
    "# blur\n",
    "\n",
    "def blur(read_data: Any, mode: str = \"b_b\", strength: int = 5, filename: str = None, save_path: str = None, show_images: bool = False) -> Tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This functions blurs the image with customizable strength.\n",
    "    The modes supported are \"b_b\" and \"m_b\", corresponding to bilateral bluring and median bluring. \n",
    "\n",
    "    Bilaterl bluring keeps edges intact, typically only affecting the interior of the image, whereas median bluring affects the entire image.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "    \n",
    "    read_data = cv2.normalize(\n",
    "        read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    if mode == \"m_b\":\n",
    "        blur = cv2.medianBlur(read_data, strength)\n",
    "    elif mode == \"b_b\":\n",
    "        blur = cv2.bilateralFilter(read_data, d=strength * 5, sigmaColor=10,sigmaSpace=75)\n",
    "  \n",
    "    if show_images:\n",
    "        plt.imshow(blur, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (blur, f\"{mode}-{filename}\")\n",
    "\n",
    "# thresholding\n",
    "\n",
    "\n",
    "def thresholding(read_data: Any, strength: int = 55, filename: str = None, save_path: str = None, show_images: bool = False) -> Tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This function applies uniform thresholding based on a strength value, it is set up to support other modes of thresholding, but they \n",
    "    are not currently in use.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "\n",
    "    read_data = cv2.normalize(\n",
    "        read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    _, th1 = cv2.threshold(read_data, strength, 255, cv2.THRESH_BINARY)\n",
    "   \n",
    "    if show_images:\n",
    "        plt.imshow(th1, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (th1, f\"t-{filename}\")\n",
    "\n",
    "# fill_contours\n",
    "\n",
    "\n",
    "def fill_contours(read_data: str, filename: str = None, dilation_iterations: int = 2, crop: bool = False, save_path: str = None, show_images: bool = False) -> Tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This function fills in the interior of the thighs and also supports cropping images who have had their border increased by 10 pixels.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "\n",
    "    img_uint8 = cv2.normalize(\n",
    "        read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    contours, _ = cv2.findContours(\n",
    "        img_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # for unilateral anatomies (e.g. single calf acquisition)\n",
    "    if anatomy == 1:\n",
    "        # take the only contour present if only 1\n",
    "        if len(contours) == 1:\n",
    "            muscles = contours\n",
    "        # take the largest contour present more than 1\n",
    "        elif len(contours) > 1:\n",
    "            largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)\n",
    "            muscles = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "            muscles = [contour for contour in muscles if cv2.contourArea(contour) == max(largest_contours)]\n",
    "\n",
    "    # for bilateral anatomies (e.g. bilateral thigh acquisition)\n",
    "    elif anatomy == 2:\n",
    "        # only grab the two largest contours corresponding to the bilateral muscles (e.g. thighs)\n",
    "        largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "        muscles = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "    \n",
    "        if len(muscles) > 1 and max(largest_contours) - min(largest_contours) > 0.9 * max(largest_contours):\n",
    "            muscles = [contour for contour in muscles if cv2.contourArea(contour) == max(largest_contours)]\n",
    "\n",
    "    background = np.zeros(read_data.shape)\n",
    "    mask = cv2.fillPoly(background, muscles, color=(255, 255, 255))\n",
    "    # Define kernel for dilation\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    # Dilate mask by 1 pixel\n",
    "    dilated_mask = cv2.dilate(mask, kernel, iterations=dilation_iterations)\n",
    "\n",
    "    dilated_mask_uint8 = cv2.normalize(\n",
    "        dilated_mask, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    contours, _ = cv2.findContours(dilated_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    h, w = dilated_mask_uint8.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        surrounding_pixels = dilated_mask_uint8[y - 1:y + h + 1, x - 1:x + w + 1]\n",
    "        if np.all(surrounding_pixels == 255):\n",
    "        # Apply flood fill to fill the black hole\n",
    "            cv2.floodFill(dilated_mask_uint8, mask, (x, y), 255)\n",
    "    \n",
    "    if crop:\n",
    "        dilated_mask_uint8 = dilated_mask_uint8[10:background.shape[0]-10, 10:background.shape[1]-10]\n",
    "\n",
    "    if show_images:\n",
    "        plt.imshow(dilated_mask_uint8, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (dilated_mask_uint8, f\"f_c-{filename}\")\n",
    "    \n",
    "    \n",
    "# denoise\n",
    "\n",
    "\n",
    "def denoise(read_data: Any, filename: str = None, save_path: str = None, show_images: bool = False) -> Tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This function denoises an image by using a variety of morphological transformations as well as increaseing the border size by 10 pixels,\n",
    "    this is needed to accomodate for some of the transformations. Filling the contours at some point after using this function will correct for the added pixels.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "\n",
    "    read_data = cv2.copyMakeBorder(src=read_data, top=10, bottom=10, left=10, right=10, borderType=cv2.BORDER_CONSTANT) \n",
    "\n",
    "    read_data_bin = read_data > 0\n",
    "    output = skimage.morphology.closing(read_data_bin)\n",
    "    output = skimage.morphology.binary_dilation(output, np.ones((5,5)))\n",
    "    output = skimage.morphology.remove_small_objects(\n",
    "        output.astype('bool'), min_size=1000, connectivity=1)\n",
    "    \n",
    "    output = (output * 1).astype('uint8')\n",
    "\n",
    "    output = fill_contours(read_data=output, dilation_iterations=5)\n",
    "    output = read_data > 0\n",
    "    \n",
    "    output = skimage.morphology.binary_opening(output)\n",
    "    kernel_erosion_small = np.array([ [0, 1, 1, 0],\n",
    "                                      [0, 1, 1, 0],\n",
    "                                      [0, 1, 1, 0],\n",
    "                                      [0, 1, 1, 0]])\n",
    "    output = skimage.morphology.binary_erosion(output, kernel_erosion_small)\n",
    "    output = (output * 1).astype('uint8')\n",
    "\n",
    "    output = fill_contours(read_data=output, dilation_iterations=3)\n",
    "    \n",
    "             \n",
    "    output = output[0] > 0\n",
    "    kernel_erosion_large = np.array([   [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1]])\n",
    "    output = skimage.morphology.binary_erosion(output, kernel_erosion_large)\n",
    "    kernel_erosion_small = np.array([ [0, 1, 0],\n",
    "                                      [0, 1, 0]])\n",
    "    output = skimage.morphology.binary_erosion(output, kernel_erosion_small)\n",
    "    output = (output * 1).astype('uint8')\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    output = cv2.erode(output, kernel, iterations=4)\n",
    "    \n",
    "    if show_images:\n",
    "        plt.imshow(output, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (output, f\"d-{filename}\")    \n",
    "\n",
    "# histogram_normalization\n",
    "\n",
    "def brightness_correction(read_data: Any, mode: str = \"CLAHE\", strength: int = 2, ds: pydicom.Dataset = None, filename: str = None, save_path: str = None, show_images: bool = False, gridsize: int = 11) -> Tuple[np.array, str, Any]:\n",
    "    \"\"\"\n",
    "    This function corrects the brightness in an image by either using CLAHE or uniform brightening in order to address dark spots and general inhomogeneity\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "    img_uint8 = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    non_black_white_pixels = None\n",
    "    gray = np.uint8(img_uint8 / np.max(img_uint8) * 255)\n",
    "    if mode == \"CLAHE\":\n",
    "        clahe = cv2.createCLAHE(clipLimit= strength, tileGridSize=(gridsize,gridsize))\n",
    "        result = clahe.apply(gray)\n",
    "    elif mode == \"BI\":\n",
    "        non_black_white_pixels = np.logical_and(gray > 10, gray < 30)\n",
    "        # Increase brightness for non-black pixels\n",
    "        brightened_image = np.clip(np.where(non_black_white_pixels, img_uint8 + strength, img_uint8), 0, 255)\n",
    "        # Clip the values to ensure they remain within the valid range [0, 255]\n",
    "        result = brightened_image\n",
    "    result = cv2.normalize(result, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_16U)\n",
    "    if show_images:\n",
    "        plt.imshow(result, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (result, f\"{mode}-{filename}\", non_black_white_pixels)\n",
    "\n",
    "\n",
    "def get_mask(read_data: Any) -> np.array:\n",
    "    \"\"\"\n",
    "    This function retruns all the pixels in an image that are white\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        img = ds.pixel_array\n",
    "    else:\n",
    "        img = read_data\n",
    "    white_pixels = np.argwhere(img == 255)\n",
    "    return white_pixels\n",
    "\n",
    "\n",
    "def get_cleaned_image(read_data: Any, mask: Any, ds: pydicom.Dataset = None, filename: str = None, save_path: str = None, show_images: bool = False) -> np.array:\n",
    "    \"\"\"\n",
    "    This function gets a cleaned image based on a base/corrected image as well as a mask containing all the pixels which we wish to retain in the new image.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(mask) is str:\n",
    "        ds = pydicom.dcmread(mask)\n",
    "        mask_array = ds.pixel_array\n",
    "    else:\n",
    "        mask_array = mask\n",
    "\n",
    "    binary_array = np.where(mask_array == 255, 1, mask_array)\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_array = ds.pixel_array\n",
    "    else:\n",
    "        read_array = read_data\n",
    "    combined = read_array*binary_array \n",
    "    combined = cv2.normalize(combined, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_16U)\n",
    "    \n",
    "    if show_images:\n",
    "        plt.imshow(combined, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Leg Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackupLegSeparation(image, side): \n",
    "    '''\n",
    "    This function runs backup leg model and resets i so all slices use backup version\n",
    "    '''\n",
    "    pt_image = image\n",
    "    pixel_values = np.sum(pt_image, axis=0) #find which x values have brightest pixels\n",
    "    from skimage.filters import threshold_otsu, threshold_multiotsu\n",
    "    x_threshold = threshold_otsu(pixel_values)\n",
    "    x_coordinates = np.arange(len(pixel_values)) #assign x values\n",
    "\n",
    "    # Save the data as a NumPy array\n",
    "    data_array = np.array([x_coordinates, pixel_values])\n",
    "    np.save('data_array.npy', data_array)\n",
    "    loaded_array = np.load('data_array.npy')\n",
    "\n",
    "    x_coordinates = np.arange(len(loaded_array[1]))\n",
    "\n",
    "    #counting intersections to determine range of interest\n",
    "    def count_intersections(x_data,y_data, horizontal_line_y):\n",
    "        num_intersections = 0\n",
    "\n",
    "        for i in range(len(y_data) - 1):\n",
    "            y1, y2 = y_data[i], y_data[i + 1]\n",
    "            x1, x2 = x_data[i], x_data[i + 1]\n",
    "\n",
    "            # Check if the horizontal line intersects the line segment\n",
    "            if min(y1, y2) <= horizontal_line_y <= max(y1, y2) and y1 != y2:\n",
    "                x_intersection = x1 + (horizontal_line_y - y1) * (x2 - x1) / (y2 - y1)\n",
    "                if x1 <= x_intersection <= x2:\n",
    "                    num_intersections += 1\n",
    "\n",
    "        return num_intersections\n",
    "\n",
    "    intersection_count = np.array([])\n",
    "    for i in range (max(loaded_array[1])-1):\n",
    "        horizontal_line_y = i\n",
    "        # Count intersections\n",
    "        intersections = count_intersections(x_coordinates, loaded_array[1], horizontal_line_y)\n",
    "        intersection_count = np.append(intersection_count, intersections)\n",
    "\n",
    "    #finding the target Y value\n",
    "    value_to_find = 4\n",
    "    indices = np.where(intersection_count == value_to_find)[0]\n",
    "    target_y = np.median(indices)\n",
    "\n",
    "\n",
    "    # Function to find X values where a vertical line intersects the graph at a specific Y value\n",
    "    def find_vertical_line_intersections(x_data, y_data, target_y):\n",
    "        intersections_x = []\n",
    "\n",
    "        for i in range(len(y_data) - 1):\n",
    "            y1, y2 = y_data[i], y_data[i + 1]\n",
    "            x1, x2 = x_data[i], x_data[i + 1]\n",
    "\n",
    "            # Check if the vertical line intersects the line segment\n",
    "            if min(y1, y2) <= target_y <= max(y1, y2) and y1 != y2:\n",
    "                x_intersection = x1 + (target_y - y1) * (x2 - x1) / (y2 - y1)\n",
    "                if x1 <= x_intersection <= x2:\n",
    "                    intersections_x.append(x_intersection)\n",
    "\n",
    "        return intersections_x\n",
    "\n",
    "    # Call the function to find X values\n",
    "    intersections_x = find_vertical_line_intersections(x_coordinates, loaded_array[1], target_y)\n",
    "\n",
    "    #cut image at average between 2 middle intersections x values\n",
    "    mid = round((intersections_x[1] + intersections_x[2])/2) #x-value between legs\n",
    "\n",
    "    desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "    #Slicing image at midpoint\n",
    "    #left side\n",
    "    if side == 'L':\n",
    "        centered_image = pt_image[:, :mid]\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "        if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "            num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "            centered_image_f = np.pad(centered_image, ((0, 0), (0, num_columns_to_add)), mode='constant')\n",
    "        elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, num_columns_to_remove:]\n",
    "        else:\n",
    "            centered_image_f = centered_image\n",
    "    #right side\n",
    "    if side == 'R':\n",
    "        centered_image = pt_image[:, mid:]\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "        if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "            num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "            centered_image_f = np.pad(centered_image, ((0, 0), (num_columns_to_add,0)), mode='constant')\n",
    "        elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, :desired_shape[1]]\n",
    "        else:\n",
    "            centered_image_f = centered_image\n",
    "    def first_last_nonzero_indices(arr):\n",
    "        # Find the first nonzero index\n",
    "        first_nonzero = next((index for index, value in enumerate(arr) if value != 0), None)\n",
    "        # Find the last nonzero index\n",
    "        last_nonzero = next((index for index, value in reversed(list(enumerate(arr))) if value != 0), None)\n",
    "        #print(f'{first_nonzero} and {last_nonzero}')\n",
    "        return first_nonzero, last_nonzero\n",
    "\n",
    "    pixel_values = np.sum(centered_image_f, axis=0) #use new image\n",
    "    first, last = first_last_nonzero_indices(pixel_values)\n",
    "    current_mid = round((first - last)/2)\n",
    "    if side == 'L':\n",
    "        shift = 128 - current_mid\n",
    "    if side == 'R':\n",
    "        shift = -1* (128 - current_mid) \n",
    "    shifted_array = np.roll(centered_image_f, shift, axis=1)\n",
    "    return centered_image_f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LegSepNew (image, side, rmv_count, num_columns_to_remove):\n",
    "    '''\n",
    "    This function separates the thighs by side so each resulting image only contains one thigh\n",
    "    '''\n",
    "    read_data = image\n",
    "    num_columns_to_remove = num_columns_to_remove\n",
    "    rmv_count = rmv_count\n",
    "    read_data = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    erode = cv2.erode(read_data, kernel, iterations=1)\n",
    "    blur = cv2.medianBlur(erode, 3)\n",
    "    blur = cv2.bilateralFilter(blur,9,10,50)                                               #locating 2 large bright regions (legs)\n",
    "    ret, thresh = cv2.threshold(blur, 30, 255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "    thighs = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "    backtorgb = cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(backtorgb, [thighs[0]], -1, (255,0,0), 1)\n",
    "    cv2.drawContours(backtorgb, [thighs[1]], -1, (0,0,255), 1)\n",
    "    min_centroid = ()\n",
    "    max_centroid = ()\n",
    "    if side == 'L':\n",
    "            for contour in thighs:\n",
    "                # Calculate the centroid of the contour\n",
    "                M = cv2.moments(contour)\n",
    "                cX = int(M['m10'] / M['m00'])\n",
    "                cY = int(M['m01'] / M['m00'])\n",
    "                if len(min_centroid) == 0 or cX < min_centroid[0]:     #chooses centroid with smaller x value (i.e. left side)\n",
    "                    min_centroid = (cX, cY, contour)\n",
    "            min_contour = min_centroid[2]\n",
    "            end_x = min_contour[:, :, 0].max() # Find the ending x-coordinate (rightmost point) of the contour\n",
    "            if rmv_count > 0:\n",
    "                centered_image = read_data[:,num_columns_to_remove:end_x]\n",
    "                start_x = min_contour[:, :, 0].min()\n",
    "                \n",
    "                if start_x < num_columns_to_remove:\n",
    "                    print(\"using backup\")\n",
    "                    centered_image = BackupLegSeparation(read_data, \"L\")\n",
    "            else:\n",
    "                centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "            \n",
    "            #reform new shape\n",
    "            desired_shape = (image.shape[0], int(image.shape[1]/2))  # define desired shape (rows, columns)\n",
    "            np.expand_dims(centered_image,axis=2)\n",
    "            if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "                num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "                centered_image_f = np.pad(centered_image, ((0, 0), (0, num_columns_to_add)), mode='constant')\n",
    "            elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "                num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "                centered_image_f = centered_image[:,:desired_shape[1]]\n",
    "                print(\"Too Big\")\n",
    "            else:\n",
    "                centered_image_f = centered_image              \n",
    "                         \n",
    "                \n",
    "    if side == 'R':\n",
    "        max_cX = None\n",
    "        for contour in thighs:\n",
    "            # Calculate the centroid of the contour\n",
    "            M = cv2.moments(contour)\n",
    "            cX = int(M['m10'] / M['m00'])\n",
    "            cY = int(M['m01'] / M['m00'])\n",
    "            if max_cX is None or cX > max_cX:\n",
    "                max_cX = cX  # Update max_cX with the current cX\n",
    "                max_centroid = (cX, cY, contour) #pick right side\n",
    "\n",
    "        max_contour = max_centroid[2]\n",
    "        start_x = max_contour[:, :, 0].min()# Find the ending x-coordinate (leftmost point) of the contour\n",
    "        desired_shape = (image.shape[0], int(image.shape[1]/2))  # define desired shape (rows, columns)\n",
    "        if rmv_count > 0:\n",
    "            cutoff = 512 - num_columns_to_remove\n",
    "            centered_image = read_data[:,start_x:cutoff]\n",
    "            start_x = max_contour[:, :, 0].max()\n",
    "        else:\n",
    "            centered_image = read_data[:, start_x:]\n",
    "        \n",
    "        if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "            num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "            centered_image_f = np.pad(centered_image, ((0, 0), (num_columns_to_add,0)), mode='constant')\n",
    "        elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, num_columns_to_remove:]\n",
    "        else:\n",
    "            centered_image_f = centered_image\n",
    "            \n",
    "    return centered_image_f\n",
    "  \n",
    "def GetShift(image,side):\n",
    "    '''\n",
    "    This function finds how much to shift all slices in patient so the final images contains entire thigh regardless of size and each slice is still in the same position relative to the slices beside it (z-connectivity)\n",
    "    '''\n",
    "    read_data = image\n",
    "    read_data = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    erode = cv2.erode(read_data, kernel, iterations=1)\n",
    "    blur = cv2.medianBlur(erode, 3)\n",
    "    blur = cv2.bilateralFilter(blur,9,10,50)                                               #locating 2 large bright regions (legs)\n",
    "    ret, thresh = cv2.threshold(blur, 30, 255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "    thighs = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "    \n",
    "    backtorgb = cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(backtorgb, [thighs[0]], -1, (255,0,0), 1)\n",
    "    cv2.drawContours(backtorgb, [thighs[1]], -1, (0,0,255), 1)\n",
    "    min_centroid = ()\n",
    "    max_centroid = ()\n",
    "    if side == 'L':\n",
    "            for contour in thighs:\n",
    "                # Calculate the centroid of the contour\n",
    "                M = cv2.moments(contour)\n",
    "                cX = int(M['m10'] / M['m00'])\n",
    "                cY = int(M['m01'] / M['m00'])\n",
    "                if len(min_centroid) == 0 or cX < min_centroid[0]:     #chooses centroid with smaller x value (i.e. left side)\n",
    "                    min_centroid = (cX, cY, contour)\n",
    "            min_contour = min_centroid[2]\n",
    "            end_x = min_contour[:, :, 0].max() # Find the ending x-coordinate ( rightmost point) of the contour\n",
    "            rmv_count = 0 #care to know if we removed columns\n",
    "            \n",
    "            desired_shape = (image.shape[0], int(image.shape[1]/2))  # define desired shape (rows, columns)\n",
    "            centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "            np.expand_dims(centered_image,axis=2)\n",
    "            if desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "                num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "                centered_image_f = centered_image[:,num_columns_to_remove:] #want to remove columns at beginning\n",
    "                rmv_count += 1   \n",
    "            else:\n",
    "                num_columns_to_remove = 0\n",
    "\n",
    "                    \n",
    "    if side == 'R':\n",
    "        max_cX = None\n",
    "        for contour in thighs:\n",
    "            # Calculate the centroid of the contour\n",
    "            M = cv2.moments(contour)\n",
    "            cX = int(M['m10'] / M['m00'])\n",
    "            cY = int(M['m01'] / M['m00'])\n",
    "            if max_cX is None or cX > max_cX:\n",
    "                max_cX = cX  # Update max_cX with the current cX\n",
    "                max_centroid = (cX, cY, contour) #pick right side\n",
    "\n",
    "        max_contour = max_centroid[2]\n",
    "        end_x = max_contour[:, :, 0].min()# Find the ending x-coordinate (leftmost point) of the contour\n",
    "        #print(end_x)\n",
    "        rmv_count = 0 #care to know if we removed columns\n",
    "        desired_shape = (image.shape[0], int(image.shape[1]/2))  # define desired shape (rows, columns)\n",
    "        centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "\n",
    "        centered_image = read_data[:, end_x:]\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "        \n",
    "        if desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, :desired_shape[1]] #want to remove columns at the end\n",
    "            rmv_count += 1\n",
    "        else:\n",
    "            num_columns_to_remove = 0\n",
    "     \n",
    "    return rmv_count, num_columns_to_remove\n",
    "\n",
    "def GetShiftManual(image,side,startend_x):\n",
    "    '''\n",
    "    This function finds how much to shift all slices in patient so the final images contains entire thigh regardless of size and each slice is still in the same position relative to the slices beside it (z-connectivity)\n",
    "    '''\n",
    "    read_data = image\n",
    "    read_data = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    erode = cv2.erode(read_data, kernel, iterations=1)\n",
    "    blur = cv2.medianBlur(erode, 3)\n",
    "    blur = cv2.bilateralFilter(blur,9,10,50)                                               #locating 2 large bright regions (legs)\n",
    "    ret, thresh = cv2.threshold(blur, 30, 255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "    thighs = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "    backtorgb = cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(backtorgb, [thighs[0]], -1, (255,0,0), 1)\n",
    "    cv2.drawContours(backtorgb, [thighs[1]], -1, (0,0,255), 1)\n",
    "    min_centroid = ()\n",
    "    max_centroid = ()\n",
    "    if side == 'L':\n",
    "            for contour in thighs:\n",
    "                # Calculate the centroid of the contour\n",
    "                M = cv2.moments(contour)\n",
    "                cX = int(M['m10'] / M['m00'])\n",
    "                cY = int(M['m01'] / M['m00'])\n",
    "                if len(min_centroid) == 0 or cX < min_centroid[0]:     #chooses centroid with smaller x value (i.e. left side)\n",
    "                    min_centroid = (cX, cY, contour)\n",
    "            min_contour = min_centroid[2]\n",
    "            end_x = startend_x # Find the ending x-coordinate ( rightmost point) of the contour\n",
    "            rmv_count = 0 #care to know if we removed columns\n",
    "            \n",
    "            desired_shape = (image.shape[0], int(image.shape[1]/2))  # define desired shape (rows, columns)\n",
    "            centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "            np.expand_dims(centered_image,axis=2)\n",
    "            if desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "                num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "                centered_image_f = centered_image[:,num_columns_to_remove:] #want to remove columns at beginning\n",
    "                rmv_count += 1   \n",
    "            else:\n",
    "                num_columns_to_remove = 0\n",
    "\n",
    "                    \n",
    "    if side == 'R':\n",
    "        max_cX = None\n",
    "        for contour in thighs:\n",
    "            # Calculate the centroid of the contour\n",
    "            M = cv2.moments(contour)\n",
    "            cX = int(M['m10'] / M['m00'])\n",
    "            cY = int(M['m01'] / M['m00'])\n",
    "            if max_cX is None or cX > max_cX:\n",
    "                max_cX = cX  # Update max_cX with the current cX\n",
    "                max_centroid = (cX, cY, contour) #pick right side\n",
    "\n",
    "        max_contour = max_centroid[2]\n",
    "        end_x = startend_x # Find the ending x-coordinate (leftmost point) of the contour\n",
    "        #print(end_x)\n",
    "        rmv_count = 0 #care to know if we removed columns\n",
    "        desired_shape = (image.shape[0], int(image.shape[1]/2))  # define desired shape (rows, columns)\n",
    "        centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "\n",
    "        centered_image = read_data[:, end_x:]\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "        \n",
    "        if desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, :desired_shape[1]] #want to remove columns at the end\n",
    "            rmv_count += 1\n",
    "        else:\n",
    "            num_columns_to_remove = 0\n",
    "     \n",
    "    return rmv_count, num_columns_to_remove\n",
    "\n",
    "def LegSepNewManual (image, side, startend_x, rmv_count, num_columns_to_remove, ):\n",
    "    read_data = image\n",
    "    num_columns_to_remove = num_columns_to_remove\n",
    "    rmv_count = rmv_count\n",
    "    read_data = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    erode = cv2.erode(read_data, kernel, iterations=1)\n",
    "    blur = cv2.medianBlur(erode, 3)\n",
    "    blur = cv2.bilateralFilter(blur,9,10,50)                                               #locating 2 large bright regions (legs)\n",
    "    ret, thresh = cv2.threshold(blur, 30, 255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "    thighs = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "    backtorgb = cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(backtorgb, [thighs[0]], -1, (255,0,0), 1)\n",
    "    cv2.drawContours(backtorgb, [thighs[1]], -1, (0,0,255), 1)\n",
    "    min_centroid = ()\n",
    "    max_centroid = ()\n",
    "    if side == 'L':\n",
    "            for contour in thighs:\n",
    "                # Calculate the centroid of the contour\n",
    "                M = cv2.moments(contour)\n",
    "                cX = int(M['m10'] / M['m00'])\n",
    "                cY = int(M['m01'] / M['m00'])\n",
    "                if len(min_centroid) == 0 or cX < min_centroid[0]:     #chooses centroid with smaller x value (i.e. left side)\n",
    "                    min_centroid = (cX, cY, contour)\n",
    "            min_contour = min_centroid[2]\n",
    "            end_x = min_contour[:, :, 0].max() # Find the ending x-coordinate (rightmost point) of the contour\n",
    "            #check if columns were removed in sample slice\n",
    "            end_x=startend_x #*** x value that matches a slice from same patient that did not have an error\n",
    "            if rmv_count > 0:\n",
    "                centered_image = read_data[:,num_columns_to_remove:end_x]\n",
    "                start_x = min_contour[:, :, 0].min()\n",
    "                \n",
    "                if start_x < num_columns_to_remove:\n",
    "                    print(\"using backup\")\n",
    "                    centered_image = BackupLegSeparation(read_data, \"L\")\n",
    "            else:\n",
    "                centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "            \n",
    "            #reform new shape\n",
    "            desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "            np.expand_dims(centered_image,axis=2)\n",
    "            if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "                num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "                centered_image_f = np.pad(centered_image, ((0, 0), (0, num_columns_to_add)), mode='constant')\n",
    "            elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "                num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "                centered_image_f = centered_image[:,:desired_shape[1]]\n",
    "                print(\"Too Big\")\n",
    "            else:\n",
    "                centered_image_f = centered_image              \n",
    "                         \n",
    "                \n",
    "    if side == 'R':\n",
    "        max_cX = None\n",
    "        for contour in thighs:\n",
    "            # Calculate the centroid of the contour\n",
    "            M = cv2.moments(contour)\n",
    "            cX = int(M['m10'] / M['m00'])\n",
    "            cY = int(M['m01'] / M['m00'])\n",
    "            if max_cX is None or cX > max_cX:\n",
    "                max_cX = cX  # Update max_cX with the current cX\n",
    "                max_centroid = (cX, cY, contour) #pick right side\n",
    "\n",
    "        max_contour = max_centroid[2]\n",
    "        start_x = max_contour[:, :, 0].min() # Find the ending x-coordinate (leftmost point) of the contour\n",
    "        desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "        start_x=startend_x # ***change to x value that matches a slice from same patient that did not have an error\n",
    "        #check if columns were removed in sample slice\n",
    "        if rmv_count > 0:\n",
    "            cutoff = 512 - num_columns_to_remove\n",
    "            centered_image = read_data[:,start_x:cutoff]\n",
    "            start_x = max_contour[:, :, 0].max()\n",
    "        else:\n",
    "            centered_image = read_data[:, start_x:]\n",
    "        \n",
    "        \n",
    "        if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "            num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "            centered_image_f = np.pad(centered_image, ((0, 0), (num_columns_to_add,0)), mode='constant')\n",
    "        elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, num_columns_to_remove:]\n",
    "        else:\n",
    "            centered_image_f = centered_image\n",
    "            \n",
    "    return centered_image_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Definitions for Muscle Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_musc_ring(image):\n",
    "    '''\n",
    "    This function finds the subcutaneous fat ring which is used to close the gaps for floodfilling when isolating muscle\n",
    "    '''\n",
    "    musc_ring=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        eroded=cv2.erode(image[i],np.ones((5,5),np.uint8),iterations = 1) \n",
    "        musc_ring[i]=image[i]-eroded \n",
    "    return musc_ring\n",
    "    \n",
    "def enlarge_size(image,pixels): \n",
    "    '''\n",
    "    This function adds a certain number of pixels to all sides of the image\n",
    "    '''\n",
    "    image_big =np.zeros([image.shape[0], image.shape[1]+(pixels*2), image.shape[2]+(pixels*2)], dtype='uint8')\n",
    "    \n",
    "    #adding pixels for shape[1] is for top_bottom - acconting for addition top bottom addition increase in size\n",
    "    #adding pixels for shape[2] is for left right - acconting for addition left bottom addition increase in size\n",
    "    \n",
    "    pixels=pixels\n",
    "    for i in range(j):\n",
    "        top_bottom=np.zeros([pixels, image.shape[2]], dtype='uint8')   \n",
    "        top_added=np.vstack((top_bottom,image[i])) \n",
    "        bottom_added=np.vstack((top_added,top_bottom)) \n",
    "        right_left=np.zeros([bottom_added.shape[0], pixels], dtype='uint8')  \n",
    "        right_added=np.hstack((bottom_added,right_left))\n",
    "        left_added=np.hstack((right_left,right_added))\n",
    "        image_big[i]=left_added\n",
    "    return  image_big, pixels #want pixels for reducing size later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_size(image_big): \n",
    "    '''\n",
    "    This function removes a certain number of pixels from all sides of the image\n",
    "    '''\n",
    "    top_removed=np.delete(image_big, np.s_[:pixels], 1)  \n",
    "    bottom_removed=np.delete(top_removed, np.s_[top_removed.shape[1]-pixels:], 1) \n",
    "    left_removed=np.delete(bottom_removed, np.s_[:pixels], 2) \n",
    "    right_removed=np.delete(left_removed, np.s_[left_removed.shape[2]-pixels:], 2)  \n",
    "    image_reg=right_removed.copy()\n",
    "    return image_reg\n",
    "\n",
    "def multi_otsu_1(image):\n",
    "    '''\n",
    "    This function takes the Otsu threshold between the second and third class and returns the fat threshold\n",
    "    '''\n",
    "    motsuth=filters.threshold_multiotsu(image, classes=3)\n",
    "    regions=np.digitize(image,bins=motsuth)\n",
    "    output=img_as_ubyte(regions)\n",
    "    return motsuth[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Get Rough Muscle Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def floodfill(image): \n",
    "    '''\n",
    "    This function flood fills the rough muscle mask\n",
    "    '''\n",
    "    ff_im=np.zeros([image.shape[0], image.shape[1]], dtype='uint8') \n",
    "    to_ff=image.copy()\n",
    "         \n",
    "    h, w = image.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    cv2.floodFill(to_ff, mask, (0,0), 1);\n",
    "    th, ff_im = cv2.threshold(to_ff, 0, 1, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    return ff_im\n",
    "\n",
    "def multi_otsu_0(image):\n",
    "    '''\n",
    "    This function takes the Otsu threshold between the first and second class and returns the fat+muscle threshold\n",
    "    '''\n",
    "    motsuth=filters.threshold_multiotsu(image, classes=3)\n",
    "    regions=np.digitize(image,bins=motsuth)\n",
    "    output=img_as_ubyte(regions)\n",
    "    return motsuth[0] \n",
    "\n",
    "\n",
    "\n",
    "def get_musc_fat_mask(image, minsize):\n",
    "    '''\n",
    "    This function applies a threshold to the image and gets the rough muscle+fat mask\n",
    "    '''\n",
    "    mask =np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    \n",
    "    k=1\n",
    "    \n",
    "    for i in range(j):\n",
    "        th=multi_otsu_0(image[i]) \n",
    "        mask[i]=(image[i]>th) \n",
    "\n",
    "        mask[i] = cv2.morphologyEx(mask[i], cv2.MORPH_OPEN, np.ones((5,5),np.uint8)) #remove connections with other leg\n",
    "\n",
    "        mask[i]=cv2.morphologyEx(mask[i], cv2.MORPH_CLOSE, np.ones((2,2),np.uint8))\n",
    "\n",
    "        mask[i] = (morphology.remove_small_holes(label(mask[i]).astype('bool'),area_threshold=minsize*1125, connectivity=1)) # *** remove holes to get entire mask of muscle + subcfat region. Default = 9000 at 0.98 mm pixel size\n",
    "\n",
    "        mask[i] = cv2.morphologyEx(mask[i], cv2.MORPH_OPEN, np.ones((7,7),np.uint8)) #get rid of line artifact\n",
    "\n",
    "        mask[i] = (morphology.remove_small_objects(label(mask[i]).astype('bool'),min_size=minsize*375, connectivity=1)) # *** get rid of noise smaller than this. Default = 3000 at 0.98 mm\n",
    "\n",
    "        ret, mask[i] = cv2.threshold(mask[i],0,1,cv2.THRESH_BINARY) \n",
    "        \n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_subcfat_ring(image):\n",
    "    '''\n",
    "    This function finds the subcutaneous fat ring which is used to close the gaps for floodfilling when isolating muscle\n",
    "    '''\n",
    "    subcfat_ring=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        eroded=cv2.erode(image[i],np.ones((5,5),np.uint8),iterations = 1) \n",
    "        subcfat_ring[i]=image[i]-eroded \n",
    "    return subcfat_ring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CurvatureFlowImageFilter(image): \n",
    "    '''\n",
    "    This function removes noise to make the fascia boundary more clear\n",
    "    '''\n",
    "    inputImage=sitk.GetImageFromArray(image)\n",
    "    inputImage = sitk.Cast(inputImage, sitk.sitkFloat32)\n",
    "    corrector = sitk.CurvatureFlowImageFilter()\n",
    "    corrector.SetNumberOfIterations( 15 );\n",
    "    corrector.SetTimeStep( 0.1 )\n",
    "    output = corrector.Execute( inputImage)\n",
    "    image_c= sitk.GetArrayFromImage(output)\n",
    "    image_c=cv2.normalize(src=image_c, dst=None, alpha=0.0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) \n",
    "    return image_c\n",
    "\n",
    "def apply_CurvatureFilter(image1,image2):\n",
    "    '''\n",
    "    This function is used to overcome instances where the image is dark\n",
    "    '''\n",
    "    mask=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    image=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        mask[i]=Ivol8c_subcfat[i]>multi_otsu_1(Ivol8c_subcfat[i])  \n",
    "        if np.sum(mask[i]>0)<1000:\n",
    "            print(f\"Slice {i+1} use Ivol8c_coi\")\n",
    "            image[i]=image2[i]\n",
    "        else:\n",
    "            image[i]=image1[i]\n",
    "    \n",
    "    curvature_flow=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        curvature_flow[i]=CurvatureFlowImageFilter(image[i])\n",
    "        \n",
    "    return curvature_flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_sharpness(image): \n",
    "    '''\n",
    "    This function is used to make the fascia boundary line darker\n",
    "    '''\n",
    "    from PIL import ImageEnhance\n",
    "    from PIL import Image\n",
    "\n",
    "    Ivol8c_c_s=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        f=image[i].copy()\n",
    "        f=Image.fromarray(f, mode=None)\n",
    "        enhancer = ImageEnhance.Sharpness(f)\n",
    "        factor =  12.0 \n",
    "        Ivol8c_c_s[i]=enhancer.enhance(factor)\n",
    "    return Ivol8c_c_s\n",
    "\n",
    "def get_subcfatvol(image, minsize):   \n",
    "    '''\n",
    "    This function gives the subcutaneous fat volume\n",
    "    '''\n",
    "    subcfatvol=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        subcfatvol[i]=image[i]>multi_otsu_1(image[i])  \n",
    "\n",
    "        subcfatvol[i] = (morphology.remove_small_holes(subcfatvol[i],area_threshold=minsize*11.25, connectivity=1))  # *** remove small holes in subcutaneous fat smaller than this. Default = 90 at 0.98 mm\n",
    "         \n",
    "    return subcfatvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floodfillall(image):\n",
    "    '''\n",
    "    This function floodfills objects in a 3D image\n",
    "    '''\n",
    "    floodfilled=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "    for i in range(j): \n",
    "        im_floodfill = image[i].copy()\n",
    "        h, w = im_floodfill.shape[:2]\n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "        cv2.floodFill(im_floodfill, mask, (0,0), 1)\n",
    "        th, floodfilled[i] = cv2.threshold(im_floodfill, 0, 1, cv2.THRESH_BINARY_INV)\n",
    "    return floodfilled\n",
    "\n",
    "def darkpieces(image, minsize): \n",
    "    '''\n",
    "    This function is used to find the dark parts of our image including vessels\n",
    "    '''\n",
    "    musc_mask1=floodfillall(image) \n",
    "    musc_mask2=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "\n",
    "\n",
    "    for i in range(j):\n",
    "        musc_mask2[i] = cv2.morphologyEx(musc_mask1[i], cv2.MORPH_OPEN, np.ones((3,3),np.uint8)) \n",
    "        \n",
    "        musc_mask2[i] = (morphology.remove_small_objects(label(musc_mask2[i]).astype('bool'),min_size=minsize*12.5, connectivity=1)) # *** removes small vessels. Default = 100 at 0.98 mm \n",
    "            \n",
    "        musc_mask2[i]= cv2.dilate(musc_mask2[i],np.ones((3,3),np.uint8),iterations = 1)\n",
    "        musc_mask2[i] = (morphology.remove_small_objects((musc_mask2[i]).astype(bool),min_size=minsize*12.5, connectivity=1)) # *** removes small vessels. Default = 100 at 0.98 mm \n",
    "        musc_mask2[i]= cv2.erode(musc_mask2[i],np.ones((3,3),np.uint8),iterations = 1) \n",
    "            \n",
    "        th, musc_mask2[i]= cv2.threshold(np.uint8(musc_mask2[i]), 0, 1, cv2.THRESH_BINARY)\n",
    "        \n",
    "    return musc_mask1, musc_mask2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any muscle overshoots into subcfat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subcfat_overshoot(image1,image2,removal_round,minsize):\n",
    "    '''\n",
    "    This function removes any overshooting that may occur when creating subcutaneous fat mask\n",
    "    '''\n",
    "    a=image1*image2\n",
    "    \n",
    "    \n",
    "    overshoot=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):        \n",
    "        th=multi_otsu_1(a[i])  \n",
    "        overshoot[i]=a[i]>th\n",
    "        \n",
    "        if removal_round==1: #larger obj removal size\n",
    "       \n",
    "            overshoot[i] = (morphology.remove_small_objects(label(overshoot[i]).astype('bool'),min_size=minsize*3.75, connectivity=1)) # *** diff obj size to be removed for round 1 vs round 2. Default = 30 at 0.98 mm pixel size\n",
    "            overshoot[i]=cv2.morphologyEx(overshoot[i], cv2.MORPH_CLOSE, np.ones((5,5),np.uint8)) \n",
    "            th, overshoot[i] = cv2.threshold(overshoot[i], 0, 1, cv2.THRESH_BINARY)\n",
    "        else:\n",
    "            overshoot[i] = (morphology.remove_small_objects(label(overshoot[i]).astype('bool'),min_size=minsize*2.50, connectivity=1)) # *** diff obj size to be removed for round 1 vs round 2. Default = 20 at 0.98 mm pixel size\n",
    "            th, overshoot[i] = cv2.threshold(overshoot[i], 0, 1, cv2.THRESH_BINARY)\n",
    "        \n",
    "\n",
    "    overshoot_removed=image1-overshoot #rough mask subtract the overshoot mask\n",
    "    overshoot_removed[overshoot_removed==255] = 1 \n",
    "  \n",
    "    \n",
    "    for i in range(j): \n",
    "        overshoot_removed[i]= (morphology.remove_small_objects(label(overshoot_removed[i]).astype('bool'),min_size=minsize*3.75, connectivity=1)) # *** remove any bits remaining from subtraction. Default = 30 at 0.98 mm pixel size\n",
    "        th, overshoot_removed[i] = cv2.threshold(overshoot_removed[i].astype(np.uint8), 0, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    return overshoot,overshoot_removed\n",
    "\n",
    "def keep_overlaps(image,overlap_num,minsize):\n",
    "    '''\n",
    "    This function keeps parts of the image that is greater than overlap_num when thresholding\n",
    "    '''\n",
    "    image2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    \n",
    "    for i in range(j):\n",
    "        if i==0:\n",
    "            image2[i]=image[i]+image[i+1]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        elif i==(j-1):\n",
    "            image2[i]=image[i-1]+image[i]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        else:\n",
    "            image2[i]=image[i-1]+image[i]+image[i+1]\n",
    "    \n",
    "    for i in range(j):\n",
    "        ret, image2[i]= cv2.threshold(image2[i],overlap_num,1,cv2.THRESH_BINARY)\n",
    "        image2[i]= (morphology.remove_small_objects(label(image2[i]).astype('bool'),min_size=minsize*5, connectivity=1)) # *** remove small objects. Default = 40 at 0.98 mm pixel size.  \n",
    "        ret, image2[i] = cv2.threshold(image2[i].astype(np.uint8), 0, 1, cv2.THRESH_BINARY)\n",
    "            \n",
    "    return image2\n",
    "    \n",
    "def keep_overlaps_DEPRECATED_BY_AW(image,overlap_num,minsize):\n",
    "    '''\n",
    "    This function keeps parts of the image that is greater than overlap_num when thresholding\n",
    "    '''\n",
    "    image2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    \n",
    "    for i in range(j):\n",
    "        if i==0:\n",
    "            image2[i]=image[i]+image[i+1]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        elif i==(j-1):\n",
    "            image2[i]=image[i-1]+image[i]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        else:\n",
    "            image2[i]=image[i-1]+image[i]+image[i+1]\n",
    "    \n",
    "\n",
    "    ret, image2= cv2.threshold(image2,overlap_num,1,cv2.THRESH_BINARY) \n",
    "    for i in range(j):\n",
    "        image2[i]= (morphology.remove_small_objects(label(image2[i]),min_size=minsize*5, connectivity=1)) # *** remove small objects. Default = 40 at 0.98 mm pixel size.  \n",
    "\n",
    "    if anatomy == 2:\n",
    "        ret, image2= cv2.threshold(image2.astype(np.uint8),0,1,cv2.THRESH_BINARY)\n",
    "        \n",
    "    elif anatomy == 1:\n",
    "        for i in range(j):\n",
    "            ret, image2[i] = cv2.threshold(image2[i].astype(np.uint8), 0, 1, cv2.THRESH_BINARY)\n",
    "            \n",
    "    return image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snakes prep: Get Muscle Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_contours(im): \n",
    "    '''\n",
    "    This function gets the contours of an image/mask\n",
    "    '''\n",
    "    contour_coords_L=[]\n",
    "\n",
    "    mask_contours=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "    zeros=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "    for i in range (j):\n",
    "        a, b =  cv2.findContours(im[i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour_coords_L.append([])\n",
    "        contour_coords_L[i].append(a) \n",
    "\n",
    "        #draw contours from contour_coords_L onto zeros array \n",
    "        mask_contours[i] = cv2.drawContours(zeros[i], contour_coords_L[i][0],  -1, (1,0,0), 1)\n",
    "        \n",
    "    return mask_contours, contour_coords_L\n",
    "\n",
    "\n",
    "def convex_hull(contours):\n",
    "    '''\n",
    "    This function gets rid of concavities in contour, used to follow the fascia as much as possible and initiate the snake\n",
    "    '''\n",
    "    hull_coords=[]\n",
    "    hull_demonstration = np.zeros((Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2], 3), np.uint8)\n",
    "    hull = np.zeros((Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]), np.uint8)\n",
    "    listt=[]\n",
    "    contours_prehull=[]\n",
    "    for i in range(j):\n",
    "        hull_coords.append([])  \n",
    "        listt.append([])\n",
    "        contours_prehull.append([])\n",
    "\n",
    "            \n",
    "        for i2 in range(len(contours[i])):\n",
    "            for i3 in range(len(contours[i][i2])):\n",
    "                for i4 in range(len(contours[i][i2][i3])):\n",
    "                    listt[i].append(contours[i][i2][i3][i4])\n",
    "     \n",
    "        contours_prehull[i]=np.array(listt[i])\n",
    "\n",
    "        hull_coords[i].append(cv2.convexHull(contours_prehull[i], False))\n",
    "    \n",
    "        for i2 in range(len(contours[i])):\n",
    "            color_contours = (0, 255, 0) # green - color for contours\n",
    "            color_hull = (255, 0, 0) # red - color for convex hull\n",
    "            cv2.drawContours(hull_demonstration[i], contours[i][0], i2, color_contours,\n",
    "                             1, 8) \n",
    "            cv2.drawContours(hull_demonstration[i], hull_coords[i], i2, color_hull, 1, 8)\n",
    "\n",
    "        for i2 in range(len(contours)): \n",
    "            color_hull = (255, 0, 0) # blue - color for convex hull\n",
    "            cv2.drawContours(hull[i], hull_coords[i],  -1, (1,0,0), 1)\n",
    "        \n",
    "    return hull, hull_demonstration, hull_coords\n",
    "\n",
    "def show_convexhull():\n",
    "    '''\n",
    "    This function displays the convex_hull\n",
    "    '''\n",
    "    fig, axs = plt.subplots(j, 3, figsize= (18, 120))\n",
    "    for i in range(j):\n",
    "        axs[i, 0].set_title(f\"slice {i+1}\", fontsize=18)\n",
    "        axs[i, 0].imshow(mask_contours[i])\n",
    "        axs[i, 1].imshow(hull_demonstration[i])\n",
    "        axs[i, 2].imshow(hull[i])\n",
    "\n",
    "        \n",
    "def compatible_coordlist(contours):\n",
    "    '''\n",
    "    This function generate the initial coordinates to use for the snake\n",
    "    '''\n",
    "    initiator_coords=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        initiator_coords.append([])\n",
    "        for i2 in range(len(contours[i][0][0])): \n",
    "            initiator_coords[i].append(contours[i][0][0][i2][0])\n",
    "        initiator_coords[i]=np.array(initiator_coords[i])\n",
    "        initiator_coords[i]=initiator_coords[i].astype(float)\n",
    "    return initiator_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_vessels(image, minsize): \n",
    "    '''\n",
    "    This function removes the vessels from the ROI\n",
    "    '''\n",
    "    vessels_present=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    test=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    vessels_removed_mask=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        otsu_th=multi_otsu_1(image[i])\n",
    "        vessels_present[i] = image[i]>otsu_th\n",
    "        \n",
    "        vessels_removed_mask[i] = label(vessels_present[i]) \n",
    "  \n",
    "        vessels_removed_mask[i]=cv2.morphologyEx(vessels_removed_mask[i], cv2.MORPH_CLOSE, np.ones((5,5),np.uint8)) \n",
    "    \n",
    "        vessels_removed_mask[i] = (morphology.remove_small_holes(vessels_removed_mask[i].astype('bool'),area_threshold=minsize*11.25, connectivity=1)).astype(int) # *** remove vessel small holes. Default = 90 at 0.98 mm pixel size \n",
    "        \n",
    "        vessels_removed_mask[i]=cv2.normalize(src=vessels_removed_mask[i], dst=None, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    return vessels_removed_mask, vessels_present\n",
    "        \n",
    "\n",
    "def get_vessels(minsize):\n",
    "    '''\n",
    "    This function checks the area to isolate circles which represent the vessels\n",
    "    '''\n",
    "    contour_coords_L=[]\n",
    "    hiercvol=[]\n",
    "    contour_listvol=[]\n",
    "    boneroi=[]\n",
    "    vessels_mask=[]\n",
    "\n",
    "    r=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        contour_coords_L.append([])\n",
    "        hiercvol.append([])\n",
    "        contour_listvol.append([])\n",
    "        boneroi.append([])\n",
    "        vessels_mask.append([])\n",
    "\n",
    "    for i in range (j):\n",
    "        a, b =  cv2.findContours(pre_vessels_mask[i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour_coords_L[i].append(a)\n",
    "        hiercvol[i].append(b)\n",
    "\n",
    "        for contour in contour_coords_L[i][0]:\n",
    "            approx = cv2.approxPolyDP(contour,0.01*cv2.arcLength(contour,True),True)\n",
    "\n",
    "            if (len(approx) > 3):  \n",
    "                contour_listvol[i].append(contour)\n",
    "\n",
    "        for i2 in range (len(contour_listvol[i])): \n",
    "            (x,y),radius = cv2.minEnclosingCircle(contour_listvol[i][i2]) # finds a circle of the minimum area enclosing a 2d point set\n",
    "            center = (int(x),int(y))\n",
    "            radius = int(radius)\n",
    "            area = cv2.contourArea(contour_listvol[i][i2]) \n",
    "      \n",
    "            #radius<50 to indicate small objects; area check relative to radius to check the circularity\n",
    "            if (radius < minsize*6.25) & (area> (0.1*(3.14*(radius**2))) and area<minsize*12.5): # *** Default = radius < 50 and area < 100 at 0.98 mm pixel size, defines vessel size maximum - appends vessels to boneROI if the radius is less than the specified number (indicating blood vessels) \n",
    "                boneroi[i].append(contour_listvol[i][i2])#append to list if it satisfies the above conditions\n",
    "                \n",
    "        vessels_mask[i] = cv2.drawContours(r[i], boneroi[i],  -1, (1,0,0), 1)\n",
    "    \n",
    "    vessels_mask=floodfillall(vessels_mask)\n",
    "\n",
    "    for i in range(j): \n",
    "        vessels_mask[i]=cv2.dilate(vessels_mask[i],np.ones((3,3),np.uint8),iterations = 1) \n",
    "   \n",
    "    return vessels_mask\n",
    "\n",
    "def get_whites():\n",
    "    '''\n",
    "    This function generates white mask to help guide the snake away from the thigh border and vessels (which are dark)\n",
    "    '''\n",
    "    whites=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        #generate the white outside\n",
    "        whites[i]=musc_fat_mask[i].copy() \n",
    "        whites[i][whites[i]==0] = 255\n",
    "   \n",
    "        whites[i][whites[i]==1] = 0\n",
    "        whites[i][vessels_mask[i]==1]=255\n",
    "    return whites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine THIGH Muscle Mask: Snakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_snakeim():\n",
    "    '''\n",
    "    This function applies a whites mask onto the filtered image to generate the image that the snake will be operating on\n",
    "    '''\n",
    "    snake_im=Ivol8c_c_s.copy()\n",
    "    for i in range(j):\n",
    "        snake_im[i][whites[i]==255] = 255 \n",
    "        snake_im[i][subcfat_ring[i]==1] = 255  \n",
    "    return snake_im\n",
    "\n",
    "def bilat_fil_snake_im(image): \n",
    "    '''\n",
    "    This function applies a bilateral filter to get rid of some noise\n",
    "    '''\n",
    "    bilateral_t=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        bilateral_t[i] = cv2.bilateralFilter(image[i],20,35,35)\n",
    "    return bilateral_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Snakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "\n",
    "def primary_snake():\n",
    "    '''\n",
    "    This function finds the primary snake coordinates using active contour model\n",
    "    '''\n",
    "    snake1_coords=[]\n",
    "    for i in range(j): \n",
    "        snake1_coords.append([])\n",
    "        snake1_coords[i]=active_contour(gaussian(bilateral_t[i], 1,preserve_range=False), initiator_coords[i],alpha=0.01,gamma=20,w_edge=8,w_line=-0.5,max_num_iter=5,max_px_move=1) # *** snake parameters - test for fascia smoother\n",
    "\n",
    "    return snake1_coords \n",
    "\n",
    "def snaketomask(coordinates):  \n",
    "    '''\n",
    "    This function uses the snake coordinates and makes a snake mask\n",
    "    ''' \n",
    "    vol=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        vol.append([])\n",
    "        for i2 in range(len(coordinates[i])):\n",
    "            vol[i].append([])\n",
    "            vol[i][i2].append(coordinates[i][i2])\n",
    "\n",
    "        vol[i]=np.rint(vol[i]).astype(int)\n",
    "    \n",
    "    drawsnake= np.zeros((Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]), np.uint8)\n",
    "    \n",
    "    #polylines function connects the dots to make it one smooth contour\n",
    "    for i in range(j):\n",
    "        cv2.polylines(drawsnake[i], [vol[i]], isClosed=True, color = (1, 0, 0) , thickness=1) \n",
    "    \n",
    "    snake_mask=drawsnake.copy()\n",
    "\n",
    "    \n",
    "    h, w = subcfatvol[i].shape[:2]\n",
    "\n",
    "    for i in range (j):\n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "        (x,y),radius = cv2.minEnclosingCircle(vol[i]) \n",
    "        cv2.floodFill(snake_mask[i], mask, (round(x),round(y)), 255)\n",
    "\n",
    "        ret, snake_mask[i] = cv2.threshold(snake_mask[i],0,1,cv2.THRESH_BINARY)\n",
    "        \n",
    "    return snake_mask\n",
    "    \n",
    "def snaketomask_DEPRECATED_BY_AW(coordinates):  \n",
    "    '''\n",
    "    This function uses the snake coordinates and makes a snake mask\n",
    "    ''' \n",
    "    vol=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        vol.append([])\n",
    "        for i2 in range(len(coordinates[i])):\n",
    "            vol[i].append([])\n",
    "            vol[i][i2].append(coordinates[i][i2])\n",
    "\n",
    "        vol[i]=np.rint(vol[i]).astype(int)\n",
    "\n",
    "    drawsnake= np.zeros((Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]), np.uint8)\n",
    "    \n",
    "    #polylines function connects the dots to make it one smooth contour\n",
    "    for i in range(j):\n",
    "        cv2.polylines(drawsnake[i], [vol[i]], isClosed=True, color = (1, 0, 0) , thickness=1) \n",
    "    \n",
    "    snake_mask=drawsnake.copy()\n",
    "\n",
    "    h, w = subcfatvol[i].shape[:2]\n",
    "\n",
    "    for i in range (j):\n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "        (x,y),radius = cv2.minEnclosingCircle(vol[i]) \n",
    "        cv2.floodFill(snake_mask[i], mask, (round(x),round(y)), 255)\n",
    "\n",
    "    ret, snake_mask = cv2.threshold(snake_mask,0,1,cv2.THRESH_BINARY)\n",
    "    return snake_mask\n",
    "\n",
    "\n",
    "def keep_overlaps2(image,overlap_num): \n",
    "    '''\n",
    "    This function keeps parts of the image that is greater than overlap_num when thresholding\n",
    "    '''\n",
    "    image2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        if i==0:\n",
    "            image2[i]=image[i]+image[i+1]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        elif i==(j-1):\n",
    "            image2[i]=image[i-1]+image[i]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        else:\n",
    "            image2[i]=image[i-1]+image[i]+image[i+1]\n",
    "    ret, image2= cv2.threshold(image2,overlap_num,1,cv2.THRESH_BINARY) \n",
    "    return image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bone Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "def sharpen(image,factor):\n",
    "    '''\n",
    "    This function sharpens the input images by enhancing their sharpness using a specified factor\n",
    "    '''\n",
    "    sharpened=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "\n",
    "        cf=image[i].copy() \n",
    "        cf=Image.fromarray(cf, mode=None)\n",
    "        enhancer = ImageEnhance.Sharpness(cf) #make border of cortical bone sharper\n",
    "\n",
    "        sharpened[i]=enhancer.enhance(factor) \n",
    "    return sharpened\n",
    "\n",
    "\n",
    "def get_boneprep(image,minsize):\n",
    "    '''This function prepares bone images by applying various filters and processing steps to enhance bone structures and remove noise\n",
    "    '''\n",
    "    bone_prep=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    bone_ots=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    subcfatmask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    bone_prep_th=[]\n",
    "\n",
    "\n",
    "    bone_prep=sharpen(image,5.0) \n",
    "    bone_prep=apply_CurvatureFilter(bone_prep, Ivol8c_roi) \n",
    "\n",
    "    subcfatmask=musc_fat_mask-musc_mask_final \n",
    "    for i in range(j):\n",
    "    \n",
    "        bone_prep[i] = cv2.bilateralFilter(bone_prep[i],15,20,45) \n",
    "            \n",
    "            \n",
    "        bone_prep_th.append([])\n",
    "        bone_prep_th[i]=multi_otsu_1(bone_prep[i])\n",
    "        bone_prep[i]=bone_prep[i]>bone_prep_th[i]\n",
    "\n",
    "            \n",
    "        bone_prep[i]=bone_prep[i]-subcfatmask[i]\n",
    "        bone_prep[i][bone_prep[i]>1] = 0 \n",
    "            \n",
    "\n",
    "        bone_prep[i] = (morphology.remove_small_holes(bone_prep[i],area_threshold=minsize*12.5, connectivity=1)) # *** remove small holes in bone. Default = 100 \n",
    "\n",
    "        bone_prep[i] = label(bone_prep[i])\n",
    "\n",
    "        bone_prep[i] = (morphology.remove_small_objects(bone_prep[i],min_size=minsize*3.75, connectivity=1)) # *** remove small objects in bone\n",
    "        \n",
    "        \n",
    "        th, bone_prep[i] = cv2.threshold(bone_prep[i], 0, 1, cv2.THRESH_BINARY)\n",
    "   \n",
    "            \n",
    "    return bone_prep, subcfatmask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_connectivity_w_adj(image):\n",
    "    '''\n",
    "    This function checks the Z-connectivity among slices in a set of images with their adjacent slices and separates Z-connected parts from non-Z parts\n",
    "    '''\n",
    "    nonZ=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    Z=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        if i==0: #if first slice only add with next slice\n",
    "            combined_w_next=image[i+1]+image[i]\n",
    "            ret, fatconnectedparts_next= cv2.threshold(combined_w_next,1,1,cv2.THRESH_BINARY)\n",
    "            z_connection=fatconnectedparts_next\n",
    "\n",
    "        elif i==(j-1): #if last slice only add with prev slice\n",
    "            combined_w_prev=image[i-1]+image[i]\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(combined_w_prev,1,1,cv2.THRESH_BINARY) #must match both adj slices\n",
    "            z_connection=fatconnectedparts_prev\n",
    "        else: #add with both prev and next slice\n",
    "            combined_w_prev=image[i-1]+image[i]\n",
    "            combined_w_next=image[i]+image[i+1]\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(combined_w_prev,1,1,cv2.THRESH_BINARY)\n",
    "            ret, fatconnectedparts_next= cv2.threshold(combined_w_next,1,1,cv2.THRESH_BINARY)\n",
    "\n",
    "            z_connection=fatconnectedparts_prev+fatconnectedparts_next\n",
    "            ret, z_connection= cv2.threshold(z_connection,1,1,cv2.THRESH_BINARY) \n",
    "\n",
    "        #find XY connections to Z connected parts\n",
    "        coordinates= np.argwhere(z_connection==1)     \n",
    "            \n",
    "        im_ff=image[i].copy() \n",
    "        h, w = im_ff.shape[:2] \n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "        for item in range(len(coordinates)): #floodfill in the coordinates of z-connectivity \n",
    "            cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "\n",
    "        #Remove small islands for Non-Z parts\n",
    "        nonZ[i]=(im_ff==1)\n",
    "   \n",
    "        Z[i] = (im_ff==2)\n",
    "        \n",
    "    return Z,nonZ\n",
    "\n",
    "\n",
    "def Z_connectivity_w_one(image, image2): \n",
    "    '''\n",
    "    This function checks the Z-connectivity of slices in a set of images with one other image and separates Z-connected parts from non-Z parts\n",
    "    '''\n",
    "    nonZ=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    Z=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):     \n",
    "        combined=image[i]+image2\n",
    "        ret, z_connection= cv2.threshold(combined,1,1,cv2.THRESH_BINARY)\n",
    "        z_connection=z_connection\n",
    "        \n",
    "        #find XY connections to Z connected parts\n",
    "        coordinates= np.argwhere(z_connection==1)    \n",
    "            \n",
    "        im_ff=image[i].copy()  \n",
    "        h, w = im_ff.shape[:2] \n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "        for item in range(len(coordinates)): #floodfill in the coordinates of z-connectivity \n",
    "            cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "\n",
    "        #Remove small islands for Non-Z parts\n",
    "        nonZ[i]=(im_ff==1)\n",
    "        Z[i] = (im_ff==2)\n",
    "         \n",
    "    return Z,nonZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find potential bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_mid_coord_one(image,y,x):  \n",
    "    '''\n",
    "    This function applies a flood fill operation starting from a specific coordinate (y, x) in the input image and returns the resulting filled area\n",
    "    '''\n",
    "    coord_applied=(image.copy()).astype(np.uint8)\n",
    "    h, w = coord_applied.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    cv2.floodFill(coord_applied, mask, (y,x), 2)\n",
    "\n",
    "    coord_applied=(coord_applied==2).astype(np.uint8)\n",
    "    return coord_applied\n",
    "\n",
    "\n",
    "def get_centroid(image):\n",
    "    '''\n",
    "    This function finds the centroid of the image\n",
    "    '''\n",
    "    coords= np.argwhere(image>0)  \n",
    "    x = [p[0] for p in coords]\n",
    "    y = [p[1] for p in coords]\n",
    "    centroid = [round(sum(x) / len(coords)), round(sum(y) / len(coords))] \n",
    "    return centroid\n",
    "\n",
    "def find_potentialbone(image,minsize):\n",
    "    '''\n",
    "    This function identifies potential bone regions in the input image by finding contours, filtering them based on area and circularity criteria, and applying flood fill operations\n",
    "    '''\n",
    "    contour_coords_L1=[]\n",
    "    contour_coords_L2=[]\n",
    "    bonemwvol=[]\n",
    " \n",
    "    test1=[]\n",
    "    test2=[]\n",
    "  \n",
    "    zeros=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "    \n",
    "    zeros1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    zeros2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "\n",
    "    k=0\n",
    "    for i in range(j):\n",
    "        contour_coords_L1.append([])\n",
    "        contour_coords_L2.append([])\n",
    "        bonemwvol.append([])\n",
    "        \n",
    "        test1.append([])\n",
    "        test2.append([])\n",
    "    \n",
    "        a, b =  cv2.findContours(image[i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "        contour_coords_L1[i].append(a) #list of contours for all slices (each index = list for each slice)\n",
    "        \n",
    "        for contour in contour_coords_L1[i][0]: \n",
    "            test1[i] = cv2.drawContours(zeros1[i], contour_coords_L1[i][0],  -1, (1,0,0), 1)\n",
    "            test1[i]=floodfill(test1[i]) \n",
    "            approx = cv2.arcLength(contour,True)\n",
    "            area = cv2.contourArea(contour) \n",
    "            (x,y),radius = cv2.minEnclosingCircle(contour) \n",
    "\n",
    "            radius = int(radius)\n",
    "            a=0.8*(radius**2) # *** 25% (3.14159/4 = ~0.8) fit of a minimum enclosing circle \n",
    "            b=0.5*(radius*approx)//2 # *** 50% fit of a circle based on perimeter of object \n",
    "        \n",
    "            if (area>a) & (area>b) & (area>minsize*3.75):  # *** threshold for a minimum area of Default = 30 based on 0.98 mm pixel size. \n",
    "                contour_coords_L2[i].append(contour) #append the contours that meet the criteria\n",
    "                test2[i] = cv2.drawContours(zeros2[i], contour_coords_L2[i],  -1, (1,0,0), 1) \n",
    "        bonemwvol=test2\n",
    "\n",
    "    \n",
    "    bonemwvol=floodfillall(bonemwvol) \n",
    "    \n",
    "    \n",
    "    return bonemwvol\n",
    "\n",
    "#recovering the fibula\n",
    "def recoverfibula():\n",
    "    bonemvol=np.zeros([Ivol8c_roi.shape[0],Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    channels_collated=[]\n",
    "    \n",
    "    for i in range(j):\n",
    "        channels_collated.append([])\n",
    "        channels_collated[i]=label(bonemvols[i])\n",
    "\n",
    "    channels_isolated=[]\n",
    "    above_th=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        above_th.append([])\n",
    "        channels_isolated.append([])\n",
    "        for ii in range(np.amax(channels_collated[i])):\n",
    "            channels_isolated[i].append((channels_collated[i]==ii+1))\n",
    "\n",
    "        for ii in range(np.amax(channels_collated[i])):\n",
    "            seg=channels_isolated[i][ii]*Ivol8c_roi[i]\n",
    "\n",
    "            seg_masked=np.ma.masked_where(seg==0,seg) #fat peeled\n",
    "            seg_mean=np.mean(seg_masked) \n",
    "\n",
    "            #if seg_mean>fat_th[i]:\n",
    "            if seg_mean>0:\n",
    "                above_th[i].append(channels_isolated[i][ii])\n",
    "                #print(i, seg_mean, fat_th[i])\n",
    "\n",
    "        size1=0\n",
    "        size2=0\n",
    "        for ii in range(len(above_th[i])):\n",
    "            if np.sum(above_th[i][ii])>size1:\n",
    "                size1=np.sum(above_th[i][ii])\n",
    "                c=ii\n",
    "            elif np.sum(above_th[i][ii])>size2:\n",
    "                size2=np.sum(above_th[i][ii])\n",
    "                d=ii\n",
    "\n",
    "        try:\n",
    "            bonemvol[i]=above_th[i][d]\n",
    "        except: \n",
    "            pass\n",
    "    return bonemvol\n",
    "\n",
    "###\n",
    "\n",
    "###____\n",
    "def recoverfibulacortical():\n",
    "    marrowcount=0\n",
    "    for i in range(j):\n",
    "        marrowcount+=fibulamarrow[i]\n",
    "    if np.amax(marrowcount)<(j*0.7):\n",
    "        recoveredmarrow=0\n",
    "    else:\n",
    "        fibulaoverlay=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "        for i in range(j):\n",
    "            fibulaoverlay+=fibulamarrow[i]\n",
    "        fibulaoverlaymax=fibulaoverlay==np.amax(fibulaoverlay)\n",
    "\n",
    "\n",
    "        centerfibmarrowlist=np.argwhere(fibulaoverlaymax==1)\n",
    "        centerfibmarrow=centerfibmarrowlist[len(centerfibmarrowlist)//2]\n",
    "\n",
    "        ###___\n",
    "        #for other code, cannot use fg. need to use boneprep to get rid of as much fat as possible\n",
    "        recoveredmarrow=fg.copy()\n",
    "        unsuccessfulfib=[]\n",
    "        successfulfib=[]\n",
    "\n",
    "        for i in range(j):\n",
    "            h, w = Ivol8c_roi[0].shape[:2]\n",
    "            mask = np.zeros((h+2, w+2), np.uint8)\n",
    "            if recoveredmarrow[i][centerfibmarrow[0],centerfibmarrow[1]]==1:\n",
    "                cv2.floodFill(recoveredmarrow[i], mask, (centerfibmarrow[1],centerfibmarrow[0]), 2);\n",
    "                ret, recoveredmarrow[i] = cv2.threshold(recoveredmarrow[i],1,1,cv2.THRESH_BINARY)\n",
    "                successfulfib.append(i)\n",
    "            else:\n",
    "                unsuccessfulfib.append(i)\n",
    "        #while loop to iterate through all until done?\n",
    "\n",
    "        for item in unsuccessfulfib:\n",
    "            overlaySUS=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "            for item2 in successfulfib:#overlay the recovered marrow onto unsuccessful bone masks\n",
    "                overlaySUS+=recoveredmarrow[item2]\n",
    "            overlaySUS=(overlaySUS>0)*len(successfulfib)\n",
    "\n",
    "\n",
    "        for item in unsuccessfulfib:\n",
    "            overlaySUS2=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')   \n",
    "            overlaySUS2=overlaySUS+recoveredmarrow[item]\n",
    "\n",
    "            coord=np.argwhere((recoveredmarrow[item])==1)\n",
    "\n",
    "            maximum=0\n",
    "            for item2 in coord:\n",
    "                if overlaySUS2[item2[0],item2[1]]>maximum:\n",
    "                    maximum=overlaySUS2[item2[0],item2[1]]\n",
    "\n",
    "            repairUScoord=np.argwhere(overlaySUS2==maximum)\n",
    "            repairUScoord=repairUScoord[len(repairUScoord)//2]\n",
    "\n",
    "            h, w = Ivol8c_roi[0].shape[:2]\n",
    "            mask = np.zeros((h+2, w+2), np.uint8)\n",
    "            print(recoveredmarrow[item][repairUScoord[1],repairUScoord[0]])\n",
    "            cv2.floodFill(recoveredmarrow[item], mask, (repairUScoord[1],repairUScoord[0]), 2);\n",
    "            ret, recoveredmarrow[item] = cv2.threshold(recoveredmarrow[item],1,1,cv2.THRESH_BINARY)\n",
    "\n",
    "    return recoveredmarrow\n",
    "    \n",
    "# Create tibia mask - AW added 10-10-2024 \n",
    "# does not hinge on tibia marrow being the largest area within each slice \n",
    "\n",
    "def tibmask(minsize):\n",
    "    # fibula seed identification \n",
    "    boneadd = np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    mscadd = np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "    # Add all slices together to see overlap region and isolate it as potential seed points\n",
    "    for i in range(j):\n",
    "        boneadd += bone_prep[i]\n",
    "        mscadd += musc_mask_final[i]\n",
    "    \n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    \n",
    "    # get the common muscle mask region and erode to remove outer pixels that might contain similarly sized fat as fibula \n",
    "    mscadd2 = (mscadd==np.max(mscadd)).astype('uint8')\n",
    "    mscadd2 = cv2.erode(mscadd2, kernel, iterations=20)\n",
    "    \n",
    "    # multiply common muscle mask with bone_prep addition (boneadd) \n",
    "    # remove previously isolated tibia mask additions from this to get fibula potential seed\n",
    "    \n",
    "    boneadd = (boneadd*mscadd2)*1\n",
    "    boneadd = (boneadd==np.max(boneadd))*1\n",
    "    tib = ((boneadd)>0)\n",
    "    \n",
    "    # filter out small objects \n",
    "    tib = (morphology.remove_small_holes(tib,area_threshold=minsize*12.5, connectivity=1)) # *** remove small holes in bone. Default = 100 \n",
    "    tib = (morphology.remove_small_objects(tib.astype('bool'),min_size=minsize, connectivity=1)) # *** remove small objects in bone. minsize*3.75\n",
    "    tib = (tib>0)*1\n",
    "    \n",
    "    # erode to an appropriate seed point - does not need to be large\n",
    "    tibseed = (cv2.erode(tib.astype('uint8'), kernel, iterations=3)>0)*1\n",
    "\n",
    "    try:\n",
    "        from scipy.ndimage import binary_dilation, label\n",
    "        tibmask = np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "        for i in range(j):\n",
    "            # Initial mask (seed mask) - 2D numpy array (binary: 1 where the seed is)\n",
    "            seed_mask = tibseed\n",
    "            \n",
    "            # Mask to expand into (boundary mask) - 2D numpy array (binary: 1 where expansion is allowed)\n",
    "            boundary_mask = (cv2.erode(bone_prep[i].astype('uint8'), kernel, iterations=1)>0)*1\n",
    "            \n",
    "            # Create an empty array for the filled region\n",
    "            filled_region = np.zeros_like(boundary_mask)\n",
    "            \n",
    "            # Use the seed to define the starting points (where seed is 1, fill_region becomes 1)\n",
    "            filled_region[seed_mask == 1] = 1\n",
    "            \n",
    "            # Iteratively grow the region using binary dilation, constrained by the boundary mask\n",
    "            # Stop when no further growth is possible\n",
    "            previous_filled_region = None\n",
    "            \n",
    "            while not np.array_equal(filled_region, previous_filled_region):\n",
    "                previous_filled_region = filled_region.copy()\n",
    "                # Perform dilation on the filled region\n",
    "                expanded = binary_dilation(filled_region)\n",
    "                # Constrain the expansion to the boundary mask\n",
    "                filled_region = expanded & boundary_mask\n",
    "            \n",
    "            # Label connected regions in the boundary mask to isolate the desired object\n",
    "            labeled_mask, num_features = label(boundary_mask)\n",
    "            \n",
    "            # Keep only the part of the labeled object that overlaps with the filled region\n",
    "            # Identify the label of the connected component containing the seed\n",
    "            object_label = labeled_mask[filled_region > 0][0]  # Find the label corresponding to the filled region\n",
    "            \n",
    "            isolated_object = (labeled_mask == object_label).astype(int)\n",
    "            tibmask[i] = (cv2.dilate(isolated_object.astype('uint8'), kernel, iterations=1)>0)*1\n",
    "            \n",
    "            # plt.imshow(tibmask[i])\n",
    "            # plt.show()\n",
    "    except: \n",
    "        tibmask = np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    return tibmask\n",
    "\n",
    "# Create fibula mask - AW added 10-10-2024 \n",
    "# does not hinge on fibula marrow being the second largest area within each slice \n",
    "\n",
    "def fibmask():\n",
    "    # fibula seed identification \n",
    "    boneadd = np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    mscadd = np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    tibadd = np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    # Add all slices together to see overlap region and isolate it as potential seed points\n",
    "    for i in range(j):\n",
    "        boneadd += bone_prep[i]\n",
    "        mscadd += musc_mask_final[i]\n",
    "        tibadd += bone_prep2[i]\n",
    "    \n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    \n",
    "    # get the common muscle mask region and erode to remove outer pixels that might contain similarly sized fat as fibula \n",
    "    mscadd2 = (mscadd==np.max(mscadd)).astype('uint8')\n",
    "    mscadd2 = cv2.erode(mscadd2, kernel, iterations=20)\n",
    "    \n",
    "    # multiply common muscle mask with bone_prep addition (boneadd) \n",
    "    # remove previously isolated tibia mask additions from this to get fibula potential seed\n",
    "    \n",
    "    boneadd = (boneadd*mscadd2)*1\n",
    "    boneaddthr = threshold_multiotsu(boneadd.ravel())\n",
    "    \n",
    "    boneadd = (boneadd>boneaddthr[1])*1\n",
    "    tibadd = (tibadd==np.max(tibadd))*1\n",
    "    tibadd = cv2.dilate(tibadd.astype('uint8'), kernel, iterations=20)\n",
    "    fib = ((boneadd - tibadd)>0)\n",
    "    \n",
    "    tiby, tibx = np.where(tibadd == 1)\n",
    "    tibaddmaxy = np.max(tiby)\n",
    "    \n",
    "    fiby, fibx = np.where(fib == 1)\n",
    "    fib[:tibaddmaxy, :] = 0\n",
    "    \n",
    "    # erode to an appropriate seed point - does not need to be large\n",
    "    fib = (cv2.erode(fib.astype('uint8'), kernel, iterations=2)>0)*1\n",
    "    \n",
    "    # filter out small objects \n",
    "    fib = (morphology.remove_small_holes(fib.astype('bool'),area_threshold=minsize*4, connectivity=1)) # *** remove small holes in bone. was minsize*12.5. Default = 100 \n",
    "    fib = (morphology.remove_small_objects(fib.astype('bool'),min_size=minsize//3, connectivity=1)) # *** remove small objects in bone default minsize*3.75\n",
    "    fib = (fib>0)*1\n",
    "    \n",
    "    # erode to an appropriate seed point - does not need to be large\n",
    "    fibseed = (cv2.dilate(fib.astype('uint8'), kernel, iterations=1)>0)*1\n",
    "\n",
    "    #try: \n",
    "    fibmask = np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        # Initial mask (seed mask) - 2D numpy array (binary: 1 where the seed is)\n",
    "        seed_mask = fibseed\n",
    "        \n",
    "        # Mask to expand into (boundary mask) - 2D numpy array (binary: 1 where expansion is allowed)\n",
    "        boundary_mask = (cv2.erode(bone_prep[i].astype('uint8'), kernel, iterations=4)>0)*1\n",
    "        boundary_mask = (cv2.dilate(boundary_mask.astype('uint8'), kernel, iterations=4)>0)*1\n",
    "        #boundary_mask = bone_prep[i].copy()\n",
    "        \n",
    "        # Create an empty array for the filled region\n",
    "        filled_region = np.zeros_like(boundary_mask)\n",
    "        \n",
    "        # Use the seed to define the starting points (where seed is 1, fill_region becomes 1)\n",
    "        filled_region[seed_mask == 1] = 1\n",
    "        \n",
    "        # Iteratively grow the region using binary dilation, constrained by the boundary mask\n",
    "        # Stop when no further growth is possible\n",
    "        previous_filled_region = None\n",
    "        \n",
    "        while not np.array_equal(filled_region, previous_filled_region):\n",
    "            previous_filled_region = filled_region.copy()\n",
    "            # Perform dilation on the filled region\n",
    "            expanded = binary_dilation(filled_region)\n",
    "            # Constrain the expansion to the boundary mask\n",
    "            filled_region = expanded & boundary_mask\n",
    "\n",
    "        # Label the objects in the mask\n",
    "        labeled_mask = label(filled_region)\n",
    "        \n",
    "        # Initialize variables to track the roundest object\n",
    "        best_label = None\n",
    "        best_roundness = -np.inf\n",
    "        \n",
    "        # Iterate over the objects and compute circularity (or other roundness metrics)\n",
    "        for region in regionprops(labeled_mask):\n",
    "            # Compute circularity: 4π * Area / (Perimeter^2)\n",
    "            if region.perimeter > 0:  # Avoid division by zero\n",
    "                circularity = 4 * np.pi * region.area / (region.perimeter ** 2)\n",
    "                \n",
    "                # Update if this object is rounder than previous ones\n",
    "                if circularity > best_roundness:\n",
    "                    best_roundness = circularity\n",
    "                    best_label = region.label\n",
    "        \n",
    "        # Create a new mask keeping only the roundest object\n",
    "        roundest_object_mask = (labeled_mask == best_label)\n",
    "\n",
    "        roundest_object_mask = (cv2.dilate(roundest_object_mask.astype('uint8'), kernel, iterations=2)>0)*1\n",
    "\n",
    "        fibmask[i] = roundest_object_mask\n",
    "\n",
    "        # Label connected regions in the boundary mask to isolate the desired object\n",
    "    \n",
    "    #except:\n",
    "        #fibmask = np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    return fibmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biggest_obj(image): #must be LABELLED image\n",
    "    '''\n",
    "    This function takes a labeled image as input and returns the largest object (with the maximum sum of pixel values) from the labeled image\n",
    "    '''\n",
    "    channels_isolated=[] \n",
    "\n",
    "    for i in range(np.amax(image)):\n",
    "        channels_isolated.append((image==i+1).astype(np.uint8))\n",
    "\n",
    "    sum_channel_L=[]\n",
    "    for i in range(np.amax(image)):\n",
    "        sum_channel_L.append([])\n",
    "        sum_channel_L[i]=np.sum(channels_isolated[i])\n",
    "\n",
    "    sum_channel_L2=sum_channel_L.copy()\n",
    "    largest_sum = max(sum_channel_L2)  \n",
    "\n",
    "\n",
    "    for i in range(np.amax(image)):\n",
    "        if sum_channel_L[i]==largest_sum: \n",
    "            largest_obj=channels_isolated[i]\n",
    "\n",
    "    return  largest_obj\n",
    "\n",
    "\n",
    "def find_potentialbone2(image1): \n",
    "    '''\n",
    "    This function identifies potential bone regions from a labeled image by finding the largest connected object in each slice of the labeled image. It then divides the slices into two halves and combines the largest objects from each half to obtain a final potential bone region\n",
    "    '''\n",
    "    z_labelled=label(image1>0).astype(np.uint8) \n",
    "        \n",
    "    tib=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "    try:\n",
    "        for i in range(j):\n",
    "            tib[i]=get_biggest_obj(z_labelled[i])  #get biggest obj from boneprep_Z_labelled \n",
    "    except: \n",
    "        tib=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "        \n",
    "    #=======================================Divide slices in half===============================================#\n",
    "    \n",
    "    #Slice number\n",
    "    j1=round(j/2)\n",
    "    j2=j-j1\n",
    "\n",
    "    #Tib\n",
    "    tib1=tib[:j1,:,:]\n",
    "    tib2=tib[j1:,:,:]\n",
    "    \n",
    "    #bone-prep - needed when apply coordinates for fib\n",
    "    bone_prep1=bone_prep[:j1,:,:]\n",
    "    bone_prep2=bone_prep[j1:,:,:] \n",
    "\n",
    "    #Ivol8c_roi - needed for overlaying to check later\n",
    "    Ivol8c_roi1=Ivol8c_roi[:j1,:,:] \n",
    "    Ivol8c_roi2=Ivol8c_roi[j1:,:,:]\n",
    "\n",
    "    \n",
    "    #===========Add HALF of the images separately =========#\n",
    "\n",
    "\n",
    "    #-----TIBIA----#\n",
    "    tib1_added=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "    tib2_added=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "    \n",
    "    for i in range(j1):\n",
    "        tib1_added+=tib1[i]\n",
    "    for i in range(j2):\n",
    "        tib2_added+=tib2[i]\n",
    "    \n",
    "    tib1_added_keep=label(tib1_added==np.amax(tib1_added)) #keep pixels that overlap at least for ALL slices\n",
    "    tib2_added_keep=label(tib2_added==np.amax(tib2_added))\n",
    "\n",
    "    \n",
    "    tib1_added_keep=get_biggest_obj(tib1_added_keep) #sometimes portion of tib is separated, results in two obj - take bigger obj\n",
    "    tib2_added_keep=get_biggest_obj(tib2_added_keep)  \n",
    "    \n",
    "    \n",
    "    #====================Get mid-point coords of tib and fib - use as seed for floodfill on bone_prep=======================================#\n",
    "    tib1_mid_coord=get_centroid(tib1_added_keep)\n",
    "    tib2_mid_coord=get_centroid(tib2_added_keep)\n",
    "\n",
    "    \n",
    "\n",
    "    bone_prep1_copy=bone_prep1.copy() \n",
    "    bone_prep2_copy=bone_prep2.copy() \n",
    "    \n",
    "\n",
    "     #------------TIBIA-------------------------#\n",
    "\n",
    "    #apply coord on image of interest    \n",
    "    tibmarrow1=bone_prep1.copy()\n",
    "    tibmarrow2=bone_prep2.copy()\n",
    "    \n",
    "    k=0\n",
    "    \n",
    "    for i in range(j1):\n",
    "        tibmarrow1[i]=apply_mid_coord_one(tibmarrow1[i],tib1_mid_coord[1],tib1_mid_coord[0]) \n",
    "    for i in range(j2):\n",
    "        tibmarrow2[i]=apply_mid_coord_one(tibmarrow2[i],tib2_mid_coord[1],tib2_mid_coord[0])\n",
    "\n",
    "            \n",
    "    #===================================ADD ISOLATED TIBS + FIBS======================================================================================\n",
    "\n",
    "\n",
    "    tib_final=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    i2=0 #need new counter for second half of slices\n",
    "    for i in range(j):\n",
    "        if i<j1:#if part of first half of slices\n",
    "            tib_final[i]=tibmarrow1[i]\n",
    "        else: #if part of second half of slices\n",
    "            tib_final[i]=tibmarrow2[i2]\n",
    "            i2+=1\n",
    "\n",
    "    return tib_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get cortical bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def corticaloutline(image,minsize): \n",
    "    '''\n",
    "    This function extracts the outline of the cortical bone from an input image, isolating the cortical bone region and removing noise\n",
    "    '''\n",
    "    cortical=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        th0=multi_otsu_0(image[i]) \n",
    "        cortical[i]=label(image[i]>th0) \n",
    "        ret, cortical[i] = cv2.threshold(cortical[i],0,1,cv2.THRESH_BINARY) \n",
    "        cortical[i] = (morphology.remove_small_holes(cortical[i],area_threshold=minsize*2.5, connectivity=1)) # *** remove small holes in bone, isolate cortical bone. Default = 20 at 0.98 mm pixel size. \n",
    "        cortical[i] = (morphology.remove_small_objects(cortical[i],min_size=minsize*50, connectivity=0))\n",
    "        cortical[i]=cv2.morphologyEx(cortical[i], cv2.MORPH_OPEN, np.ones((7,7),np.uint8))\n",
    "    return cortical\n",
    "\n",
    "def merge_bones(cortical_mask,bonem_mask,minsize):   \n",
    "    '''\n",
    "    This function merges the cortical bone mask and the bone marrow mask, isolating the cortical bone region while removing any overlapping regions with the bone marrow\n",
    "    '''\n",
    "    k=8\n",
    "\n",
    "    #=========== TIBIA REMOVAL==========#\n",
    "    \n",
    "    corticalt=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "\n",
    "    bonem_mask_dilated=cv2.dilate(bonem_mask,np.ones((5,5),np.uint8),iterations = 1) #minimize obj left behind after subtraction\n",
    "    \n",
    "    t_bone=cortical_mask-bonem_mask_dilated\n",
    "    t_bone[t_bone>1]=0\n",
    "\n",
    "    t_bone = t_bone.astype('bool')\n",
    "\n",
    "    # deprecated by AW - remove_small functions require boolean \n",
    "    # corticalt = (morphology.remove_small_holes(label(t_bone),area_threshold=minsize*3.75, connectivity=0)) # *** get rid of lines. Default = 30 at 0.98 mm pixel size.  \n",
    "    # corticalt = (morphology.remove_small_objects(label(corticalt),min_size=minsize*187.5, connectivity=0)) # *** remove white stuff in cortical bone. Default = 1500 at 0.98 mm pixel size.  \n",
    "    # corticalt = (morphology.remove_small_objects(label(corticalt),min_size=minsize*187.5, connectivity=0)) # *** remove white stuff in cortical bone. Default = 1500 at 0.98 mm pixel size. \n",
    "\n",
    "    corticalt = (morphology.remove_small_holes(t_bone,area_threshold=minsize*3.75, connectivity=0)) # *** get rid of lines. Default = 30 at 0.98 mm pixel size.  \n",
    "    corticalt = (morphology.remove_small_objects(corticalt,min_size=minsize*187.5, connectivity=0)) # *** remove white stuff in cortical bone. was minsize*187.5 Default = 1500 at 0.98 mm pixel size.  \n",
    "    corticalt = (morphology.remove_small_objects(corticalt,min_size=minsize*187.5, connectivity=0)) # *** remove white stuff in cortical bone. was minsize*187.5 Default = 1500 at 0.98 mm pixel size. \n",
    "    corticalt = corticalt.astype(np.uint8)\n",
    "    \n",
    "    corticalt = cv2.morphologyEx(corticalt, cv2.MORPH_CLOSE, np.ones((7,7),np.uint8)) #get rid of remaining holes \n",
    "\n",
    "    im_floodfill = corticalt.copy()\n",
    "    h, w = im_floodfill.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 1)\n",
    "    th, corticalt_final = cv2.threshold(im_floodfill, 0, 1, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    #if more than 1 obj - take the largest \n",
    "    labelled=np.zeros([cortical_mask.shape[0], cortical_mask.shape[1]], dtype='uint8')\n",
    "\n",
    "    num_obj,labelled=cv2.connectedComponents(corticalt_final)\n",
    "    if num_obj>2: #if more than just 2 obj (background + 1 bone)\n",
    "        corticalt_final=get_biggest_obj(label(corticalt_final)) #must be labelled\n",
    "       \n",
    "    else:\n",
    "        corticalt_final=corticalt_final\n",
    "\n",
    "    corticalt_final = corticalt_final.astype(np.uint8)\n",
    "\n",
    "    corticalt_final=cv2.morphologyEx(corticalt_final, cv2.MORPH_CLOSE, np.ones((7,7),np.uint8)) \n",
    " \n",
    "    return corticalt_final\n",
    "    \n",
    "def merge_bones_DEPRECATED_BY_AW(cortical_mask,bonem_mask,minsize):   \n",
    "    '''\n",
    "    This function merges the cortical bone mask and the bone marrow mask, isolating the cortical bone region while removing any overlapping regions with the bone marrow\n",
    "    '''\n",
    "    k=8\n",
    "\n",
    "    #=========== TIBIA REMOVAL==========#\n",
    "    \n",
    "    corticalt=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "\n",
    "    bonem_mask_dilated=cv2.dilate(bonem_mask,np.ones((5,5),np.uint8),iterations = 1) #minimize obj left behind after subtraction\n",
    "    \n",
    "    t_bone=cortical_mask-bonem_mask_dilated\n",
    "    t_bone[t_bone>1]=0\n",
    "   \n",
    "    \n",
    "    for i in range(j):   \n",
    "        corticalt[i] = (morphology.remove_small_holes(label(t_bone[i]).astype('bool'),area_threshold=minsize*3.75, connectivity=0)) # *** get rid of lines. Default = 30 at 0.98 mm pixel size.  \n",
    "\n",
    "        corticalt[i] = (morphology.remove_small_objects(label(corticalt[i]).astype('bool'),min_size=minsize*187.5, connectivity=0)) # *** remove white stuff in cortical bone. Default = 1500 at 0.98 mm pixel size.  \n",
    "  \n",
    "        corticalt[i] = (morphology.remove_small_objects(label(corticalt[i]).astype('bool'),min_size=minsize*187.5, connectivity=0)) # *** remove white stuff in cortical bone. Default = 1500 at 0.98 mm pixel size. \n",
    "     \n",
    "        corticalt[i]=cv2.morphologyEx(corticalt[i], cv2.MORPH_CLOSE, np.ones((7,7),np.uint8)) #get rid of remaining holes  \n",
    "     \n",
    "    corticalt_final=floodfillall(corticalt)\n",
    "    \n",
    "    #if more than 1 obj - take the largest \n",
    "    labelled=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        num_obj,labelled[i]=cv2.connectedComponents(corticalt_final[i])\n",
    "        if num_obj>2: #if more than just 2 obj (background + 1 bone)\n",
    "            corticalt_final[i]=get_biggest_obj(label(corticalt_final[i])) #must be labelled\n",
    "       \n",
    "            \n",
    "        else:\n",
    "            corticalt_final[i]=corticalt_final[i]\n",
    "    \n",
    "    corticalt_final=cv2.morphologyEx(corticalt_final, cv2.MORPH_CLOSE, np.ones((7,7),np.uint8)) \n",
    "    \n",
    " \n",
    "    return corticalt_final\n",
    "\n",
    "def get_roi(musc_mask,bone_mask,image):\n",
    "    roi_mask=musc_mask-bone_mask\n",
    "    roi_mask[roi_mask>1] = 0 \n",
    "    \n",
    "    for i in range(len(roi_mask)):\n",
    "        ret, roi_mask[i] = cv2.threshold(roi_mask[i],0,1,cv2.THRESH_BINARY)\n",
    "    \n",
    "    roi=roi_mask*image\n",
    "    return roi_mask, roi\n",
    "\n",
    "def get_roi_DEPRECATED_BY_AW(musc_mask,bone_mask,image):\n",
    "    '''\n",
    "    This function extracts the region of interest (ROI) from an input image based on the muscle mask and bone mask\n",
    "    '''\n",
    "    roi_mask=musc_mask-bone_mask \n",
    "    roi_mask[roi_mask>1] = 0 \n",
    "    ret, roi_mask = cv2.threshold(roi_mask,0,1,cv2.THRESH_BINARY)\n",
    "    \n",
    "    roi=roi_mask*image\n",
    "    return roi_mask, roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> ITSA 1st Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_th(image):\n",
    "    '''\n",
    "    This function calculates the initial threshold values for optimization using multi-otsu thresholding for each slice of the input image\n",
    "    '''\n",
    "    initial_th=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        initial_th.append([])\n",
    "        initial_th[i]=multi_otsu_1(image[i]) \n",
    "\n",
    "    return initial_th\n",
    "\n",
    "def ITSA_no_Z(roivar,ots,minsize):  \n",
    "    '''\n",
    "    This function implements the ITSA (Iterative Threshold Selection Algorithm) without Z-connectivity check. \n",
    "    It iteratively adjusts the threshold value based on the mean signal intensity of the muscle and fat regions until convergence\n",
    "    '''\n",
    "\n",
    "    k=1\n",
    "    ThPrev=0\n",
    "    ThRev=ots  \n",
    "\n",
    "    ThPrevlist=[ThPrev]  \n",
    "    ThRevlist=[ThRev] \n",
    "\n",
    "    klist=[0] \n",
    "    matchlist=[] \n",
    "    while ThRev!=ThPrev: \n",
    "        \n",
    "        ThPrev=ThRev\n",
    "        \n",
    "        prefatmask = label(roivar>ThRev).astype('bool') \n",
    "        prefatmask = (morphology.remove_small_objects(prefatmask,min_size=minsize, connectivity=1)) # *** remove islands of fat. Default = 8 at 0.98 mm pixelsize. \n",
    "        prefatmask = np.uint8(prefatmask)\n",
    "        ret, fatmask = cv2.threshold(prefatmask,0,1,cv2.THRESH_BINARY)\n",
    "  \n",
    "        fatseg = fatmask*roivar \n",
    "        preMuscSegM=roivar-fatseg \n",
    "        MuscSegM=np.ma.masked_where(preMuscSegM == 0, preMuscSegM)\n",
    "        FatSegM=np.ma.masked_where(fatseg==0,fatseg) \n",
    "        MuscSegI=np.mean(MuscSegM) \n",
    "        FatSegI=np.mean(FatSegM)\n",
    "        ThRev=(1+((FatSegI-MuscSegI)/FatSegI))*MuscSegI \n",
    "        \n",
    "        ThPrevlist.append(ThPrev) \n",
    "        ThRevlist.append(ThRev) \n",
    "        klist.append(k) \n",
    "        matchlist.append(\"No\") \n",
    "        k+=1\n",
    "        if k==50:\n",
    "            break\n",
    "       \n",
    "        if ThRev==ThPrev:\n",
    "            matchlist.append(\"Yes\")\n",
    "            table=QTable([klist,ThPrevlist,ThRevlist,matchlist],\n",
    "            names=('Iteration','ThPrev','ThRev','ThRev=ThPrev?'))\n",
    "  \n",
    "\n",
    "            x=klist \n",
    "            y=ThRevlist\n",
    "\n",
    "    return fatmask, fatseg, ThRev \n",
    "      \n",
    "def print_th(th):\n",
    "    '''\n",
    "    This function prints all threshold values\n",
    "    '''\n",
    "    for i in range(j):\n",
    "        print (f\"Slice {i+1} th = {th[i]}\") \n",
    "        \n",
    "def apply_ITSA_no_Z(image,initial_th,size):\n",
    "    '''\n",
    "    This function applies the ITSA without Z-connectivity check to each slice of the input image using the initial threshold values calculated previously\n",
    "    '''\n",
    "    fatseg_mask=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    optimized_th_L=[] #optimized thresholds\n",
    "    \n",
    "    for i in range(j): \n",
    "        fatseg_mask[i],fatseg[i],ThRev=ITSA_no_Z(image[i], initial_th[i],size)\n",
    "        optimized_th_L.append(ThRev) \n",
    "        \n",
    "    return optimized_th_L,fatseg_mask,fatseg\n",
    "\n",
    "\n",
    "def subtract_fat1(fat1):\n",
    "    '''\n",
    "    This function subtracts the fat region obtained from the initial thresholding from the input image to obtain the region for further processing\n",
    "    '''\n",
    "    roi_for_S1R2=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    roi_for_S1R2=roi-fat1 \n",
    "    return roi_for_S1R2\n",
    "\n",
    "def fatfinal_S1R1(roivar,th,minsize):  # not in use\n",
    "    '''\n",
    "    This function applies the final thresholding to obtain the fat region after subtracting the initial fat region from the input image\n",
    "    '''\n",
    "    fat1_mask=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat1=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        fat1_mask[i] = label(roivar[i]>th[i]) \n",
    "        fat1_mask[i] = np.uint8(fat1_mask[i]) \n",
    "        fat1_mask[i] = (morphology.remove_small_objects(fat1_mask[i].astype('bool'),min_size=minsize, connectivity=1)).astype(int) # *** remove small islands of fat. Default = 8 at 0.98 mm pixel size. \n",
    "        ret, fat1_mask[i] = cv2.threshold(fat1_mask[i],0,1,cv2.THRESH_BINARY) \n",
    "\n",
    "        fat1[i]= fat1_mask[i]*roivar[i]   \n",
    "\n",
    "    return fat1_mask,fat1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> ITSA 2nd Round "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_th(th, image): \n",
    "    '''\n",
    "    This function applies the threshold values obtained from optimization to the input image to generate binary masks for z-connectivity checking\n",
    "    '''\n",
    "    zcheck=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j): \n",
    "        zcheck[i]=(image[i]>th[i]).astype(int)\n",
    "    return zcheck\n",
    "\n",
    "def apply_fixedth(th, image): \n",
    "    '''\n",
    "    This function applies the threshold values obtained from optimization to the input image to generate binary masks for z-connectivity checking\n",
    "    '''\n",
    "    zcheck=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j): \n",
    "        zcheck[i]=(image[i]>th[i]).astype(int)\n",
    "    return zcheck\n",
    "    \n",
    "def get_final_fatsegs_S1(fatfinal,th,fatfinal_mask,image):  \n",
    "    '''\n",
    "    This function retrieves the final fat segments from Set 1 without removing objects by comparing the fat region obtained after applying the optimized threshold values to the input image with the initial fat region\n",
    "    '''\n",
    "    fat2_mask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "\n",
    "    fat1_mask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "\n",
    "    for i in range(j):\n",
    "        fat1_mask[i]=fatfinal[i]>th[i] \n",
    "        \n",
    "        fat2_mask[i]= (fat1_mask[i]!=fatfinal_mask[i])\n",
    "\n",
    "        \n",
    "        fat1[i]=fat1_mask[i]*image[i]\n",
    "        fat2[i]=fat2_mask[i]*image[i]\n",
    "        \n",
    "    return fat1_mask,fat1,fat2_mask,fat2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ITSA_w_Z(i, roivar, initial_th, zcheck,minsize):  \n",
    "    '''\n",
    "    This function performs the Improved Threshold Selection Algorithm (ITSA) with Z-connectivity check for a specific slice i of the input image. \n",
    "    It iteratively adjusts the threshold value based on fat and muscle intensities and ensures Z-connectivity by incorporating neighboring slices\n",
    "    '''\n",
    "    k=1\n",
    "    ThPrev_S2=0 \n",
    "    ThRev_S2= initial_th[i] \n",
    "\n",
    "    x=0\n",
    "    y=0\n",
    "    \n",
    "    ThPrevlist=[ThPrev_S2]  \n",
    "    ThRevlist=[ThRev_S2] \n",
    "\n",
    "    klist=[0] \n",
    "    matchlist=[] \n",
    "    \n",
    "    FatInt_L=[\"N/A\"]\n",
    "    MuscInt_L=[\"N/A\"]\n",
    "   \n",
    "    \n",
    "    while ThRev_S2!=ThPrev_S2:\n",
    "        ThPrev_S2=ThRev_S2  \n",
    "        prefatmask_S2 = (roivar[i]>ThRev_S2)\n",
    "        prefatmask_S2 = np.uint8(prefatmask_S2)\n",
    "        ret, fatmask_S2 = cv2.threshold(prefatmask_S2,0,1,cv2.THRESH_BINARY) \n",
    "\n",
    "        if i==0:\n",
    "            fatcombined_next=zcheck[i+1]+fatmask_S2\n",
    "            ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "            z_connection=fatconnectedparts_next\n",
    "   \n",
    "        elif i==(j-1):\n",
    "            fatcombined_prev=zcheck[i-1]+fatmask_S2\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "            z_connection=fatconnectedparts_prev\n",
    "   \n",
    "        else:\n",
    "            fatcombined_prev=zcheck[i-1]+fatmask_S2\n",
    "            fatcombined_next=fatmask_S2+zcheck[i+1]\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "            ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "\n",
    "            z_connection=fatconnectedparts_prev+fatconnectedparts_next\n",
    "            ret, z_connection= cv2.threshold(z_connection,0,1,cv2.THRESH_BINARY) \n",
    "        \n",
    "        #find XY connections to Z connected parts\n",
    "        coordinates= np.argwhere(z_connection ==1) \n",
    "        \n",
    "        \n",
    "        im_ff=fatmask_S2.copy()\n",
    "        h, w = im_ff.shape[:2] \n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "        for item in range(len(coordinates)):\n",
    "            cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "        \n",
    "        #Remove small islands for Non-Z parts\n",
    "        nonZ =label(im_ff==1)\n",
    "        nonZ = nonZ.astype('bool')\n",
    "        nonZ_keep = (morphology.remove_small_objects(nonZ,min_size=minsize, connectivity=1)) # *** remove small fat islands. Default = 8 at 0.98 mm pixel size.  \n",
    "        ret, nonZ_keep= cv2.threshold(np.uint8(nonZ_keep),0,1,cv2.THRESH_BINARY)\n",
    "\n",
    "        Z = (im_ff==2)\n",
    "  \n",
    "        \n",
    "        prefatseg1_S2=(Z+nonZ_keep) \n",
    "        fatseg1_S2=prefatseg1_S2*roivar[i]\n",
    "        \n",
    "        \n",
    "        #Fat and Muscle Quantification\n",
    "\n",
    "        preMuscSegP_S2=roivar[i]-fatseg1_S2\n",
    "        \n",
    "        MuscSegP_S2=np.ma.masked_where(preMuscSegP_S2 == 0, preMuscSegP_S2)\n",
    "        FatSegP_S2=np.ma.masked_where(fatseg1_S2==0,fatseg1_S2) \n",
    "        MuscSegI_S2=np.mean(MuscSegP_S2)\n",
    "        FatSegI_S2=np.mean(FatSegP_S2)\n",
    "        \n",
    "        \n",
    "        if type(FatSegI_S2)== np.ma.core.MaskedConstant:\n",
    "            ThRev_S2=ThPrev_S2\n",
    "        else:\n",
    "            ThRev_S2=(1+((FatSegI_S2-MuscSegI_S2)/FatSegI_S2))*MuscSegI_S2 \n",
    "        \n",
    "         \n",
    "        ThPrevlist.append(ThPrev_S2) \n",
    "        ThRevlist.append(ThRev_S2)\n",
    "        klist.append(k) \n",
    "        matchlist.append(\"No\")\n",
    "        \n",
    "       \n",
    "        FatInt_L.append(FatSegI_S2)\n",
    "        \n",
    "        MuscInt_L.append(MuscSegI_S2)\n",
    "\n",
    "        \n",
    "        k+=1\n",
    "        if k==50:\n",
    "            break\n",
    "            \n",
    "        if ThRev_S2==ThPrev_S2:\n",
    "            matchlist.append(\"Yes\")\n",
    "            table=QTable([klist,ThPrevlist,ThRevlist,matchlist],\n",
    "            names=('Iteration','ThPrev_S2','ThRev_S2','ThRev_S2=ThPrev_S2?'))\n",
    "\n",
    "    thresholds_S2=ThRev_S2\n",
    "    \n",
    "    return prefatseg1_S2, fatseg1_S2, thresholds_S2\n",
    "\n",
    "\n",
    "def apply_ITSA_w_Z(roivar, initial_th, zcheck,minsize):\n",
    "    '''\n",
    "    This function applies the ITSA with Z-connectivity check to all slices of the input image and returns the optimized threshold values and segmented fat regions\n",
    "    '''\n",
    "    fatseg_mask =np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg =np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "\n",
    "    optimized_th_L =[] \n",
    "    for i in range(j):\n",
    "        optimized_th_L .append([])\n",
    "        fatseg_mask[i],fatseg[i], optimized_th_L[i]=ITSA_w_Z(i, roivar,initial_th,zcheck,minsize)  \n",
    "    return optimized_th_L,fatseg_mask,fatseg   \n",
    "\n",
    "def apply_2SDabovmed(roivar):\n",
    "    two_std_above_median = []\n",
    "    abov2sdroimask = np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    masked_roi = np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    masked_roi = np.ma.masked_where(masked_roi == 0, masked_roi)\n",
    "    fatseg2 = np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        two_std_above_median.append([])\n",
    "        masked_roi[i] = np.ma.masked_where(roivar[i] == 0, roivar[i])\n",
    "        median_value = np.ma.median(masked_roi[i])\n",
    "        \n",
    "        std_value = np.ma.std(masked_roi[i])\n",
    "        two_std_above_median[i] = median_value + 2 * std_value\n",
    "\n",
    "        abov2sdroimask[i] = (roivar[i]>two_std_above_median[i])*1\n",
    "        fatseg2[i] = abov2sdroimask[i]*roivar[i]\n",
    "\n",
    "    return two_std_above_median, abov2sdroimask, fatseg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Z-Connectivity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_zcheck(i,th,zcheck,minsize): \n",
    "    '''\n",
    "    This function performs the final Z-connectivity check for slice i after applying the optimized threshold value th[i] and considering neighboring slices' fat masks represented by zcheck\n",
    "    '''\n",
    "    prefatmask_R3 = (roi[i]>th[i]) \n",
    "\n",
    "    fatmask_R3 = np.uint8(prefatmask_R3)\n",
    "    \n",
    "    if i==0:\n",
    "        fatcombined_next=zcheck[i+1]+fatmask_R3\n",
    "        ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "        z_connection=fatconnectedparts_next      \n",
    "    elif i==(j-1):\n",
    "        fatcombined_prev=zcheck[i-1]+fatmask_R3  \n",
    "        ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "        z_connection=fatconnectedparts_prev    \n",
    "    else:\n",
    "        fatcombined_prev=zcheck[i-1]+fatmask_R3\n",
    "        fatcombined_next=zcheck[i+1]+fatmask_R3 \n",
    "\n",
    "        ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "        ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "\n",
    "        z_connection=fatconnectedparts_prev+fatconnectedparts_next\n",
    "        ret, z_connection= cv2.threshold(z_connection,0,1,cv2.THRESH_BINARY)      \n",
    "\n",
    "        \n",
    "    coordinates= np.argwhere(z_connection ==1)      \n",
    "    im_ff=fatmask_R3.copy()\n",
    "    h, w = im_ff.shape[:2] \n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    for item in range(len(coordinates)):\n",
    "        cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "\n",
    "    #Remove small islands for Non-Z parts\n",
    "    nonZ =label(im_ff==1)\n",
    "    nonZ = nonZ.astype('bool')\n",
    "    nonZ_keep = (morphology.remove_small_objects(nonZ,min_size=minsize, connectivity=1)) # *** remove small islands of fat. Default = 8 at 0.98 mm pixel size. \n",
    "    ret, nonZ_keep= cv2.threshold(np.uint8(nonZ_keep),0,1,cv2.THRESH_BINARY)\n",
    "\n",
    "    Z = (im_ff==2)\n",
    "   \n",
    "    final_fat_mask=(Z+nonZ_keep) \n",
    "    final_fat=final_fat_mask*Ivol8c_roi[i] \n",
    "\n",
    "  \n",
    "    return final_fat_mask, final_fat\n",
    "\n",
    "def apply_final_zcheck(th,zcheck,minsize): \n",
    "    '''\n",
    "    This function applies the final Z-connectivity check to all slices using the optimized threshold values and Z-connectivity masks, resulting in the final segmented fat masks and fat regions\n",
    "    '''\n",
    "    fat_mask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        fat_mask[i], fat[i]=final_zcheck(i,th,zcheck,minsize) # *** minsize\n",
    "\n",
    "    return  fat_mask, fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_fatsegs(fatfinal,th,fatfinal_mask,image):\n",
    "    '''\n",
    "    This function calculates the final segmented fat masks (fatseg_mask_final_R1 and fatseg_mask_final_R2) and fat regions (fatseg_final_R1 and fatseg_final_R2) based on the optimized threshold values th applied to the final fat segmentation result fatfinal. \n",
    "    It considers the 3D connectivity check and the difference between the final fat mask and the initial fat mask\n",
    "    '''\n",
    "    fatseg_mask_final_R1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg_final_R1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    fatseg_final_R2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg_mask_final_R2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        fatseg_mask_final_R1[i]=fatfinal[i]>th[i] \n",
    "        fatseg_mask_final_R2[i]= (fatseg_mask_final_R1[i]!=fatfinal_mask[i])\n",
    "\n",
    "        fatseg_final_R1[i]=fatseg_mask_final_R1[i]*image[i]\n",
    "        fatseg_final_R2[i]=fatseg_mask_final_R2[i]*image[i]\n",
    "    \n",
    "    return fatseg_mask_final_R1,fatseg_final_R1,fatseg_mask_final_R2,fatseg_final_R2\n",
    "\n",
    "\n",
    "def overlay_TWO_SEP(f1,f2,image):\n",
    "    '''\n",
    "    This function overlays the segmented fat regions f1 and f2 on the original image image for visualization purposes. \n",
    "    It plots each slice of the image along with the overlaid fat regions in separate subplots\n",
    "    '''\n",
    "    def overlayTWO_1(image, f1,f2,x):    \n",
    "        overlay = np.ma.masked_where(f1 == 0, f1)\n",
    "        overlay2= np.ma.masked_where(f2 == 0, f2)\n",
    "        axs[x,1].imshow(image, cmap=\"bone\")\n",
    "        axs[x,1].imshow(overlay, cmap=\"autumn\", vmin=0, vmax=1)\n",
    "        axs[x,1].imshow(overlay2, cmap=\"bwr\", vmin=0, vmax=1, alpha=1)\n",
    "        axs[x, 1].set_title(f\"slice {i+1}\", fontsize=12)\n",
    "    fig, axs = plt.subplots(j, 2, figsize=(12, 100))\n",
    "    for i in range(j):\n",
    "        axs[i,0].imshow(image[i], cmap='bone')\n",
    "        overlayTWO_1(image[i],f1[i], f2[i],i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Quality check and tag export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_buttons(ID,slic):\n",
    "    '''\n",
    "    This function is used to create buttons to identify which masks need manual adjustments\n",
    "    '''\n",
    "    ID = ID\n",
    "    slic = slic\n",
    "\n",
    "    def record_click(button_clicked):\n",
    "        # Create a dictionary with the data to be recorded\n",
    "        new_entry = {\n",
    "            'ID': ID,\n",
    "            'slice': slic,\n",
    "            'Button Clicked': button_clicked\n",
    "        }\n",
    "\n",
    "        # Append the new entry to the DataFrame\n",
    "        data.loc[len(data)] = new_entry\n",
    "    # Create a button for each case\n",
    "    button_a = widgets.Button(description=\"Good\")\n",
    "    button_b = widgets.Button(description=\"Overshoot\")\n",
    "    button_c = widgets.Button(description=\"Undershoot\")\n",
    "    button_d = widgets.Button(description=\"Incorrect Thigh Cut\")\n",
    "\n",
    "    # Attach the click event handlers for buttons A and B\n",
    "    def button_a_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Good\"\n",
    "        record_click(button_clicked)\n",
    "\n",
    "    def button_b_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Overshoot\"\n",
    "        record_click(button_clicked)\n",
    "\n",
    "    def button_c_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Undershoot\"\n",
    "        record_click(button_clicked)\n",
    "\n",
    "    def button_d_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Incorrect Thigh Cut\"\n",
    "        record_click(button_clicked)\n",
    "        \n",
    "    button_a.on_click(button_a_click)\n",
    "    button_b.on_click(button_b_click)\n",
    "    button_c.on_click(button_c_click)\n",
    "    button_d.on_click(button_d_click)\n",
    "\n",
    "    # Display the buttons\n",
    "    display(button_a)\n",
    "    display(button_b)\n",
    "    display(button_c)\n",
    "    display(button_d)\n",
    "\n",
    "    # Initialize the button_clicked variable\n",
    "    button_clicked = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check(image1, image2, ID):\n",
    "    '''\n",
    "    This function overlays 2 images to check the quality of the masks created and identify those that need manual edits\n",
    "    '''\n",
    "    def check(im, to_overlay):\n",
    "        overlay = np.ma.masked_where(to_overlay == 0, to_overlay)\n",
    "        plt.imshow(im, cmap=\"bone\")\n",
    "        plt.imshow(overlay, cmap=\"hsv\", vmin=0, vmax=1, alpha=0.5)\n",
    "        plt.title(f\"{ID}\", fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "    j = len(image1)  \n",
    "\n",
    "    for i in range(j):\n",
    "        check(image1[i], image2[i])\n",
    "\n",
    "        quality_buttons(ID,i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import errno \n",
    "import shutil\n",
    "\n",
    "def writetag(drive):\n",
    "    '''\n",
    "    This function generates a tag file and saves it to a specified directory. \n",
    "    The tag file contains metadata and pixel data extracted from an input image array\n",
    "    '''\n",
    "    \n",
    "    volsitk.GetOrigin()\n",
    "    epais = 0.0 \n",
    "    org_x = volsitk.GetOrigin()[0]\n",
    "    org_y = volsitk.GetOrigin()[1]\n",
    "    org_z = 0 \n",
    "    org_x, org_y, org_z\n",
    "    dimx = volsitk.GetSize()[0]\n",
    "    dimy = volsitk.GetSize()[1]\n",
    "    dimz = 1\n",
    "    inc_x = inc_y = 1\n",
    "    \n",
    "    dir_h_x=1.0000\n",
    "    dir_h_y=0.0000\n",
    "    dir_h_z=0.0000\n",
    "    dir_v_x=0.0000\n",
    "    dir_v_y=1.0000\n",
    "    dir_v_z=0.0000\n",
    "\n",
    "    imfmscb = []\n",
    "    for j in range(imfbonemsc.shape[0]):\n",
    "        for i in range(imfbonemsc.shape[1]): \n",
    "            imfmscb.append(imfbonemsc[j,i])\n",
    "    imfmscbytes = bytes(np.uint8(np.array(imfmscb)))\n",
    "\n",
    "    serdesc = \"Exp_\"+stid\n",
    "    outtag = os.path.join(drive, \"ToSegmentBW\", stid, \"OutputTags\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(outtag)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise   \n",
    "    file = open(outtag+\"\\\\\"+serdesc+\"_org\"+str(slc)+\".tag\", \"wb\")\n",
    "\n",
    "    header = \\\n",
    "    \"x:\"+str(dimx)+\" \"+ \\\n",
    "    \"y:\"+str(dimy)+\" \"+ \\\n",
    "    \"z:\"+str(dimz)+\" \"+ \\\n",
    "    \"type:BYTE \\n\" + \\\n",
    "    \"org_x:\"+str(org_x)+\" \"+ \\\n",
    "    \"org_y:\"+str(org_y)+\" \"+ \\\n",
    "    \"org_z:\"+str(org_z)+\" \\n\"+ \\\n",
    "    \"inc_x:\"+str(inc_x)+\" \"+ \\\n",
    "    \"inc_y:\"+str(inc_y)+\" \"+ \\\n",
    "    \"epais:\"+str(epais)+\" \\n\"+ \\\n",
    "    \"dir_h_x:1.0000     dir_h_y:0.0000     dir_h_z:0.0000     \\n\"+ \\\n",
    "    \"dir_v_x:0.0000     dir_v_y:1.0000     dir_v_z:0.0000     \\n\"+ \\\n",
    "    \"\\x0c\"\n",
    "\n",
    "    headerb = header.encode()\n",
    "    file.write(headerb)\n",
    "    file.write(imfmscbytes)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def writetofolder(drive, output_filename):\n",
    "    '''\n",
    "    This function copies a target range of original DICOM images to a specified directory and renames them accordingly\n",
    "    '''\n",
    "    root2 = os.path.join(drive, \"ToSegmentBW\", stid)\n",
    "    outpath2 = os.path.join(root2, \"OutputTags\")\n",
    "    try:\n",
    "        os.makedirs(outpath2)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    \n",
    "    origdcm_fn = output_filename\n",
    "    shutsrc = os.path.join(origdcm_fn) ### check syntax \n",
    "    serdesc = \"Exp_\"+stid\n",
    "    shutdst = os.path.join(outpath2, serdesc+\"_org\"+str(slc)+'.dcm')\n",
    "    shutil.copy(shutsrc, shutdst)\n",
    "        \n",
    "    return drive, root2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import corrected tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import logging\n",
    "import re\n",
    "import vtk\n",
    "import vtk.util.numpy_support as VN\n",
    "\n",
    "\n",
    "def tagtoarray(path):\n",
    "    '''\n",
    "    This function reads tag files from a specified directory, extracts metadata, and converts the voxel data into a NumPy array\n",
    "    '''\n",
    "    i = 0\n",
    "    count=0\n",
    "    imagetag= []\n",
    "    tagarray0 = []\n",
    "    tagsln0 = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.find('tag') > 0:\n",
    "            filename=os.path.join(path, file)\n",
    "\n",
    "            # get slice #\n",
    "            slpos = file.find(\".dcm.tag\")\n",
    "            if slpos > 1 and file[slpos-1].isdigit():\n",
    "                # Collect all consecutive digits preceding \".dcm.tag\"\n",
    "                digit_str = \"\"\n",
    "                index = slpos - 1\n",
    "\n",
    "                while index >= 0 and file[index].isdigit():\n",
    "                    digit_str = file[index] + digit_str\n",
    "                    index -= 1\n",
    "\n",
    "                slicenum = int(digit_str.replace(\"_\", \"\"))\n",
    "                tagsln0.append(slicenum)\n",
    "            \n",
    "            endOfHeaderChar = '\\x0c'\n",
    "\n",
    "            with open(filename) as f:\n",
    "                text = f.read(1000)  \n",
    "\n",
    "                if not endOfHeaderChar in text:\n",
    "                # end of header character is not found, it is not a valid tag file\n",
    "                   print(\"This is an invalid tag file.\")\n",
    "                else:\n",
    "                    header = text.split(endOfHeaderChar)[0]\n",
    "                    fields = re.split('[\\n\\t\\r ]+', header)\n",
    "\n",
    "                    dims = [0, 0, 0]\n",
    "                    origin = [0.0, 0.0, 0.0]\n",
    "                    spacing = [1.0, 1.0, 1.0]\n",
    "                    axisX = [1.0, 0.0, 0.0]\n",
    "                    axisY = [0.0, 1.0, 0.0]\n",
    "\n",
    "                    for field in fields:\n",
    "                      if not field:\n",
    "                        continue\n",
    "                      name, value = field.split(':')\n",
    "                      if name == 'x':\n",
    "                        dims[0] = int(value)\n",
    "                      elif name == 'y':\n",
    "                        dims[1] = int(value)\n",
    "                      elif name == 'z':\n",
    "                        dims[2] = int(value)\n",
    "                      elif name == 'org_x':\n",
    "                        origin[0] = float(value)\n",
    "                      elif name == 'org_y':\n",
    "                        origin[1] = float(value)\n",
    "                      elif name == 'org_z':\n",
    "                        origin[2] = float(value)\n",
    "                      elif name == 'inc_x':\n",
    "                        spacing[0] = float(value)\n",
    "                      elif name == 'inc_y':\n",
    "                        spacing[1] = float(value)\n",
    "                      elif name == 'epais':\n",
    "                        spacing[2] = float(value)\n",
    "                      elif name == 'dir_h_x':\n",
    "                        axisX[0] = float(value)\n",
    "                      elif name == 'dir_h_y':\n",
    "                        axisX[1] = float(value)\n",
    "                      elif name == 'dir_h_z':\n",
    "                        axisX[2] = float(value)\n",
    "                      elif name == 'dir_v_x':\n",
    "                        axisY[0] = float(value)\n",
    "                      elif name == 'dir_v_y':\n",
    "                        axisY[1] = float(value)\n",
    "                      elif name == 'dir_v_z':\n",
    "                        axisY[2] = float(value)\n",
    "                      elif name == 'type':\n",
    "                        # type is BYTE in tag files\n",
    "                        if value != 'BYTE':\n",
    "                          logging.warning('Voxel type in tag file is expected to be BYTE')\n",
    "                      elif name == 'uid':\n",
    "                        pass\n",
    "                      elif name == 'chksum':\n",
    "                        pass\n",
    "\n",
    "                    headerInfo = {\n",
    "                        'dims': dims,\n",
    "                        'origin': origin,\n",
    "                        'spacing': spacing,\n",
    "                        'axisX': axisX,\n",
    "                        'axisY': axisY,\n",
    "                        'headerSize': len(header)+1\n",
    "                        }\n",
    "\n",
    "\n",
    "                filePath=filename\n",
    "\n",
    "                scalarType = vtk.VTK_CHAR\n",
    "                numberOfComponents = 1\n",
    "                sliceSize = headerInfo['dims'][0] * headerInfo['dims'][1] * vtk.vtkDataArray.GetDataTypeSize(scalarType) * numberOfComponents\n",
    "                headerSize = headerInfo['headerSize']\n",
    "                totalFilesize = os.path.getsize(filePath)\n",
    "                voxelDataSize = totalFilesize - headerSize\n",
    "                maxNumberOfSlices = int(voxelDataSize/sliceSize)\n",
    "                if headerInfo['dims'][2] > maxNumberOfSlices:\n",
    "                    logging.error(f\"Tag file is expected to contain {headerInfo['dims'][2]} slices but it has only {maxNumberOfSlices}\")\n",
    "\n",
    "                reader = vtk.vtkImageReader2()\n",
    "                reader.SetFileName(filePath)\n",
    "                reader.SetFileDimensionality(3)\n",
    "                reader.SetDataExtent(0, headerInfo['dims'][0]-1, 0, headerInfo['dims'][1]-1, 0, headerInfo['dims'][2]-1)\n",
    "      \n",
    "                reader.SetDataScalarType(scalarType)\n",
    "                reader.SetNumberOfScalarComponents(numberOfComponents)\n",
    "                reader.SetHeaderSize(headerSize)\n",
    "                reader.SetFileLowerLeft(True) # to match input from NRRD reader\n",
    "                reader.Update()\n",
    "\n",
    "\n",
    "\n",
    "                imageout = reader.GetOutput()\n",
    "                rows, cols, sl = imageout.GetDimensions()\n",
    "\n",
    "                sc = imageout.GetPointData().GetScalars()\n",
    "                a = VN.vtk_to_numpy(sc)\n",
    "                a = a.reshape(sl,cols,rows)\n",
    "\n",
    "                imagetag.append([])\n",
    "\n",
    "                imagetag[count] = a[0]\n",
    "\n",
    "\n",
    "                \n",
    "                count+=1\n",
    "\n",
    "                \n",
    "    return imagetag, tagsln0, axisX, axisY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Running ITSA with corrected tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOG(filepath):\n",
    "    '''\n",
    "    This function reads a DICOM file from the specified filepath and returns the pixel data as a NumPy array\n",
    "    '''\n",
    "    dicom_data = pydicom.dcmread(filepath, force=True)\n",
    "    # Extract the pixel data as a NumPy array\n",
    "    pixel_array = dicom_data.pixel_array\n",
    "    return pixel_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc2(F1_mask,F1_im,F2_mask,F2_im,BF_mask,BF_im,roi_mask,roi_im):\n",
    "    '''\n",
    "    This function calculates various metrics related to fat and muscle areas and volumes within specified regions of interest (ROIs). \n",
    "    It computes areas, volumes, percentages, and correction factors based on provided masks and intensity images, returning a comprehensive DataFrame containing the calculated metrics for each slice of the image data\n",
    "    '''\n",
    "    ROI_MuscFatAreaPix_L=[]\n",
    "    ROI_MuscFatAreaMM_L=[]\n",
    "    ROI_MuscFatVolMM_L=[]\n",
    "    F1_AreaPix_slice=[]\n",
    "    F1_AreaMM_slice=[]\n",
    "    Musc1AreaPix_slice=[]\n",
    "    Musc1AreaMM_slice=[]\n",
    "    F1_Perc_slice=[]\n",
    "    F1_VolMM_slice=[]\n",
    "    Musc1VolMM_slice=[]\n",
    "    F2_AreaPix_slice=[]\n",
    "    F2_AreaMM_slice=[]\n",
    "    Musc2AreaPix_slice=[]\n",
    "    Musc2AreaMM_slice=[]\n",
    "    F2Perc_slice=[]\n",
    "\n",
    "    F2VolMM_slice=[]\n",
    "    F2_MuscVolMMc=[]\n",
    "    Musc2VolMM_slice=[]\n",
    "    FatSegI_F1_slice=[]\n",
    "    FatSegI_F2_slice=[]\n",
    "    cfactor_slice=[]\n",
    "    FatVolCombined_slice=[]\n",
    "    F2_VolMM_c_slice=[]\n",
    "    FatVolCombined_C_slice=[] \n",
    "    F2_Perc_c_slice=[]\n",
    "    FatPercCombined_C_slice=[]\n",
    "    \n",
    "    BFAreaPix_slice=[]\n",
    "    BF_AreaMM_slice=[]\n",
    "    Musc3AreaPix_slice=[]\n",
    "    Musc3AreaMM_slice=[]\n",
    "    BF_Perc_NOTc_slice=[]\n",
    "    BF_VolMM_slice=[]\n",
    "    Musc3VolMM_slice=[]\n",
    "    Musc3VolMM_slice_c=[]\n",
    "  \n",
    "    FatVolCombined_C_all=[]\n",
    "    MuscVolCombined_all=[]\n",
    "    \n",
    "    FatPercAvgCombined_all=[] \n",
    "\n",
    "    for i in range(j):\n",
    "        ROI_MuscFatAreaPix_L.append([])\n",
    "        ROI_MuscFatAreaMM_L.append([])\n",
    "        ROI_MuscFatVolMM_L.append([])\n",
    "        F1_AreaPix_slice.append([])\n",
    "        F1_AreaMM_slice.append([])\n",
    "        Musc1AreaPix_slice.append([])\n",
    "        Musc1AreaMM_slice.append([])\n",
    "        F1_Perc_slice.append([])\n",
    "        F1_VolMM_slice.append([])\n",
    "        Musc1VolMM_slice.append([])\n",
    "        F2_AreaPix_slice.append([])\n",
    "        F2_AreaMM_slice.append([])\n",
    "        Musc2AreaPix_slice.append([])\n",
    "        Musc2AreaMM_slice.append([])\n",
    "        F2Perc_slice.append([])\n",
    "        FatPercCombined_C_slice.append([]) \n",
    "\n",
    "        F2VolMM_slice.append([])\n",
    "        F2_MuscVolMMc.append([])\n",
    "        Musc2VolMM_slice.append([])\n",
    "        FatSegI_F1_slice.append([])\n",
    "        FatSegI_F2_slice.append([])\n",
    "        cfactor_slice.append([])\n",
    "        FatVolCombined_slice.append([])\n",
    "        F2_VolMM_c_slice.append([])\n",
    "        FatVolCombined_C_slice.append([])\n",
    "        F2_Perc_c_slice.append([])\n",
    "\n",
    "        BFAreaPix_slice.append([])\n",
    "        BF_AreaMM_slice.append([])\n",
    "        Musc3AreaPix_slice.append([])\n",
    "        Musc3AreaMM_slice.append([])\n",
    "        BF_Perc_NOTc_slice.append([])\n",
    "        BF_VolMM_slice.append([])\n",
    "        Musc3VolMM_slice.append([])\n",
    "        Musc3VolMM_slice_c.append([])\n",
    "    \n",
    "        FatVolCombined_C_all.append([]) \n",
    "        MuscVolCombined_all.append([])\n",
    "        \n",
    "        FatPercAvgCombined_all.append([])\n",
    "    #MUSCLE + FAT AREA\n",
    "        ROI_MuscFatAreaPix=np.sum(roi_mask[i]>0)   \n",
    "        ROI_MuscFatAreaMM=ROI_MuscFatAreaPix*im_spacing[0]*im_spacing[1] \n",
    "        ROI_MuscFatVolMM=ROI_MuscFatAreaMM*im_spacing[2]\n",
    "        \n",
    "    #THRESHOLD 1 FAT\n",
    "        musc_no_F1=(roi_mask[i]-F1_mask[i])*roi_im[i] \n",
    "\n",
    "        #FAT AREA\n",
    "        F1_AreaPix=np.sum(F1_mask[i]>0) \n",
    "        F1_AreaMM=F1_AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #MUSCLE AREA\n",
    "        Musc1AreaPix=np.sum(musc_no_F1>0)\n",
    "        Musc1AreaMM=Musc1AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #FAT PERCENTAGE\n",
    "        F1_Perc=F1_AreaPix*100/ROI_MuscFatAreaPix \n",
    "        #VOLUME OF EACH SLICE\n",
    "        F1_VolMM=F1_AreaMM*im_spacing[2] #multiply by z -slice thickness\n",
    "        Mus1cVolMM=Musc1AreaMM*im_spacing[2]\n",
    "\n",
    "    #THRESHOLD 2 FAT\n",
    "        #NOT including threshold 1 fat----------------------------------------------\n",
    "        musc_no_F2=(roi_mask[i]-F2_mask[i])*roi_im[i]  \n",
    "\n",
    "        #FAT AREA\n",
    "        F2_AreaPix=np.sum(F2_mask[i] >0)\n",
    "        F2_AreaMM=F2_AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #MUSCLE AREA\n",
    "        Musc2AreaPix=np.sum(musc_no_F2>0)\n",
    "        Musc2AreaMM=Musc2AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #FAT PERCENTAGE\n",
    "        F2Perc=F2_AreaPix*100/ROI_MuscFatAreaPix \n",
    "        #VOLUME OF EACH SLICE\n",
    "        F2VolMM=F2_AreaMM*im_spacing[2]\n",
    "        Musc2VolMM=Musc2AreaMM*im_spacing[2]\n",
    "        \n",
    "    #FINAL FAT using Threshold 2 ----------------------------------------------------\n",
    "        musc_no_BF=(roi_mask[i]-BF_mask[i])*roi_im[i]\n",
    "\n",
    "        #FAT AREA -F2 here NOT CORRECTED \n",
    "        BFAreaPix=np.sum(BF_mask[i]>0) \n",
    "        BF_AreaMM=BFAreaPix*im_spacing[0]*im_spacing[1]\n",
    "        \n",
    "        #MUSCLE AREA\n",
    "        Musc3AreaPix=np.sum(musc_no_BF>0)\n",
    "        Musc3AreaMM=Musc3AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        \n",
    "        #FAT PERCENTAGE -F2 here NOT CORRECTED \n",
    "        BF_Perc_NOTc=BFAreaPix*100/ROI_MuscFatAreaPix \n",
    "        \n",
    "        #VOLUME OF EACH SLICE\n",
    "        BF_VolMM=BF_AreaMM*im_spacing[2] \n",
    "        Musc3VolMM=Musc3AreaMM*im_spacing[2]\n",
    "        \n",
    "      \n",
    "    #FAT CORRECTION - break\n",
    "        if np.sum(F2_im[i] >0)==0: #if there is NO R2 refined fat just take th1 loop fat\n",
    "            #print(f\"{ID} Slice {i+1} no R2 refined\")\n",
    "            #keep vars for final table\n",
    "            F1_im_masked=np.ma.masked_where(F1_im[i]==0,F1_im[i]) \n",
    "            F2_im_masked=np.ma.masked_where(F2_im[i] ==0,F2_im[i]) \n",
    "            FatSegI_F1=np.mean(F1_im_masked) \n",
    "            FatSegI_F2=np.mean(F2_im_masked)\n",
    "            cfactor=9999\n",
    "            FatVolCombined=9999\n",
    "            F2_VolMM_c=9999\n",
    "            F2_Perc_c=9999\n",
    "            \n",
    "            #take F1 values only\n",
    "            FatVolCombined_C=F1_VolMM \n",
    "            FatPercCombined_C=F1_Perc\n",
    "            \n",
    "        else:\n",
    "\n",
    "            F1_im_masked=np.ma.masked_where(F1_im[i]==0,F1_im[i]) \n",
    "            F2_im_masked=np.ma.masked_where(F2_im[i] ==0,F2_im[i])\n",
    "            FatSegI_F1=np.mean(F1_im_masked) \n",
    "            FatSegI_F2=np.mean(F2_im_masked)\n",
    "            cfactor=(FatSegI_F2/FatSegI_F1) #fat correction factor\n",
    "    \n",
    "        \n",
    "            FatVolCombined=F1_VolMM+F2VolMM #final volume not corrected\n",
    "            F2_VolMM_c=F2VolMM*cfactor \n",
    "            FatVolCombined_C=F1_VolMM+F2_VolMM_c #final volume corrected\n",
    "            \n",
    "            F2_Perc_c=F2Perc*cfactor \n",
    "            FatPercCombined_C=F1_Perc+F2_Perc_c \n",
    "            \n",
    "        ROI_MuscFatAreaPix_L[i]=ROI_MuscFatAreaPix\n",
    "        ROI_MuscFatAreaMM_L[i]=ROI_MuscFatAreaMM\n",
    "        ROI_MuscFatVolMM_L[i]=ROI_MuscFatVolMM \n",
    "        F1_AreaPix_slice[i]=F1_AreaPix\n",
    "        F1_AreaMM_slice[i]=F1_AreaMM\n",
    "        Musc1AreaPix_slice[i]= Musc1AreaPix\n",
    "        Musc1AreaMM_slice[i]=Musc1AreaMM\n",
    "        F1_Perc_slice[i]=F1_Perc \n",
    "        F1_VolMM_slice[i]=F1_VolMM \n",
    "        Musc1VolMM_slice[i]=Mus1cVolMM\n",
    "        F2_AreaPix_slice[i]=F2_AreaPix\n",
    "        F2_AreaMM_slice[i]=F2_AreaMM\n",
    "        Musc2AreaPix_slice[i]=Musc2AreaPix\n",
    "        Musc2AreaMM_slice[i]=Musc2AreaMM\n",
    "        F2Perc_slice[i]=F2Perc\n",
    "        FatPercCombined_C_slice[i]=FatPercCombined_C \n",
    "        \n",
    "        F2VolMM_slice[i]=F2VolMM\n",
    "        F2_MuscVolMMc[i] = F2VolMM * (1-cfactor) \n",
    "        Musc2VolMM_slice[i]=Musc2VolMM\n",
    "        FatSegI_F1_slice[i]=FatSegI_F1\n",
    "        FatSegI_F2_slice[i]=FatSegI_F2\n",
    "        cfactor_slice[i]=cfactor\n",
    "        FatVolCombined_slice[i]=FatVolCombined\n",
    "        F2_VolMM_c_slice[i]=F2_VolMM_c\n",
    "        FatVolCombined_C_slice[i]=FatVolCombined_C \n",
    "        F2_Perc_c_slice[i]=F2_Perc_c\n",
    "        FatPercCombined_C_slice[i]=FatPercCombined_C\n",
    "\n",
    "        BFAreaPix_slice[i]=BFAreaPix\n",
    "        BF_AreaMM_slice[i]=BF_AreaMM\n",
    "        Musc3AreaPix_slice[i]=Musc3AreaPix\n",
    "        Musc3AreaMM_slice[i]=Musc3AreaMM\n",
    "        BF_Perc_NOTc_slice[i]=BF_Perc_NOTc\n",
    "        BF_VolMM_slice[i]=BF_VolMM\n",
    "        Musc3VolMM_slice[i]=Musc3VolMM #not corrected  \n",
    "        Musc3VolMM_slice_c[i]= Mus1cVolMM + (F2VolMM * (1-cfactor)) \n",
    "        \n",
    "        FatVolCombined_C_all[i]=sum(FatVolCombined_C_slice) \n",
    "        MuscVolCombined_all[i]=sum(Musc3VolMM_slice)\n",
    "        \n",
    "        FatPercAvgCombined_all[i]=mean(FatPercCombined_C_slice)\n",
    "        \n",
    "        \n",
    "    slice_num=[]\n",
    "    slice_num=list(range(1,j+1))  \n",
    "    \n",
    "    slice_num2=(list(reversed(slice_num)))  \n",
    "\n",
    "    OG_slice_num=slice_num\n",
    "    \n",
    "    \n",
    "    #table for ALL data\n",
    "    data = {'ID': ID,'Anatomy': anatomy, 'Slice': slice_num,'ROI_MuscFatAreaPix':ROI_MuscFatAreaPix_L, 'ROI_MuscFatAreaMM':ROI_MuscFatAreaMM_L, 'ROI_MuscFatVolMM': ROI_MuscFatVolMM_L,\n",
    "            'F1_AreaPix':F1_AreaPix_slice,'F1_AreaMM':F1_AreaMM_slice,'F1_MuscAreaPix':Musc1AreaPix_slice,'F1_MuscAreaMM':Musc1AreaMM_slice,\n",
    "            'F1_Perc':F1_Perc_slice,'F1_VolMM':F1_VolMM_slice,'F1_MuscVolMM':Musc1VolMM_slice, \n",
    "            'F2_AreaPix':F2_AreaPix_slice,'F2_AreaMM':F2_AreaMM_slice,'Musc_noF2_AreaPix':Musc2AreaPix_slice,'musc_no_F2_AreaMM':Musc2AreaMM_slice,\n",
    "            'F2_Perc_NOTc':F2Perc_slice,'F2_VolMM_NOTc':F2VolMM_slice,'F2_MuscVolMM':Musc2VolMM_slice,\n",
    "            'F1_Intensity':FatSegI_F1_slice,'F2_Intensity':FatSegI_F2_slice,\n",
    "            'F2_cfactor':cfactor_slice,'BF_FatVol_NOTc':FatVolCombined_slice,'F2_VolMM_c':F2_VolMM_c_slice,'F2_MuscVolMMc':F2_MuscVolMMc,\n",
    "            'BF_FatVol_c':FatVolCombined_C_slice,\n",
    "            'F2_Perc_c':F2_Perc_c_slice,'BF_Perc_c':FatPercCombined_C_slice,\n",
    "          \n",
    "            'BF_AreaPix_NOTc':BFAreaPix_slice,'BF_AreaMM^2_NOTc':BF_AreaMM_slice,'Musc_noBF_AreaPix_NOTc':Musc3AreaPix_slice,\n",
    "            'musc_no_BF_AreaMM_NOTc':Musc3AreaMM_slice,'BF_Perc_NOTc':BF_Perc_NOTc_slice,\n",
    "            'BF_VolMM_NOTc':BF_VolMM_slice,'Musc_noBF_VolMM_NOTc':Musc3VolMM_slice,\n",
    "            'TOTAL_FatVol_c':FatVolCombined_C_all,'TOTAL_MuscVol':MuscVolCombined_all,'TOTAL_MuscVol_c':Musc3VolMM_slice_c}  \n",
    "\n",
    "    data_table = pd.DataFrame(data, columns = ['ID','Anatomy','Slice','ROI_MuscFatAreaPix','ROI_MuscFatAreaMM', 'ROI_MuscFatVolMM',\n",
    "                                                    'F1_AreaPix','F1_AreaMM','F1_MuscAreaPix','F1_MuscAreaMM','F1_Perc','F1_VolMM','F1_MuscVolMM', \n",
    "                                                    'F2_AreaPix','F2_AreaMM','Musc_noF2_AreaPix','musc_no_F2_AreaMM','F2_Perc_NOTc','F2_VolMM_NOTc',\n",
    "                                                    'F1_Intensity','F2_Intensity','F2_cfactor','BF_FatVol_NOTc','F2_VolMM_c','F2_MuscVolMMc','BF_FatVol_c','F2_Perc_c','BF_Perc_c',\n",
    "                                                    \n",
    "                                                    'BF_AreaPix_NOTc','BF_AreaMM^2_NOTc','Musc_noBF_AreaPix_NOTc','musc_no_BF_AreaMM_NOTc','BF_Perc_NOTc','BF_VolMM_NOTc','Musc_noBF_VolMM_NOTc','TOTAL_FatVol_c','TOTAL_MuscVol_c'])\n",
    "\n",
    "\n",
    "    print(f'{ID} total fatvol= {sum(FatVolCombined_C_slice)}\\n')\n",
    "\n",
    "    \n",
    "    Total_FatVol=sum(FatVolCombined_C_slice) \n",
    "    Total_MuscVol=sum(Musc3VolMM_slice)\n",
    "    TotalMuscFatVol=Total_FatVol+Total_MuscVol #corrected  \n",
    "    Total_FatPerc=Total_FatVol/TotalMuscFatVol\n",
    "    \n",
    "    return data_table  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_sheet(to_append,excel_path,sheetname):\n",
    "    '''\n",
    "    This function reads a specific sheetname from an Excel file and concatenates the contents of this sheet with \"to_append\", ensuring that the index is ignored during concatenation to maintain a continuous index.\n",
    "    '''\n",
    "    df_excel = pd.read_excel((excel_path),sheet_name=sheetname) #read specific sheet name\n",
    "    result = pd.concat([df_excel,to_append], ignore_index=True) #concatenate sheet contents with new df\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

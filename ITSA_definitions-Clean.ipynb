{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Users only need to make changes to the drive variable in the functions \"writetofolder\" and \"writetag\". Remaining definitions require no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import all libraries needed\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom as dicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.bool = np.bool_ \n",
    "np.float = np.float_\n",
    "import SimpleITK as sitk\n",
    "import sys\n",
    "import skimage\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage import data, io, img_as_ubyte,filters\n",
    "from skimage.measure import label\n",
    "import matplotlib as mpl\n",
    "import imutils \n",
    "from typing import Any\n",
    "from PIL import ImageEnhance \n",
    "from PIL import Image\n",
    "import math \n",
    "%matplotlib inline\n",
    "mpl.rc('image', interpolation='none')\n",
    "plt.rcParams['figure.figsize'] = (7.0, 7.0)\n",
    "from astropy.table import QTable \n",
    "from tabulate import tabulate\n",
    "from statistics import mean \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import *\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getimages(image):\n",
    "    \"\"\"\n",
    "    This function takes dcm images and converts to array that is then normalized  \n",
    "    \"\"\"\n",
    "    Ivol=sitk.GetArrayFromImage(image[:image.GetSize()[0]//2,:,:])#get all slices #left, right, top, top-bottom \n",
    "    Ivol8=np.zeros([Ivol.shape[0], Ivol.shape[1], Ivol.shape[2]], dtype='uint8') \n",
    "    for i in range(Ivol.shape[0]):\n",
    "        Ivol8[i]=cv2.normalize(src=Ivol[i], dst=None, alpha=0.0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    j=Ivol8[0].shape\n",
    "    plotx=5\n",
    "    return Ivol8,j,plotx\n",
    "            \n",
    "def stackimages(image, x=0, y=0): \n",
    "    \"\"\"\n",
    "    This function displays all 15 slices at once (5 by 3)\n",
    "    \"\"\"\n",
    "    plotx = 5\n",
    "    fig, axs = plt.subplots ((j//plotx), plotx, figsize=(20,10)) \n",
    "    for i in range(j):\n",
    "        axs[y, x].imshow(image[i], cmap='bone')\n",
    "        axs[y, x].set_title(f\"slice {i+1}\", fontsize=12) \n",
    "        axs[y,x].axis(\"off\")\n",
    "        if x <(plotx-1):\n",
    "            x+=1\n",
    "        else:\n",
    "            x=0\n",
    "            y+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackimages_w_filename(image, x=0, y=0):\n",
    "    \"\"\"\n",
    "    This function displays all 15 slices at once with the corresponding filename (5 by 3)\n",
    "    \"\"\"\n",
    "    plotx = 5\n",
    "    fig, axs = plt.subplots ((j//plotx), plotx, figsize=(20,10)) \n",
    "    for i in range(j):\n",
    "        axs[y, x].imshow(image[i], cmap='bone')\n",
    "        axs[y, x].set_title(f\"{files}: slice {i+1}\", fontsize=12)\n",
    "        axs[y,x].axis(\"off\")\n",
    "        if x <(plotx-1):\n",
    "            x+=1\n",
    "        else:\n",
    "            x=0\n",
    "            y+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Inhomogeneity Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions for image correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_numpy_DICOM_volume\n",
    "def get_numpy_DICOM_volume(image_path: str) -> np.array:\n",
    "    file_names = os.listdir(image_path)\n",
    "\n",
    "    # Load DICOM images and extract z-coordinates\n",
    "    slices = []\n",
    "    for file_name in file_names:\n",
    "        ds = pydicom.dcmread(os.path.join(image_path, file_name))\n",
    "        slices.append((ds.ImagePositionPatient[2], ds.pixel_array))\n",
    "\n",
    "    # Sort slices by z-coordinate\n",
    "    slices.sort()\n",
    "\n",
    "    # Stack 2D pixel arrays into 3D numpy array\n",
    "    volume = np.stack([slice[1] for slice in slices], axis=-1)\n",
    "    return volume\n",
    "\n",
    "# show_diff\n",
    "def show_diff(orig_read_data: Any, alt_read_data: Any, show_image: bool = True, show_hist: bool = False) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    This function shows the differences between 2 images in terms of removed pixels (painted black), added pixels (black pixels painted some grey scale)\n",
    "    and shifted pixels (greyscale pixels whos value changes)    \n",
    "    \"\"\"\n",
    "    if type(orig_read_data) is str:\n",
    "        ds_orig = pydicom.dcmread(orig_read_data).pixel_array\n",
    "    else:\n",
    "        ds_orig = orig_read_data\n",
    "    if type(alt_read_data) is str:\n",
    "        ds_alt = pydicom.dcmread(alt_read_data).pixel_array\n",
    "    else:\n",
    "        ds_alt = alt_read_data\n",
    "    \n",
    "    orig_img = Image.fromarray(ds_orig)\n",
    "    alt_img = Image.fromarray(ds_alt)\n",
    "    alt_img = alt_img.convert(\"L\")\n",
    "    orig_img = orig_img.convert(\"L\")\n",
    "\n",
    "    orig_numpydata = np.asarray(orig_img)\n",
    "    alt_numpydata = np.asarray(alt_img)\n",
    "    diff_array = np.zeros(\n",
    "        (orig_numpydata.shape[0], orig_numpydata.shape[1], 3))\n",
    "    color_counts = {\"Red\": 0, \"Green\": 0, \"Yellow\": 0}\n",
    "\n",
    "    for i in range(orig_numpydata.shape[0]):\n",
    "        for j in range(orig_numpydata.shape[1]):\n",
    "            if orig_numpydata[i, j] == alt_numpydata[i, j]:  \n",
    "                diff_array[i, j] = [0, 0, 0]\n",
    "            # non-black pixel was painted black (removed)\n",
    "            elif (orig_numpydata[i, j]) != 0 and (alt_numpydata[i, j]) == 0:\n",
    "                diff_array[i, j] = [255, 0, 0]\n",
    "                color_counts[\"Red\"] += 1\n",
    "            # pixel color was changed (altered)\n",
    "            elif (orig_numpydata[i, j]) != 0 and (alt_numpydata[i, j]) != 0:\n",
    "                diff_array[i, j] = [255, 255, 0]\n",
    "                color_counts[\"Yellow\"] += 1\n",
    "            # black pixel was painted a differnt color (added)\n",
    "            elif (orig_numpydata[i, j]) == 0 and (alt_numpydata[i, j]) != 0:\n",
    "                diff_array[i, j] = [0, 255, 0]\n",
    "                color_counts[\"Green\"] += 1\n",
    "    txt = \"Red: pixel value became 0 (black),\\n Green: pixel 0 (black) changed to some greyscale value > 0,\\n Yellow: one non-0 (non-black) greyscale value changed to another non-0 (non-black) greyscale value\"\n",
    "    if show_image:\n",
    "        overlay = np.ma.masked_where(diff_array == 0, diff_array)\n",
    "        plt.figtext(0.5, 0.01, txt, wrap=True,\n",
    "                    horizontalalignment='center', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(orig_img, cmap=\"bone\", vmin=0, vmax=2200)\n",
    "        plt.imshow(overlay, vmin=1, vmax=10, alpha=0.5)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    if show_hist:\n",
    "        colors = list(color_counts.keys())\n",
    "        values = list(color_counts.values())\n",
    "        # creating the bar plot\n",
    "        plt.bar(colors, values, color=colors,\n",
    "                width=0.4)\n",
    "\n",
    "        plt.xlabel(txt, wrap=True, fontsize=8)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    return color_counts\n",
    "\n",
    "\n",
    "def DICOM_volume_to_numpy(folder_path: str) -> tuple[np.array, list[str]]:\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError\n",
    "    slices = []\n",
    "    file_names = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        full_path = os.path.join(folder_path, file)\n",
    "        if os.path.isdir(full_path) or file.lower().endswith((\".nrrd\", \".ds_store\")): # skip nested folders or nrrd files\n",
    "            continue\n",
    "        else:\n",
    "            ds = pydicom.dcmread(full_path)\n",
    "            slices.append((ds.ImagePositionPatient[2], ds.pixel_array))\n",
    "            file_names.append(file)\n",
    "\n",
    "    # Stack 2D pixel arrays into 3D numpy array\n",
    "    volume = np.stack([slice[1] for slice in slices], axis=-1)\n",
    "    return (volume, file_names)\n",
    "                    \n",
    "# inhomogeneity_correction\n",
    "\n",
    "def inhomogeneity_correction(read_data: Any, filename: str, save_path: str = None, mask_array = None, show_images: bool = False) -> tuple[np.array, str]:\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions corrects image inhomogeneity by means of using N4 bias field correction, this function is slow and not reccomended as \n",
    "    the brightness correction function does a much better and faster job.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "        \n",
    "    image = sitk.GetImageFromArray(read_data)\n",
    "    image = sitk.Cast(image, sitk.sitkFloat32)\n",
    "    if mask_array is None:\n",
    "        maskImage = sitk.OtsuThreshold(image, 0, 1, 200)\n",
    "    else:\n",
    "        mask_image = sitk.GetImageFromArray(mask_image)\n",
    "\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected_image = corrector.Execute(image, maskImage)\n",
    "    corrected_image = sitk.GetArrayFromImage(corrected_image)\n",
    "\n",
    "    log_bias_field = corrector.GetLogBiasFieldAsImage(image)\n",
    "\n",
    "    corrected_image_full_resolution = image / sitk.Exp(log_bias_field)\n",
    "    corrected_image = sitk.GetArrayFromImage(corrected_image_full_resolution)\n",
    "    corrected_image = cv2.normalize(src=corrected_image, dst=None, alpha=0.0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_16U)\n",
    "    \n",
    "    if show_images:\n",
    "        plt.imshow(corrected_image, cmap='bone')\n",
    "        plt.show()\n",
    "\n",
    "    return (corrected_image, f\"i_c-{filename}\")\n",
    "\n",
    "\n",
    "def sharpen1(read_data: Any, filename: str = None, save_path: str = None, mode: str = \"e_e\", show_images: bool = False) -> tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    Function that applies 3 different kernels that sharpen an image\n",
    "    show_images defaults to False, setting to True will display the result.\n",
    "\n",
    "    Supports modes: \"s\", \"e_s\", \"e_e\"\n",
    "    These modes corrsepond to sharpening, exessive sharpening, edge enhancement respectivley. \"e_e\" is applied by default\n",
    "    \"\"\"\n",
    "    # Retrieved from https://subscription.packtpub.com/book/application-development/9781785283932/2/ch02lvl1sec22/sharpening\n",
    "\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "    if mode == \"s\":\n",
    "        # generating the kernels\n",
    "        kernel_sharpen_1 = np.array([[-1, -1, -1],\n",
    "                                    [-1, 9, -1],\n",
    "                                    [-1, -1, -1]])\n",
    "        output = cv2.filter2D(read_data, -1, kernel_sharpen_1)\n",
    "    elif mode == \"e_s\":\n",
    "        kernel_sharpen_2 = np.array([[1, 1, 1],\n",
    "                                    [1, -7, 1],\n",
    "                                    [1, 1, 1]])\n",
    "        output = cv2.filter2D(read_data, -1, kernel_sharpen_2)\n",
    "    elif mode == \"e_e\":\n",
    "        kernel_sharpen_3 = np.array([[-1, -1, -1, -1, -1],\n",
    "                                    [-1, 2, 2, 2, -1],\n",
    "                                    [-1, 2, 100, 2, -1],\n",
    "                                    [-1, 2, 2, 2, -1],\n",
    "                                    [-1, -1, -1, -1, -1]]) / 2\n",
    "        output = cv2.filter2D(read_data, -1, kernel_sharpen_3)\n",
    "  \n",
    "    if show_images:\n",
    "        plt.imshow(output, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (output, f\"{mode}-{filename}\")\n",
    "\n",
    "# blur\n",
    "\n",
    "def blur(read_data: Any, mode: str = \"b_b\", strength: int = 5, filename: str = None, save_path: str = None, show_images: bool = False) -> tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This functions blurs the image with customizable strength.\n",
    "    The modes supported are \"b_b\" and \"m_b\", corresponding to bilateral bluring and median bluring. \n",
    "\n",
    "    Bilaterl bluring keeps edges intact, typically only affecting the interior of the image, whereas median bluring affects the entire image.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "    \n",
    "    read_data = cv2.normalize(\n",
    "        read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    if mode == \"m_b\":\n",
    "        blur = cv2.medianBlur(read_data, strength)\n",
    "    elif mode == \"b_b\":\n",
    "        blur = cv2.bilateralFilter(read_data, d=strength * 5, sigmaColor=10,sigmaSpace=75)\n",
    "  \n",
    "    if show_images:\n",
    "        plt.imshow(blur, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (blur, f\"{mode}-{filename}\")\n",
    "\n",
    "# thresholding\n",
    "\n",
    "\n",
    "def thresholding(read_data: Any, strength: int = 55, filename: str = None, save_path: str = None, show_images: bool = False) -> tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This function applies uniform thresholding based on a strength value, it is set up to support other modes of thresholding, but they \n",
    "    are not currently in use.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "\n",
    "    read_data = cv2.normalize(\n",
    "        read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    _, th1 = cv2.threshold(read_data, strength, 255, cv2.THRESH_BINARY)\n",
    "   \n",
    "    if show_images:\n",
    "        plt.imshow(th1, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (th1, f\"t-{filename}\")\n",
    "\n",
    "# fill_contours\n",
    "\n",
    "\n",
    "def fill_contours(read_data: str, filename: str = None, dilation_iterations: int = 2, crop: bool = False, save_path: str = None, show_images: bool = False) -> tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This function fills in the interior of the thighs and also supports cropping images who have had their border increased by 10 pixels.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "\n",
    "    img_uint8 = cv2.normalize(\n",
    "        read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    contours, _ = cv2.findContours(\n",
    "        img_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\n",
    "    largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "    # only grab the two largest contours corresponding to the thigh slices\n",
    "    thighs = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "\n",
    "    if len(thighs) > 1 and max(largest_contours) - min(largest_contours) > 0.9 * max(largest_contours):\n",
    "        thighs = [contour for contour in thighs if cv2.contourArea(contour) == max(largest_contours)]\n",
    "\n",
    "    background = np.zeros(read_data.shape)\n",
    "    mask = cv2.fillPoly(background, thighs, color=(255, 255, 255))\n",
    "    # Define kernel for dilation\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    # Dilate mask by 1 pixel\n",
    "    dilated_mask = cv2.dilate(mask, kernel, iterations=dilation_iterations)\n",
    "\n",
    "    dilated_mask_uint8 = cv2.normalize(\n",
    "        dilated_mask, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    contours, _ = cv2.findContours(dilated_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    h, w = dilated_mask_uint8.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        surrounding_pixels = dilated_mask_uint8[y - 1:y + h + 1, x - 1:x + w + 1]\n",
    "        if np.all(surrounding_pixels == 255):\n",
    "        # Apply flood fill to fill the black hole\n",
    "            cv2.floodFill(dilated_mask_uint8, mask, (x, y), 255)\n",
    "    \n",
    "    if crop:\n",
    "        dilated_mask_uint8 = dilated_mask_uint8[10:266, 10:522]\n",
    "\n",
    "    if show_images:\n",
    "        plt.imshow(dilated_mask_uint8, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (dilated_mask_uint8, f\"f_c-{filename}\")\n",
    "        \n",
    "    \n",
    "# denoise\n",
    "\n",
    "\n",
    "def denoise(read_data: Any, filename: str = None, save_path: str = None, show_images: bool = False) -> tuple[np.array, str]:\n",
    "    \"\"\"\n",
    "    This function denoises an image by using a variety of morphological transformations as well as increaseing the border size by 10 pixels,\n",
    "    this is needed to accomodate for some of the transformations. Filling the contours at some point after using this function will correct for the added pixels.\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "\n",
    "    read_data = cv2.copyMakeBorder(src=read_data, top=10, bottom=10, left=10, right=10, borderType=cv2.BORDER_CONSTANT) \n",
    "\n",
    "    read_data_bin = read_data > 0\n",
    "    output = skimage.morphology.closing(read_data_bin)\n",
    "    output = skimage.morphology.binary_dilation(output, np.ones((5,5)))\n",
    "    output = skimage.morphology.remove_small_objects(\n",
    "        output, min_size=1000, connectivity=1)\n",
    "    \n",
    "    output = (output * 1).astype('uint8')\n",
    "\n",
    "    output = fill_contours(read_data=output, dilation_iterations=5)\n",
    "    output = read_data > 0\n",
    "    \n",
    "    output = skimage.morphology.binary_opening(output)\n",
    "    kernel_erosion_small = np.array([ [0, 1, 1, 0],\n",
    "                                      [0, 1, 1, 0],\n",
    "                                      [0, 1, 1, 0],\n",
    "                                      [0, 1, 1, 0]])\n",
    "    output = skimage.morphology.binary_erosion(output, kernel_erosion_small)\n",
    "    output = (output * 1).astype('uint8')\n",
    "\n",
    "    output = fill_contours(read_data=output, dilation_iterations=3)\n",
    "    \n",
    "             \n",
    "    output = output[0] > 0\n",
    "    kernel_erosion_large = np.array([   [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1],\n",
    "                                        [-1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1]])\n",
    "    output = skimage.morphology.binary_erosion(output, kernel_erosion_large)\n",
    "    kernel_erosion_small = np.array([ [0, 1, 0],\n",
    "                                      [0, 1, 0]])\n",
    "    output = skimage.morphology.binary_erosion(output, kernel_erosion_small)\n",
    "    output = (output * 1).astype('uint8')\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    output = cv2.erode(output, kernel, iterations=4)\n",
    "    \n",
    "    if show_images:\n",
    "        plt.imshow(output, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (output, f\"d-{filename}\")    \n",
    "\n",
    "# histogram_normalization\n",
    "\n",
    "def brightness_correction(read_data: Any, mode: str = \"CLAHE\", strength: int = 2, ds: pydicom.Dataset = None, filename: str = None, save_path: str = None, show_images: bool = False) -> tuple[np.array, str, Any]:\n",
    "    \"\"\"\n",
    "    This function corrects the brightness in an image by either using CLAHE or uniform brightening in order to address dark spots and general inhomogeneity\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_data = ds.pixel_array\n",
    "    img_uint8 = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    non_black_white_pixels = None\n",
    "    gray = np.uint8(img_uint8 / np.max(img_uint8) * 255)\n",
    "    if mode == \"CLAHE\":\n",
    "        clahe = cv2.createCLAHE(clipLimit= strength, tileGridSize=(11,11))\n",
    "        result = clahe.apply(gray)\n",
    "    elif mode == \"BI\":\n",
    "        non_black_white_pixels = np.logical_and(gray > 10, gray < 30)\n",
    "        # Increase brightness for non-black pixels\n",
    "        brightened_image = np.clip(np.where(non_black_white_pixels, img_uint8 + strength, img_uint8), 0, 255)\n",
    "        # Clip the values to ensure they remain within the valid range [0, 255]\n",
    "        result = brightened_image\n",
    "    result = cv2.normalize(result, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_16U)\n",
    "    if show_images:\n",
    "        plt.imshow(result, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return (result, f\"{mode}-{filename}\", non_black_white_pixels)\n",
    "\n",
    "\n",
    "def get_mask(read_data: Any) -> np.array:\n",
    "    \"\"\"\n",
    "    This function retruns all the pixels in an image that are white\n",
    "    \"\"\"\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        img = ds.pixel_array\n",
    "    else:\n",
    "        img = read_data\n",
    "    white_pixels = np.argwhere(img == 255)\n",
    "    return white_pixels\n",
    "\n",
    "\n",
    "def get_cleaned_image(read_data: Any, mask: Any, ds: pydicom.Dataset = None, filename: str = None, save_path: str = None, show_images: bool = False) -> np.array:\n",
    "    \"\"\"\n",
    "    This function gets a cleaned image based on a base/corrected image as well as a mask containing all the pixels which we wish to retain in the new image.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(mask) is str:\n",
    "        ds = pydicom.dcmread(mask)\n",
    "        mask_array = ds.pixel_array\n",
    "    else:\n",
    "        mask_array = mask\n",
    "\n",
    "    binary_array = np.where(mask_array == 255, 1, mask_array)\n",
    "    if type(read_data) is str:\n",
    "        ds = pydicom.dcmread(read_data)\n",
    "        read_array = ds.pixel_array\n",
    "    else:\n",
    "        read_array = read_data\n",
    "    combined = read_array*binary_array \n",
    "    combined = cv2.normalize(combined, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_16U)\n",
    "    \n",
    "    if show_images:\n",
    "        plt.imshow(combined, cmap=\"bone\")\n",
    "        plt.show()\n",
    "    return combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Leg Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackupLegSeparation(image, side): \n",
    "    '''\n",
    "    This function runs backup leg model and resets i so all slices use backup version\n",
    "    '''\n",
    "    pt_image = image\n",
    "    pixel_values = np.sum(pt_image, axis=0) #find which x values have brightest pixels\n",
    "    from skimage.filters import threshold_otsu, threshold_multiotsu\n",
    "    x_threshold = threshold_otsu(pixel_values)\n",
    "    x_coordinates = np.arange(len(pixel_values)) #assign x values\n",
    "\n",
    "    # Save the data as a NumPy array\n",
    "    data_array = np.array([x_coordinates, pixel_values])\n",
    "    np.save('data_array.npy', data_array)\n",
    "    loaded_array = np.load('data_array.npy')\n",
    "\n",
    "    x_coordinates = np.arange(len(loaded_array[1]))\n",
    "\n",
    "    #counting intersections to determine range of interest\n",
    "    def count_intersections(x_data,y_data, horizontal_line_y):\n",
    "        num_intersections = 0\n",
    "\n",
    "        for i in range(len(y_data) - 1):\n",
    "            y1, y2 = y_data[i], y_data[i + 1]\n",
    "            x1, x2 = x_data[i], x_data[i + 1]\n",
    "\n",
    "            # Check if the horizontal line intersects the line segment\n",
    "            if min(y1, y2) <= horizontal_line_y <= max(y1, y2) and y1 != y2:\n",
    "                x_intersection = x1 + (horizontal_line_y - y1) * (x2 - x1) / (y2 - y1)\n",
    "                if x1 <= x_intersection <= x2:\n",
    "                    num_intersections += 1\n",
    "\n",
    "        return num_intersections\n",
    "\n",
    "    intersection_count = np.array([])\n",
    "    for i in range (max(loaded_array[1])-1):\n",
    "        horizontal_line_y = i\n",
    "        # Count intersections\n",
    "        intersections = count_intersections(x_coordinates, loaded_array[1], horizontal_line_y)\n",
    "        intersection_count = np.append(intersection_count, intersections)\n",
    "\n",
    "    #finding the target Y value\n",
    "    value_to_find = 4\n",
    "    indices = np.where(intersection_count == value_to_find)[0]\n",
    "    target_y = np.median(indices)\n",
    "\n",
    "\n",
    "    # Function to find X values where a vertical line intersects the graph at a specific Y value\n",
    "    def find_vertical_line_intersections(x_data, y_data, target_y):\n",
    "        intersections_x = []\n",
    "\n",
    "        for i in range(len(y_data) - 1):\n",
    "            y1, y2 = y_data[i], y_data[i + 1]\n",
    "            x1, x2 = x_data[i], x_data[i + 1]\n",
    "\n",
    "            # Check if the vertical line intersects the line segment\n",
    "            if min(y1, y2) <= target_y <= max(y1, y2) and y1 != y2:\n",
    "                x_intersection = x1 + (target_y - y1) * (x2 - x1) / (y2 - y1)\n",
    "                if x1 <= x_intersection <= x2:\n",
    "                    intersections_x.append(x_intersection)\n",
    "\n",
    "        return intersections_x\n",
    "\n",
    "    # Call the function to find X values\n",
    "    intersections_x = find_vertical_line_intersections(x_coordinates, loaded_array[1], target_y)\n",
    "\n",
    "    #cut image at average between 2 middle intersections x values\n",
    "    mid = round((intersections_x[1] + intersections_x[2])/2) #x-value between legs\n",
    "\n",
    "    desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "    #Slicing image at midpoint\n",
    "    #left side\n",
    "    if side == 'L':\n",
    "        centered_image = pt_image[:, :mid]\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "        if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "            num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "            centered_image_f = np.pad(centered_image, ((0, 0), (0, num_columns_to_add)), mode='constant')\n",
    "        elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, num_columns_to_remove:]\n",
    "        else:\n",
    "            centered_image_f = centered_image\n",
    "    #right side\n",
    "    if side == 'R':\n",
    "        centered_image = pt_image[:, mid:]\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "        if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "            num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "            centered_image_f = np.pad(centered_image, ((0, 0), (num_columns_to_add,0)), mode='constant')\n",
    "        elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, :desired_shape[1]]\n",
    "        else:\n",
    "            centered_image_f = centered_image\n",
    "    def first_last_nonzero_indices(arr):\n",
    "        # Find the first nonzero index\n",
    "        first_nonzero = next((index for index, value in enumerate(arr) if value != 0), None)\n",
    "        # Find the last nonzero index\n",
    "        last_nonzero = next((index for index, value in reversed(list(enumerate(arr))) if value != 0), None)\n",
    "        #print(f'{first_nonzero} and {last_nonzero}')\n",
    "        return first_nonzero, last_nonzero\n",
    "\n",
    "    pixel_values = np.sum(centered_image_f, axis=0) #use new image\n",
    "    first, last = first_last_nonzero_indices(pixel_values)\n",
    "    current_mid = round((first - last)/2)\n",
    "    if side == 'L':\n",
    "        shift = 128 - current_mid\n",
    "    if side == 'R':\n",
    "        shift = -1* (128 - current_mid) \n",
    "    shifted_array = np.roll(centered_image_f, shift, axis=1)\n",
    "    return centered_image_f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LegSepNew (image, side, rmv_count, num_columns_to_remove):\n",
    "    '''\n",
    "    This function separates the thighs by side so each resulting image only contains one thigh\n",
    "    '''\n",
    "    read_data = image\n",
    "    num_columns_to_remove = num_columns_to_remove\n",
    "    rmv_count = rmv_count\n",
    "    read_data = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    erode = cv2.erode(read_data, kernel, iterations=1)\n",
    "    blur = cv2.medianBlur(erode, 3)\n",
    "    blur = cv2.bilateralFilter(blur,9,10,50)                                               #locating 2 large bright regions (legs)\n",
    "    ret, thresh = cv2.threshold(blur, 30, 255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "    thighs = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "    backtorgb = cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(backtorgb, [thighs[0]], -1, (255,0,0), 1)\n",
    "    cv2.drawContours(backtorgb, [thighs[1]], -1, (0,0,255), 1)\n",
    "    min_centroid = ()\n",
    "    max_centroid = ()\n",
    "    if side == 'L':\n",
    "            for contour in thighs:\n",
    "                # Calculate the centroid of the contour\n",
    "                M = cv2.moments(contour)\n",
    "                cX = int(M['m10'] / M['m00'])\n",
    "                cY = int(M['m01'] / M['m00'])\n",
    "                if len(min_centroid) == 0 or cX < min_centroid[0]:     #chooses centroid with smaller x value (i.e. left side)\n",
    "                    min_centroid = (cX, cY, contour)\n",
    "            min_contour = min_centroid[2]\n",
    "            end_x = min_contour[:, :, 0].max() # Find the ending x-coordinate (rightmost point) of the contour\n",
    "            if rmv_count > 0:\n",
    "                centered_image = read_data[:,num_columns_to_remove:end_x]\n",
    "                start_x = min_contour[:, :, 0].min()\n",
    "                \n",
    "                if start_x < num_columns_to_remove:\n",
    "                    print(\"using backup\")\n",
    "                    centered_image = BackupLegSeparation(read_data, \"L\")\n",
    "            else:\n",
    "                centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "            \n",
    "            #reform new shape\n",
    "            desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "            np.expand_dims(centered_image,axis=2)\n",
    "            if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "                num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "                centered_image_f = np.pad(centered_image, ((0, 0), (0, num_columns_to_add)), mode='constant')\n",
    "            elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "                num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "                centered_image_f = centered_image[:,:desired_shape[1]]\n",
    "                print(\"Too Big\")\n",
    "            else:\n",
    "                centered_image_f = centered_image              \n",
    "                         \n",
    "                \n",
    "    if side == 'R':\n",
    "        max_cX = None\n",
    "        for contour in thighs:\n",
    "            # Calculate the centroid of the contour\n",
    "            M = cv2.moments(contour)\n",
    "            cX = int(M['m10'] / M['m00'])\n",
    "            cY = int(M['m01'] / M['m00'])\n",
    "            if max_cX is None or cX > max_cX:\n",
    "                max_cX = cX  # Update max_cX with the current cX\n",
    "                max_centroid = (cX, cY, contour) #pick right side\n",
    "\n",
    "        max_contour = max_centroid[2]\n",
    "        start_x = max_contour[:, :, 0].min()# Find the ending x-coordinate (leftmost point) of the contour\n",
    "        desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "        if rmv_count > 0:\n",
    "            cutoff = 512 - num_columns_to_remove\n",
    "            centered_image = read_data[:,start_x:cutoff]\n",
    "            start_x = max_contour[:, :, 0].max()\n",
    "        else:\n",
    "            centered_image = read_data[:, start_x:]\n",
    "        \n",
    "        if desired_shape[1] - centered_image.shape[1] > 0: #add columns\n",
    "            num_columns_to_add = desired_shape[1] - centered_image.shape[1]\n",
    "            centered_image_f = np.pad(centered_image, ((0, 0), (num_columns_to_add,0)), mode='constant')\n",
    "        elif desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, num_columns_to_remove:]\n",
    "        else:\n",
    "            centered_image_f = centered_image\n",
    "            \n",
    "    return centered_image_f\n",
    "  \n",
    "def GetShift(image,side):\n",
    "    '''\n",
    "    This function finds how much to shift all slices in patient so the final images contains entire thigh regardless of size and each slice is still in the same position relative to the slices beside it (z-connectivity)\n",
    "    '''\n",
    "    read_data = image\n",
    "    read_data = cv2.normalize(read_data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]], dtype = np.uint8)\n",
    "    erode = cv2.erode(read_data, kernel, iterations=1)\n",
    "    blur = cv2.medianBlur(erode, 3)\n",
    "    blur = cv2.bilateralFilter(blur,9,10,50)                                               #locating 2 large bright regions (legs)\n",
    "    ret, thresh = cv2.threshold(blur, 30, 255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    largest_contours = sorted([cv2.contourArea(obj) for obj in contours], reverse=True)[:2]\n",
    "    thighs = [obj for obj in contours if cv2.contourArea(obj) in largest_contours]\n",
    "    backtorgb = cv2.cvtColor(thresh,cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(backtorgb, [thighs[0]], -1, (255,0,0), 1)\n",
    "    cv2.drawContours(backtorgb, [thighs[1]], -1, (0,0,255), 1)\n",
    "    min_centroid = ()\n",
    "    max_centroid = ()\n",
    "    if side == 'L':\n",
    "            for contour in thighs:\n",
    "                # Calculate the centroid of the contour\n",
    "                M = cv2.moments(contour)\n",
    "                cX = int(M['m10'] / M['m00'])\n",
    "                cY = int(M['m01'] / M['m00'])\n",
    "                if len(min_centroid) == 0 or cX < min_centroid[0]:     #chooses centroid with smaller x value (i.e. left side)\n",
    "                    min_centroid = (cX, cY, contour)\n",
    "            min_contour = min_centroid[2]\n",
    "            end_x = min_contour[:, :, 0].max() # Find the ending x-coordinate ( rightmost point) of the contour\n",
    "            rmv_count = 0 #care to know if we removed columns\n",
    "            desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "            centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "            np.expand_dims(centered_image,axis=2)\n",
    "            if desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "                num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "                centered_image_f = centered_image[:,num_columns_to_remove:] #want to remove columns at beginning\n",
    "                rmv_count += 1   \n",
    "            else:\n",
    "                num_columns_to_remove = 0\n",
    "\n",
    "                    \n",
    "    if side == 'R':\n",
    "        max_cX = None\n",
    "        for contour in thighs:\n",
    "            # Calculate the centroid of the contour\n",
    "            M = cv2.moments(contour)\n",
    "            cX = int(M['m10'] / M['m00'])\n",
    "            cY = int(M['m01'] / M['m00'])\n",
    "            if max_cX is None or cX > max_cX:\n",
    "                max_cX = cX  # Update max_cX with the current cX\n",
    "                max_centroid = (cX, cY, contour) #pick right side\n",
    "\n",
    "        max_contour = max_centroid[2]\n",
    "        end_x = max_contour[:, :, 0].min()# Find the ending x-coordinate (leftmost point) of the contour\n",
    "        #print(end_x)\n",
    "        rmv_count = 0 #care to know if we removed columns\n",
    "        desired_shape = (256, 256)  # define desired shape (rows, columns)\n",
    "        centered_image = read_data[:, :end_x] #cut off at centroid\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "\n",
    "        centered_image = read_data[:, end_x:]\n",
    "        np.expand_dims(centered_image,axis=2)\n",
    "        \n",
    "        if desired_shape[1] - centered_image.shape[1] < 0: #remove columns\n",
    "            num_columns_to_remove = centered_image.shape[1] - desired_shape[1]\n",
    "            centered_image_f = centered_image[:, :desired_shape[1]] #want to remove columns at the end\n",
    "            rmv_count += 1\n",
    "        else:\n",
    "            num_columns_to_remove = 0\n",
    "     \n",
    "    return rmv_count, num_columns_to_remove\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Definitions for Muscle Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def enlarge_size(image,pixels): \n",
    "    '''\n",
    "    This function adds a certain number of pixels to all sides of the image\n",
    "    '''\n",
    "    image_big =np.zeros([image.shape[0], image.shape[1]+(pixels*2), image.shape[2]+(pixels*2)], dtype='uint8')\n",
    "    \n",
    "    #adding pixels for shape[1] is for top_bottom - acconting for addition top bottom addition increase in size\n",
    "    #adding pixels for shape[2] is for left right - acconting for addition left bottom addition increase in size\n",
    "    \n",
    "    pixels=pixels\n",
    "    for i in range(j):\n",
    "        top_bottom=np.zeros([pixels, image.shape[2]], dtype='uint8')   \n",
    "        top_added=np.vstack((top_bottom,image[i])) \n",
    "        bottom_added=np.vstack((top_added,top_bottom)) \n",
    "        right_left=np.zeros([bottom_added.shape[0], pixels], dtype='uint8')  \n",
    "        right_added=np.hstack((bottom_added,right_left))\n",
    "        left_added=np.hstack((right_left,right_added))\n",
    "        image_big[i]=left_added\n",
    "    return  image_big, pixels #want pixels for reducing size later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_size(image_big): \n",
    "    '''\n",
    "    This function removes a certain number of pixels from all sides of the image\n",
    "    '''\n",
    "    top_removed=np.delete(image_big, np.s_[:pixels], 1)  \n",
    "    bottom_removed=np.delete(top_removed, np.s_[top_removed.shape[1]-pixels:], 1) \n",
    "    left_removed=np.delete(bottom_removed, np.s_[:pixels], 2) \n",
    "    right_removed=np.delete(left_removed, np.s_[left_removed.shape[2]-pixels:], 2)  \n",
    "    image_reg=right_removed.copy()\n",
    "    return image_reg\n",
    "\n",
    "def multi_otsu_1(image):\n",
    "    '''\n",
    "    This function takes the Otsu threshold between the second and third class and returns the fat threshold\n",
    "    '''\n",
    "    motsuth=filters.threshold_multiotsu(image, classes=3)\n",
    "    regions=np.digitize(image,bins=motsuth)\n",
    "    output=img_as_ubyte(regions)\n",
    "    return motsuth[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Get Rough Muscle Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def floodfill(image): \n",
    "    '''\n",
    "    This function flood fills the rough muscle mask\n",
    "    '''\n",
    "    ff_im=np.zeros([image.shape[0], image.shape[1]], dtype='uint8') \n",
    "    to_ff=image.copy()\n",
    "         \n",
    "    h, w = image.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    cv2.floodFill(to_ff, mask, (0,0), 1);\n",
    "    th, ff_im = cv2.threshold(to_ff, 0, 1, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    return ff_im\n",
    "\n",
    "def multi_otsu_0(image):\n",
    "    '''\n",
    "    This function takes the Otsu threshold between the first and second class and returns the fat+muscle threshold\n",
    "    '''\n",
    "    motsuth=filters.threshold_multiotsu(image, classes=3)\n",
    "    regions=np.digitize(image,bins=motsuth)\n",
    "    output=img_as_ubyte(regions)\n",
    "    return motsuth[0] \n",
    "\n",
    "\n",
    "\n",
    "def get_musc_fat_mask(image):\n",
    "    '''\n",
    "    This function applies a threshold to the image and gets the rough muscle+fat mask\n",
    "    '''\n",
    "    mask =np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    \n",
    "    k=1\n",
    "    \n",
    "    for i in range(j):\n",
    "        th=multi_otsu_0(image[i]) \n",
    "        mask[i]=(image[i]>th) \n",
    "\n",
    "        mask[i] = cv2.morphologyEx(mask[i], cv2.MORPH_OPEN, np.ones((5,5),np.uint8)) #remove connections with other leg\n",
    "\n",
    "        \n",
    "        mask[i]=cv2.morphologyEx(mask[i], cv2.MORPH_CLOSE, np.ones((2,2),np.uint8))\n",
    "\n",
    "        mask[i] = (morphology.remove_small_holes(label(mask[i]),area_threshold=9000, connectivity=1)) #remove holes to get entire mask of muscle + subcfat region\n",
    "\n",
    "        mask[i] = cv2.morphologyEx(mask[i], cv2.MORPH_OPEN, np.ones((7,7),np.uint8)) #get rid of line artifact\n",
    "\n",
    "        mask[i] = (morphology.remove_small_objects(label(mask[i]),min_size=3000, connectivity=1))#get rid of noise \n",
    "\n",
    "        ret, mask[i] = cv2.threshold(mask[i],0,1,cv2.THRESH_BINARY) \n",
    "        \n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_subcfat_ring(image):\n",
    "    '''\n",
    "    This function finds the subcutaneous fat ring which is used to close the gaps for floodfilling when isolating muscle\n",
    "    '''\n",
    "    subcfat_ring=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        eroded=cv2.erode(image[i],np.ones((5,5),np.uint8),iterations = 1) \n",
    "        subcfat_ring[i]=image[i]-eroded \n",
    "    return subcfat_ring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CurvatureFlowImageFilter(image): \n",
    "    '''\n",
    "    This function removes noise to make the fascia boundary more clear\n",
    "    '''\n",
    "    inputImage=sitk.GetImageFromArray(image)\n",
    "    inputImage = sitk.Cast(inputImage, sitk.sitkFloat32)\n",
    "    corrector = sitk.CurvatureFlowImageFilter()\n",
    "    corrector.SetNumberOfIterations( 15 );\n",
    "    corrector.SetTimeStep( 0.1 )\n",
    "    output = corrector.Execute( inputImage)\n",
    "    image_c= sitk.GetArrayFromImage(output)\n",
    "    image_c=cv2.normalize(src=image_c, dst=None, alpha=0.0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) \n",
    "    return image_c\n",
    "\n",
    "def apply_CurvatureFilter(image1,image2):\n",
    "    '''\n",
    "    This function is used to overcome instances where the image is dark\n",
    "    '''\n",
    "    mask=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    image=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        mask[i]=Ivol8c_subcfat[i]>multi_otsu_1(Ivol8c_subcfat[i])  \n",
    "        if np.sum(mask[i]>0)<1000:\n",
    "            print(f\"Slice {i+1} use Ivol8c_coi\")\n",
    "            image[i]=image2[i]\n",
    "        else:\n",
    "            image[i]=image1[i]\n",
    "    \n",
    "    curvature_flow=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        curvature_flow[i]=CurvatureFlowImageFilter(image[i])\n",
    "        \n",
    "    return curvature_flow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def enhance_sharpness(image): \n",
    "    '''\n",
    "    This function is used to make the fascia boundary line darker\n",
    "    '''\n",
    "    from PIL import ImageEnhance\n",
    "    from PIL import Image\n",
    "\n",
    "    Ivol8c_c_s=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        f=image[i].copy()\n",
    "        f=Image.fromarray(f, mode=None)\n",
    "        enhancer = ImageEnhance.Sharpness(f)\n",
    "        factor =  12.0 \n",
    "        Ivol8c_c_s[i]=enhancer.enhance(factor)\n",
    "    return Ivol8c_c_s\n",
    "\n",
    "def get_subcfatvol(image):   \n",
    "    '''\n",
    "    This function gives the subcutaneous fat volume\n",
    "    '''\n",
    "    subcfatvol=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        subcfatvol[i]=image[i]>multi_otsu_1(image[i])  \n",
    "\n",
    "        subcfatvol[i] = (morphology.remove_small_holes(subcfatvol[i],area_threshold=90, connectivity=1))  \n",
    "         \n",
    "    return subcfatvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floodfillall(image):\n",
    "    '''\n",
    "    This function floodfills objects in a 3D image\n",
    "    '''\n",
    "    floodfilled=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "    for i in range(j): \n",
    "        im_floodfill = image[i].copy()\n",
    "        h, w = im_floodfill.shape[:2]\n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "        cv2.floodFill(im_floodfill, mask, (0,0), 1);\n",
    "        th, floodfilled[i] = cv2.threshold(im_floodfill, 0, 1, cv2.THRESH_BINARY_INV)\n",
    "    return floodfilled\n",
    "\n",
    "def darkpieces(image): \n",
    "    '''\n",
    "    This function is used to find the dark parts of our image including vessels\n",
    "    '''\n",
    "    musc_mask1=floodfillall(image) \n",
    "    musc_mask2=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "\n",
    "\n",
    "    for i in range(j):\n",
    "        musc_mask2[i] = cv2.morphologyEx(musc_mask1[i], cv2.MORPH_OPEN, np.ones((3,3),np.uint8)) \n",
    "        \n",
    "        musc_mask2[i] = (morphology.remove_small_objects(label(musc_mask2[i]),min_size=100, connectivity=1)) \n",
    "            \n",
    "        musc_mask2[i]= cv2.dilate(musc_mask2[i],np.ones((3,3),np.uint8),iterations = 1)\n",
    "        musc_mask2[i] = (morphology.remove_small_objects((musc_mask2[i]).astype(bool),min_size=100, connectivity=1)) \n",
    "        musc_mask2[i]= cv2.erode(musc_mask2[i],np.ones((3,3),np.uint8),iterations = 1) \n",
    "            \n",
    "        th, musc_mask2[i]= cv2.threshold(np.uint8(musc_mask2[i]), 0, 1, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return musc_mask1, musc_mask2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any muscle overshoots into subcfat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_subcfat_overshoot(image1,image2,removal_round):\n",
    "    '''\n",
    "    This function removes any overshooting that may occur when creating subcutaneous fat mask\n",
    "    '''\n",
    "    a=image1*image2\n",
    "    \n",
    "    \n",
    "    overshoot=np.zeros([image1.shape[0], image1.shape[1], image1.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):        \n",
    "        th=multi_otsu_1(a[i])  \n",
    "        overshoot[i]=a[i]>th\n",
    "        \n",
    "        if removal_round==1: #larger obj removal size\n",
    "       \n",
    "            overshoot[i] = (morphology.remove_small_objects(label(overshoot[i]),min_size=30, connectivity=1)) #diff obj size to be removed for round 1 vs round 2\n",
    "            overshoot[i]=cv2.morphologyEx(overshoot[i], cv2.MORPH_CLOSE, np.ones((5,5),np.uint8)) \n",
    "            th, overshoot[i] = cv2.threshold(overshoot[i], 0, 1, cv2.THRESH_BINARY)\n",
    "        else:\n",
    "            overshoot[i] = (morphology.remove_small_objects(label(overshoot[i]),min_size=20, connectivity=1)) #diff obj size to be removed for round 1 vs round 2\n",
    "            th, overshoot[i] = cv2.threshold(overshoot[i], 0, 1, cv2.THRESH_BINARY)\n",
    "        \n",
    "\n",
    "    overshoot_removed=image1-overshoot #rough mask subtract the overshoot mask\n",
    "    overshoot_removed[overshoot_removed==255] = 1 \n",
    "  \n",
    "    \n",
    "    for i in range(j): \n",
    "        overshoot_removed[i]= (morphology.remove_small_objects(label(overshoot_removed[i]),min_size=30, connectivity=1)) #remove any bits remaining from subtraction\n",
    "        th, overshoot_removed[i] = cv2.threshold(overshoot_removed[i].astype(np.uint8), 0, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    return overshoot,overshoot_removed\n",
    "\n",
    "def keep_overlaps(image,overlap_num):\n",
    "    '''\n",
    "    This function keeps parts of the image that is greater than overlap_num when thresholding\n",
    "    '''\n",
    "    image2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    \n",
    "    for i in range(j):\n",
    "        if i==0:\n",
    "            image2[i]=image[i]+image[i+1]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        elif i==(j-1):\n",
    "            image2[i]=image[i-1]+image[i]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        else:\n",
    "            image2[i]=image[i-1]+image[i]+image[i+1]\n",
    "    \n",
    "\n",
    "    ret, image2= cv2.threshold(image2,overlap_num,1,cv2.THRESH_BINARY) \n",
    "    for i in range(j):\n",
    "        image2[i]= (morphology.remove_small_objects(label(image2[i]),min_size=40, connectivity=1)) \n",
    "    \n",
    "    ret, image2= cv2.threshold(image2.astype(np.uint8),0,1,cv2.THRESH_BINARY)\n",
    "\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snakes prep: Get Muscle Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_contours(im): \n",
    "    '''\n",
    "    This function gets the contours of an image/mask\n",
    "    '''\n",
    "    contour_coords_L=[]\n",
    "\n",
    "    mask_contours=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "    zeros=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "    for i in range (j):\n",
    "        a, b =  cv2.findContours(im[i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour_coords_L.append([])\n",
    "        contour_coords_L[i].append(a) \n",
    "\n",
    "        #draw contours from contour_coords_L onto zeros array \n",
    "        mask_contours[i] = cv2.drawContours(zeros[i], contour_coords_L[i][0],  -1, (1,0,0), 1)\n",
    "        \n",
    "    return mask_contours, contour_coords_L\n",
    "\n",
    "\n",
    "def convex_hull(contours):\n",
    "    '''\n",
    "    This function gets rid of concavities in contour, used to follow the fascia as much as possible and initiate the snake\n",
    "    '''\n",
    "    hull_coords=[]\n",
    "    hull_demonstration = np.zeros((Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2], 3), np.uint8)\n",
    "    hull = np.zeros((Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]), np.uint8)\n",
    "    listt=[]\n",
    "    contours_prehull=[]\n",
    "    for i in range(j):\n",
    "        hull_coords.append([])  \n",
    "        listt.append([])\n",
    "        contours_prehull.append([])\n",
    "\n",
    "            \n",
    "        for i2 in range(len(contours[i])):\n",
    "            for i3 in range(len(contours[i][i2])):\n",
    "                for i4 in range(len(contours[i][i2][i3])):\n",
    "                    listt[i].append(contours[i][i2][i3][i4])\n",
    "     \n",
    "        contours_prehull[i]=np.array(listt[i])\n",
    "\n",
    "        hull_coords[i].append(cv2.convexHull(contours_prehull[i], False))\n",
    "    \n",
    "        for i2 in range(len(contours[i])):\n",
    "            color_contours = (0, 255, 0) # green - color for contours\n",
    "            color_hull = (255, 0, 0) # red - color for convex hull\n",
    "            cv2.drawContours(hull_demonstration[i], contours[i][0], i2, color_contours,\n",
    "                             1, 8) \n",
    "            cv2.drawContours(hull_demonstration[i], hull_coords[i], i2, color_hull, 1, 8)\n",
    "\n",
    "        for i2 in range(len(contours)): \n",
    "            color_hull = (255, 0, 0) # blue - color for convex hull\n",
    "            cv2.drawContours(hull[i], hull_coords[i],  -1, (1,0,0), 1)\n",
    "        \n",
    "    return hull, hull_demonstration, hull_coords\n",
    "\n",
    "def show_convexhull():\n",
    "    '''\n",
    "    This function displays the convex_hull\n",
    "    '''\n",
    "    fig, axs = plt.subplots(j, 3, figsize= (18, 120))\n",
    "    for i in range(j):\n",
    "        axs[i, 0].set_title(f\"slice {i+1}\", fontsize=18)\n",
    "        axs[i, 0].imshow(mask_contours[i])\n",
    "        axs[i, 1].imshow(hull_demonstration[i])\n",
    "        axs[i, 2].imshow(hull[i])\n",
    "\n",
    "        \n",
    "def compatible_coordlist(contours):\n",
    "    '''\n",
    "    This function generate the initial coordinates to use for the snake\n",
    "    '''\n",
    "    initiator_coords=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        initiator_coords.append([])\n",
    "        for i2 in range(len(contours[i][0][0])): \n",
    "            initiator_coords[i].append(contours[i][0][0][i2][0])\n",
    "        initiator_coords[i]=np.array(initiator_coords[i])\n",
    "        initiator_coords[i]=initiator_coords[i].astype(float)\n",
    "    return initiator_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_vessels(image): \n",
    "    '''\n",
    "    This function removes the vessels from the ROI\n",
    "    '''\n",
    "    vessels_present=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    test=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "    vessels_removed_mask=np.zeros([image.shape[0], image.shape[1], image.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        otsu_th=multi_otsu_1(image[i])\n",
    "        vessels_present[i] = image[i]>otsu_th\n",
    "        \n",
    "        vessels_removed_mask[i] = label(vessels_present[i]) \n",
    "  \n",
    "        vessels_removed_mask[i]=cv2.morphologyEx(vessels_removed_mask[i], cv2.MORPH_CLOSE, np.ones((5,5),np.uint8)) \n",
    "    \n",
    "        vessels_removed_mask[i] = (morphology.remove_small_holes(vessels_removed_mask[i],area_threshold=90, connectivity=1)).astype(int) \n",
    "        \n",
    "        vessels_removed_mask[i]=cv2.normalize(src=vessels_removed_mask[i], dst=None, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    return vessels_removed_mask, vessels_present\n",
    "        \n",
    "\n",
    "def get_vessels():\n",
    "    '''\n",
    "    This function checks the area to isolate circles which represent the vessels\n",
    "    '''\n",
    "    contour_coords_L=[]\n",
    "    hiercvol=[]\n",
    "    contour_listvol=[]\n",
    "    boneroi=[]\n",
    "    vessels_mask=[]\n",
    "\n",
    "    r=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        contour_coords_L.append([])\n",
    "        hiercvol.append([])\n",
    "        contour_listvol.append([])\n",
    "        boneroi.append([])\n",
    "        vessels_mask.append([])\n",
    "\n",
    "    for i in range (j):\n",
    "        a, b =  cv2.findContours(pre_vessels_mask[i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour_coords_L[i].append(a)\n",
    "        hiercvol[i].append(b)\n",
    "\n",
    "        for contour in contour_coords_L[i][0]:\n",
    "            approx = cv2.approxPolyDP(contour,0.01*cv2.arcLength(contour,True),True)\n",
    "\n",
    "            if (len(approx) > 3):  \n",
    "                contour_listvol[i].append(contour)\n",
    "\n",
    "        for i2 in range (len(contour_listvol[i])): \n",
    "            (x,y),radius = cv2.minEnclosingCircle(contour_listvol[i][i2]) #finds a circle of the minimum area enclosing a 2d point set\n",
    "            center = (int(x),int(y))\n",
    "            radius = int(radius)\n",
    "            area = cv2.contourArea(contour_listvol[i][i2]) \n",
    "      \n",
    "            #radius<50 to indicate small objects; area check relative to radius to check the circularity\n",
    "            if (radius < 50) & (area> (0.1*(3.14*(radius**2))) and area<100): #appends to boneROI if the radius is less than the specified number (indicating blood vessels) \n",
    "                boneroi[i].append(contour_listvol[i][i2])#append to list if it satisfies the above conditions\n",
    "                \n",
    "        vessels_mask[i] = cv2.drawContours(r[i], boneroi[i],  -1, (1,0,0), 1)\n",
    "    \n",
    "    vessels_mask=floodfillall(vessels_mask)\n",
    "\n",
    "    for i in range(j): \n",
    "        vessels_mask[i]=cv2.dilate(vessels_mask[i],np.ones((3,3),np.uint8),iterations = 1) \n",
    "   \n",
    "    return vessels_mask\n",
    "\n",
    "def get_whites():\n",
    "    '''\n",
    "    This function generates white mask to help guide the snake away from the thigh border and vessels (which are dark)\n",
    "    '''\n",
    "    whites=np.zeros([Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        #generate the white outside\n",
    "        whites[i]=musc_fat_mask[i].copy() \n",
    "        whites[i][whites[i]==0] = 255\n",
    "   \n",
    "        whites[i][whites[i]==1] = 0\n",
    "        whites[i][vessels_mask[i]==1]=255\n",
    "    return whites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine THIGH Muscle Mask: Snakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_snakeim():\n",
    "    '''\n",
    "    This function applies a whites mask onto the filtered image to generate the image that the snake will be operating on\n",
    "    '''\n",
    "    snake_im=Ivol8c_c_s.copy()\n",
    "    for i in range(j):\n",
    "        snake_im[i][whites[i]==255] = 255 \n",
    "        snake_im[i][subcfat_ring[i]==1] = 255  \n",
    "    return snake_im\n",
    "\n",
    "def bilat_fil_snake_im(image): \n",
    "    '''\n",
    "    This function applies a bilateral filter to get rid of some noise\n",
    "    '''\n",
    "    bilateral_t=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        bilateral_t[i] = cv2.bilateralFilter(image[i],20,35,35)\n",
    "    return bilateral_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Snakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "\n",
    "def primary_snake():\n",
    "    '''\n",
    "    This function finds the primary snake coordinates using active contour model\n",
    "    '''\n",
    "    snake1_coords=[]\n",
    "    for i in range(j): \n",
    "        snake1_coords.append([])\n",
    "        snake1_coords[i]=active_contour(gaussian(bilateral_t[i], 1,preserve_range=False), initiator_coords[i],alpha=0.01,gamma=20,w_edge=8,w_line=-0.5,max_num_iter=5,max_px_move=1)#test for fascia smoother\n",
    "\n",
    "    return snake1_coords \n",
    "\n",
    "\n",
    "def snaketomask(coordinates):  \n",
    "    '''\n",
    "    This function uses the snake coordinates and makes a snake mask\n",
    "    ''' \n",
    "    vol=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        vol.append([])\n",
    "        for i2 in range(len(coordinates[i])):\n",
    "            vol[i].append([])\n",
    "            vol[i][i2].append(coordinates[i][i2])\n",
    "\n",
    "        vol[i]=np.rint(vol[i]).astype(int)\n",
    "\n",
    "    drawsnake= np.zeros((Ivol8c_subcfat.shape[0], Ivol8c_subcfat.shape[1], Ivol8c_subcfat.shape[2]), np.uint8)\n",
    "    \n",
    "    #polylines function connects the dots to make it one smooth contour\n",
    "    for i in range(j):\n",
    "        cv2.polylines(drawsnake[i], [vol[i]], isClosed=True, color = (1, 0, 0) , thickness=1) \n",
    "    \n",
    "    snake_mask=drawsnake.copy()\n",
    "\n",
    "    h, w = subcfatvol[i].shape[:2]\n",
    "\n",
    "    for i in range (j):\n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "        (x,y),radius = cv2.minEnclosingCircle(vol[i]) \n",
    "        cv2.floodFill(snake_mask[i], mask, (round(x),round(y)), 255)\n",
    "\n",
    "    ret, snake_mask = cv2.threshold(snake_mask,0,1,cv2.THRESH_BINARY)\n",
    "    return snake_mask\n",
    "\n",
    "\n",
    "def keep_overlaps2(image,overlap_num): \n",
    "    '''\n",
    "    This function keeps parts of the image that is greater than overlap_num when thresholding\n",
    "    '''\n",
    "    image2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        if i==0:\n",
    "            image2[i]=image[i]+image[i+1]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        elif i==(j-1):\n",
    "            image2[i]=image[i-1]+image[i]\n",
    "            image2[i][image2[i]==2]=3\n",
    "        else:\n",
    "            image2[i]=image[i-1]+image[i]+image[i+1]\n",
    "    ret, image2= cv2.threshold(image2,overlap_num,1,cv2.THRESH_BINARY) \n",
    "    return image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bone Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "def sharpen(image,factor):\n",
    "    '''\n",
    "    This function sharpens the input images by enhancing their sharpness using a specified factor\n",
    "    '''\n",
    "    sharpened=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "\n",
    "        cf=image[i].copy() \n",
    "        cf=Image.fromarray(cf, mode=None)\n",
    "        enhancer = ImageEnhance.Sharpness(cf) #make border of cortical bone sharper\n",
    "\n",
    "        sharpened[i]=enhancer.enhance(factor) \n",
    "    return sharpened\n",
    "\n",
    "\n",
    "def get_boneprep(image):\n",
    "    '''This function prepares bone images by applying various filters and processing steps to enhance bone structures and remove noise\n",
    "    '''\n",
    "    k=14\n",
    "    bone_prep=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    bone_ots=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    subcfatmask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    bone_prep_th=[]\n",
    "\n",
    "\n",
    "    bone_prep=sharpen(image,5.0) \n",
    "    bone_prep=apply_CurvatureFilter(bone_prep, Ivol8c_roi) \n",
    "\n",
    "    subcfatmask=musc_fat_mask-musc_mask_final \n",
    "    for i in range(j):\n",
    "    \n",
    "        bone_prep[i] = cv2.bilateralFilter(bone_prep[i],15,20,45) \n",
    "            \n",
    "            \n",
    "        bone_prep_th.append([])\n",
    "        bone_prep_th[i]=multi_otsu_1(bone_prep[i])\n",
    "        bone_prep[i]=bone_prep[i]>bone_prep_th[i]\n",
    "\n",
    "            \n",
    "        bone_prep[i]=bone_prep[i]-subcfatmask[i]\n",
    "        bone_prep[i][bone_prep[i]>1] = 0 \n",
    "            \n",
    "\n",
    "        bone_prep[i] = (morphology.remove_small_holes(bone_prep[i],area_threshold=100, connectivity=1)) \n",
    "\n",
    "        bone_prep[i] = label(bone_prep[i])\n",
    "\n",
    "        bone_prep[i] = (morphology.remove_small_objects(bone_prep[i],min_size=30, connectivity=1))    \n",
    "        \n",
    "        \n",
    "        th, bone_prep[i] = cv2.threshold(bone_prep[i], 0, 1, cv2.THRESH_BINARY)\n",
    "   \n",
    "            \n",
    "    return bone_prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Z_connectivity_w_adj(image):\n",
    "    '''\n",
    "    This function checks the Z-connectivity among slices in a set of images with their adjacent slices and separates Z-connected parts from non-Z parts\n",
    "    '''\n",
    "    nonZ=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    Z=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        if i==0: #if first slice only add with next slice\n",
    "            combined_w_next=image[i+1]+image[i]\n",
    "            ret, fatconnectedparts_next= cv2.threshold(combined_w_next,1,1,cv2.THRESH_BINARY)\n",
    "            z_connection=fatconnectedparts_next\n",
    "\n",
    "        elif i==(j-1): #if last slice only add with prev slice\n",
    "            combined_w_prev=image[i-1]+image[i]\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(combined_w_prev,1,1,cv2.THRESH_BINARY) #must match both adj slices\n",
    "            z_connection=fatconnectedparts_prev\n",
    "        else: #add with both prev and next slice\n",
    "            combined_w_prev=image[i-1]+image[i]\n",
    "            combined_w_next=image[i]+image[i+1]\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(combined_w_prev,1,1,cv2.THRESH_BINARY)\n",
    "            ret, fatconnectedparts_next= cv2.threshold(combined_w_next,1,1,cv2.THRESH_BINARY)\n",
    "\n",
    "            z_connection=fatconnectedparts_prev+fatconnectedparts_next\n",
    "            ret, z_connection= cv2.threshold(z_connection,1,1,cv2.THRESH_BINARY) \n",
    "\n",
    "        #find XY connections to Z connected parts\n",
    "        coordinates= np.argwhere(z_connection==1)     \n",
    "            \n",
    "        im_ff=image[i].copy() \n",
    "        h, w = im_ff.shape[:2] \n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "        for item in range(len(coordinates)): #floodfill in the coordinates of z-connectivity \n",
    "            cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "\n",
    "        #Remove small islands for Non-Z parts\n",
    "        nonZ[i]=(im_ff==1)\n",
    "   \n",
    "        Z[i] = (im_ff==2)\n",
    "        \n",
    "    return Z,nonZ\n",
    "\n",
    "\n",
    "def Z_connectivity_w_one(image, image2): \n",
    "    '''\n",
    "    This function checks the Z-connectivity of slices in a set of images with one other image and separates Z-connected parts from non-Z parts\n",
    "    '''\n",
    "    nonZ=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    Z=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):     \n",
    "        combined=image[i]+image2\n",
    "        ret, z_connection= cv2.threshold(combined,1,1,cv2.THRESH_BINARY)\n",
    "        z_connection=z_connection\n",
    "        \n",
    "        #find XY connections to Z connected parts\n",
    "        coordinates= np.argwhere(z_connection==1)    \n",
    "            \n",
    "        im_ff=image[i].copy()  \n",
    "        h, w = im_ff.shape[:2] \n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "        for item in range(len(coordinates)): #floodfill in the coordinates of z-connectivity \n",
    "            cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "\n",
    "        #Remove small islands for Non-Z parts\n",
    "        nonZ[i]=(im_ff==1)\n",
    "        Z[i] = (im_ff==2)\n",
    "         \n",
    "    return Z,nonZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find potential bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_mid_coord_one(image,y,x):  \n",
    "    '''\n",
    "    This function applies a flood fill operation starting from a specific coordinate (y, x) in the input image and returns the resulting filled area\n",
    "    '''\n",
    "    coord_applied=(image.copy()).astype(np.uint8)\n",
    "    h, w = coord_applied.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    cv2.floodFill(coord_applied, mask, (y,x), 2)\n",
    "\n",
    "    coord_applied=(coord_applied==2).astype(np.uint8)\n",
    "    return coord_applied\n",
    "\n",
    "\n",
    "def get_centroid(image):\n",
    "    '''\n",
    "    This function finds the centroid of the image\n",
    "    '''\n",
    "    coords= np.argwhere(image>0)  \n",
    "    x = [p[0] for p in coords]\n",
    "    y = [p[1] for p in coords]\n",
    "    centroid = [round(sum(x) / len(coords)), round(sum(y) / len(coords))] \n",
    "    return centroid\n",
    "\n",
    "def find_potentialbone(image):\n",
    "    '''\n",
    "    This function identifies potential bone regions in the input image by finding contours, filtering them based on area and circularity criteria, and applying flood fill operations\n",
    "    '''\n",
    "    contour_coords_L1=[]\n",
    "    contour_coords_L2=[]\n",
    "    bonemwvol=[]\n",
    " \n",
    "    test1=[]\n",
    "    test2=[]\n",
    "  \n",
    "    zeros=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "    \n",
    "    zeros1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    zeros2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "\n",
    "    k=0\n",
    "    for i in range(j):\n",
    "        contour_coords_L1.append([])\n",
    "        contour_coords_L2.append([])\n",
    "        bonemwvol.append([])\n",
    "        \n",
    "        test1.append([])\n",
    "        test2.append([])\n",
    "\n",
    "    \n",
    "        a, b =  cv2.findContours(image[i], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "        contour_coords_L1[i].append(a) #list of contours for all slices (each index = list for each slice)\n",
    "        for contour in contour_coords_L1[i][0]: \n",
    "            test1[i] = cv2.drawContours(zeros1[i], contour_coords_L1[i][0],  -1, (1,0,0), 1)\n",
    "            test1[i]=floodfill(test1[i]) \n",
    "            approx = cv2.arcLength(contour,True)\n",
    "            area = cv2.contourArea(contour) \n",
    "            (x,y),radius = cv2.minEnclosingCircle(contour) \n",
    "\n",
    "            radius = int(radius)\n",
    "            a=0.8*(radius**2) #keep objects that resemble 80% of a circular shape\n",
    "            b=0.5*(radius*approx)//2 \n",
    "        \n",
    "            if (area>a) & (area>b) & (area>30):  \n",
    "                contour_coords_L2[i].append(contour) #append the contours that meet the criteria\n",
    "                test2[i] = cv2.drawContours(zeros2[i], contour_coords_L2[i],  -1, (1,0,0), 1) \n",
    "        bonemwvol=test2\n",
    "    \n",
    "\n",
    "    \n",
    "    bonemwvol=floodfillall(bonemwvol) \n",
    "    \n",
    "    \n",
    "    \n",
    "    return bonemwvol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biggest_obj(image): #must be LABELLED image\n",
    "    '''\n",
    "    This function takes a labeled image as input and returns the largest object (with the maximum sum of pixel values) from the labeled image\n",
    "    '''\n",
    "    channels_isolated=[] \n",
    "\n",
    "    for i in range(np.amax(image)):\n",
    "        channels_isolated.append((image==i+1).astype(np.uint8))\n",
    "\n",
    "    sum_channel_L=[]\n",
    "    for i in range(np.amax(image)):\n",
    "        sum_channel_L.append([])\n",
    "        sum_channel_L[i]=np.sum(channels_isolated[i])\n",
    "\n",
    "    sum_channel_L2=sum_channel_L.copy()\n",
    "    largest_sum = max(sum_channel_L2)  \n",
    "\n",
    "\n",
    "    for i in range(np.amax(image)):\n",
    "        if sum_channel_L[i]==largest_sum: \n",
    "            largest_obj=channels_isolated[i]\n",
    "\n",
    "    return  largest_obj\n",
    "\n",
    "\n",
    "def find_potentialbone2(image1): \n",
    "    '''\n",
    "    This function identifies potential bone regions from a labeled image by finding the largest connected object in each slice of the labeled image. It then divides the slices into two halves and combines the largest objects from each half to obtain a final potential bone region\n",
    "    '''\n",
    "    z_labelled=label(image1>0).astype(np.uint8) \n",
    "        \n",
    "    tib=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        tib[i]=get_biggest_obj(z_labelled[i])  #get biggest obj from boneprep_Z_labelled \n",
    "    \n",
    "    #=======================================Divide slices in half===============================================#\n",
    "    \n",
    "    #Slice number\n",
    "    j1=round(j/2)\n",
    "    j2=j-j1\n",
    "\n",
    "    #Tib\n",
    "    tib1=tib[:j1,:,:]\n",
    "    tib2=tib[j1:,:,:]\n",
    "    \n",
    "    #bone-prep - needed when apply coordinates for fib\n",
    "    bone_prep1=bone_prep[:j1,:,:]\n",
    "    bone_prep2=bone_prep[j1:,:,:] \n",
    "\n",
    "    #Ivol8c_roi - needed for overlaying to check later\n",
    "    Ivol8c_roi1=Ivol8c_roi[:j1,:,:] \n",
    "    Ivol8c_roi2=Ivol8c_roi[j1:,:,:]\n",
    "\n",
    "    \n",
    "    #===========Add HALF of the images separately =========#\n",
    "\n",
    "\n",
    "    #-----TIBIA----#\n",
    "    tib1_added=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "    tib2_added=np.zeros([Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "    \n",
    "    for i in range(j1):\n",
    "        tib1_added+=tib1[i]\n",
    "    for i in range(j2):\n",
    "        tib2_added+=tib2[i]\n",
    "    \n",
    "    tib1_added_keep=label(tib1_added==np.amax(tib1_added)) #keep pixels that overlap at least for ALL slices\n",
    "    tib2_added_keep=label(tib2_added==np.amax(tib2_added))\n",
    "\n",
    "    \n",
    "    tib1_added_keep=get_biggest_obj(tib1_added_keep) #sometimes portion of tib is separated, results in two obj - take bigger obj\n",
    "    tib2_added_keep=get_biggest_obj(tib2_added_keep)  \n",
    "    \n",
    "    \n",
    "    #====================Get mid-point coords of tib and fib - use as seed for floodfill on bone_prep=======================================#\n",
    "    tib1_mid_coord=get_centroid(tib1_added_keep)\n",
    "    tib2_mid_coord=get_centroid(tib2_added_keep)\n",
    "\n",
    "    \n",
    "\n",
    "    bone_prep1_copy=bone_prep1.copy() \n",
    "    bone_prep2_copy=bone_prep2.copy() \n",
    "    \n",
    "\n",
    "     #------------TIBIA-------------------------#\n",
    "\n",
    "    #apply coord on image of interest    \n",
    "    tibmarrow1=bone_prep1.copy()\n",
    "    tibmarrow2=bone_prep2.copy()\n",
    "    \n",
    "    k=0\n",
    "    \n",
    "    for i in range(j1):\n",
    "        tibmarrow1[i]=apply_mid_coord_one(tibmarrow1[i],tib1_mid_coord[1],tib1_mid_coord[0]) \n",
    "    for i in range(j2):\n",
    "        tibmarrow2[i]=apply_mid_coord_one(tibmarrow2[i],tib2_mid_coord[1],tib2_mid_coord[0])\n",
    "\n",
    "            \n",
    "    #===================================ADD ISOLATED TIBS + FIBS======================================================================================\n",
    "\n",
    "\n",
    "    tib_final=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    i2=0 #need new counter for second half of slices\n",
    "    for i in range(j):\n",
    "        if i<j1:#if part of first half of slices\n",
    "            tib_final[i]=tibmarrow1[i]\n",
    "        else: #if part of second half of slices\n",
    "            tib_final[i]=tibmarrow2[i2]\n",
    "            i2+=1\n",
    "\n",
    "    return tib_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get cortical bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def corticaloutline(image): \n",
    "    '''\n",
    "    This function extracts the outline of the cortical bone from an input image, isolating the cortical bone region and removing noise\n",
    "    '''\n",
    "    cortical=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        th0=multi_otsu_0(image[i]) \n",
    "        cortical[i]=label(image[i]>th0) \n",
    "        ret, cortical[i] = cv2.threshold(cortical[i],0,1,cv2.THRESH_BINARY) \n",
    "        cortical[i] = (morphology.remove_small_holes(cortical[i],area_threshold=20, connectivity=1)) #remove noise, isolate cortical bone \n",
    "        \n",
    "    return cortical\n",
    "\n",
    "\n",
    "def merge_bones(cortical_mask,bonem_mask):   \n",
    "    '''\n",
    "    This function merges the cortical bone mask and the bone marrow mask, isolating the cortical bone region while removing any overlapping regions with the bone marrow\n",
    "    '''\n",
    "    k=8\n",
    "\n",
    "    #=========== TIBIA REMOVAL==========#\n",
    "    \n",
    "    corticalt=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "\n",
    "    bonem_mask_dilated=cv2.dilate(bonem_mask,np.ones((5,5),np.uint8),iterations = 1) #minimize obj left behind after subtraction\n",
    "    \n",
    "    t_bone=cortical_mask-bonem_mask_dilated\n",
    "    t_bone[t_bone>1]=0\n",
    "   \n",
    "    \n",
    "    for i in range(j):   \n",
    "        corticalt[i] = (morphology.remove_small_holes(label(t_bone[i]),area_threshold=30, connectivity=0)) #get rid of lines \n",
    "\n",
    "\n",
    "        corticalt[i] = (morphology.remove_small_objects(label(corticalt[i]),min_size=1500, connectivity=0)) #remove white stuff in cortical bone \n",
    "  \n",
    "        corticalt[i] = (morphology.remove_small_objects(label(corticalt[i]),min_size=1500, connectivity=0)) #remove white stuff in cortical bone \n",
    "     \n",
    "        corticalt[i]=cv2.morphologyEx(corticalt[i], cv2.MORPH_CLOSE, np.ones((7,7),np.uint8)) #get rid of remaining holes  \n",
    "     \n",
    "    corticalt_final=floodfillall(corticalt)\n",
    "    \n",
    "    #if more than 1 obj - take the largest \n",
    "    labelled=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j):\n",
    "        num_obj,labelled[i]=cv2.connectedComponents(corticalt_final[i])\n",
    "        if num_obj>2: #if more than just 2 obj (background + 1 bone)\n",
    "            corticalt_final[i]=get_biggest_obj(label(corticalt_final[i])) #must be labelled\n",
    "       \n",
    "            \n",
    "        else:\n",
    "            corticalt_final[i]=corticalt_final[i]\n",
    "    \n",
    "    corticalt_final=cv2.morphologyEx(corticalt_final, cv2.MORPH_CLOSE, np.ones((7,7),np.uint8)) \n",
    "    \n",
    " \n",
    "    return corticalt_final\n",
    "\n",
    "def get_roi(musc_mask,bone_mask,image):\n",
    "    '''\n",
    "    This function extracts the region of interest (ROI) from an input image based on the muscle mask and bone mask\n",
    "    '''\n",
    "    roi_mask=musc_mask-bone_mask \n",
    "    roi_mask[roi_mask>1] = 0 \n",
    "    ret, roi_mask = cv2.threshold(roi_mask,0,1,cv2.THRESH_BINARY)\n",
    "    \n",
    "    roi=roi_mask*image\n",
    "    return roi_mask, roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> ITSA 1st Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_th(image):\n",
    "    '''\n",
    "    This function calculates the initial threshold values for optimization using multi-otsu thresholding for each slice of the input image\n",
    "    '''\n",
    "    initial_th=[]\n",
    "\n",
    "    for i in range(j):\n",
    "        initial_th.append([])\n",
    "        initial_th[i]=multi_otsu_1(image[i]) \n",
    "\n",
    "    return initial_th\n",
    "\n",
    "def ITSA_no_Z(roivar, ots,size): \n",
    "    '''\n",
    "    This function implements the ITSA (Iterative Threshold Selection Algorithm) without Z-connectivity check. \n",
    "    It iteratively adjusts the threshold value based on the mean signal intensity of the muscle and fat regions until convergence\n",
    "    '''\n",
    "\n",
    "    k=1\n",
    "    ThPrev=0\n",
    "    ThRev=ots  \n",
    "\n",
    "    ThPrevlist=[ThPrev]  \n",
    "    ThRevlist=[ThRev] \n",
    "\n",
    "    klist=[0] \n",
    "    matchlist=[] \n",
    "    while ThRev!=ThPrev: \n",
    "        \n",
    "        ThPrev=ThRev\n",
    "        \n",
    "        prefatmask = label(roivar>ThRev) \n",
    "        prefatmask = np.uint8(prefatmask) \n",
    "        prefatmask = (morphology.remove_small_objects(prefatmask,min_size=size, connectivity=1))\n",
    "        ret, fatmask = cv2.threshold(prefatmask,0,1,cv2.THRESH_BINARY)\n",
    "  \n",
    "        fatseg = fatmask*roivar \n",
    "        preMuscSegM=roivar-fatseg \n",
    "        MuscSegM=np.ma.masked_where(preMuscSegM == 0, preMuscSegM)\n",
    "        FatSegM=np.ma.masked_where(fatseg==0,fatseg) \n",
    "        MuscSegI=np.mean(MuscSegM) \n",
    "        FatSegI=np.mean(FatSegM)\n",
    "        ThRev=(1+((FatSegI-MuscSegI)/FatSegI))*MuscSegI \n",
    "        \n",
    "        ThPrevlist.append(ThPrev) \n",
    "        ThRevlist.append(ThRev) \n",
    "        klist.append(k) \n",
    "        matchlist.append(\"No\") \n",
    "        k+=1\n",
    "        if k==50:\n",
    "            break\n",
    "       \n",
    "        if ThRev==ThPrev:\n",
    "            matchlist.append(\"Yes\")\n",
    "            table=QTable([klist,ThPrevlist,ThRevlist,matchlist],\n",
    "            names=('Iteration','ThPrev','ThRev','ThRev=ThPrev?'))\n",
    "  \n",
    "\n",
    "            x=klist \n",
    "            y=ThRevlist\n",
    "\n",
    "    return fatmask, fatseg, ThRev \n",
    "      \n",
    "def print_th(th):\n",
    "    '''\n",
    "    This function prints all threshold values\n",
    "    '''\n",
    "    for i in range(j):\n",
    "        print (f\"Slice {i+1} th = {th[i]}\") \n",
    "        \n",
    "def apply_ITSA_no_Z(image,initial_th,size):\n",
    "    '''\n",
    "    This function applies the ITSA without Z-connectivity check to each slice of the input image using the initial threshold values calculated previously\n",
    "    '''\n",
    "    fatseg_mask=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    optimized_th_L=[] #optimized thresholds\n",
    "    \n",
    "    for i in range(j): \n",
    "        fatseg_mask[i],fatseg[i],ThRev=ITSA_no_Z(image[i], initial_th[i],size)\n",
    "        optimized_th_L.append(ThRev) \n",
    "        \n",
    "    return optimized_th_L,fatseg_mask,fatseg\n",
    "\n",
    "\n",
    "def subtract_fat1(fat1):\n",
    "    '''\n",
    "    This function subtracts the fat region obtained from the initial thresholding from the input image to obtain the region for further processing\n",
    "    '''\n",
    "    roi_for_S1R2=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    roi_for_S1R2=roi-fat1 \n",
    "    return roi_for_S1R2\n",
    "\n",
    "def fatfinal_S1R1(roivar,th,size): \n",
    "    '''\n",
    "    This function applies the final thresholding to obtain the fat region after subtracting the initial fat region from the input image\n",
    "    '''\n",
    "    fat1_mask=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat1=np.empty([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        fat1_mask[i] = label(roivar[i]>th[i]) \n",
    "        fat1_mask[i] = np.uint8(fat1_mask[i]) \n",
    "        fat1_mask[i] = (morphology.remove_small_objects(fat1_mask[i],min_size=size, connectivity=1)).astype(int)\n",
    "        ret, fat1_mask[i] = cv2.threshold(fat1_mask[i],0,1,cv2.THRESH_BINARY) \n",
    "\n",
    "        fat1[i]= fat1_mask[i]*roivar[i]   \n",
    "\n",
    "    return fat1_mask,fat1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> ITSA 2nd Round "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_th(th, image): \n",
    "    '''\n",
    "    This function applies the threshold values obtained from optimization to the input image to generate binary masks for z-connectivity checking\n",
    "    '''\n",
    "    zcheck=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    for i in range(j): \n",
    "        zcheck[i]=(image[i]>th[i]).astype(int)\n",
    "    return zcheck\n",
    "\n",
    "\n",
    "def get_final_fatsegs_S1(fatfinal,th,fatfinal_mask,image):  \n",
    "    '''\n",
    "    This function retrieves the final fat segments from Set 1 without removing objects by comparing the fat region obtained after applying the optimized threshold values to the input image with the initial fat region\n",
    "    '''\n",
    "    fat2_mask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "\n",
    "    fat1_mask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "\n",
    "    for i in range(j):\n",
    "        fat1_mask[i]=fatfinal[i]>th[i] \n",
    "        \n",
    "        fat2_mask[i]= (fat1_mask[i]!=fatfinal_mask[i])\n",
    "\n",
    "        \n",
    "        fat1[i]=fat1_mask[i]*image[i]\n",
    "        fat2[i]=fat2_mask[i]*image[i]\n",
    "        \n",
    "    return fat1_mask,fat1,fat2_mask,fat2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ITSA_w_Z(i, roivar, initial_th, zcheck,size): \n",
    "    '''\n",
    "    This function performs the Improved Threshold Selection Algorithm (ITSA) with Z-connectivity check for a specific slice i of the input image. \n",
    "    It iteratively adjusts the threshold value based on fat and muscle intensities and ensures Z-connectivity by incorporating neighboring slices\n",
    "    '''\n",
    "    k=1\n",
    "    ThPrev_S2=0 \n",
    "    ThRev_S2= initial_th[i] \n",
    "\n",
    "    x=0\n",
    "    y=0\n",
    "    \n",
    "    ThPrevlist=[ThPrev_S2]  \n",
    "    ThRevlist=[ThRev_S2] \n",
    "\n",
    "    klist=[0] \n",
    "    matchlist=[] \n",
    "    \n",
    "    FatInt_L=[\"N/A\"]\n",
    "    MuscInt_L=[\"N/A\"]\n",
    "   \n",
    "    \n",
    "    while ThRev_S2!=ThPrev_S2:\n",
    "        ThPrev_S2=ThRev_S2  \n",
    "        prefatmask_S2 = (roivar[i]>ThRev_S2)\n",
    "        prefatmask_S2 = np.uint8(prefatmask_S2)\n",
    "        ret, fatmask_S2 = cv2.threshold(prefatmask_S2,0,1,cv2.THRESH_BINARY) \n",
    "\n",
    "        if i==0:\n",
    "            fatcombined_next=zcheck[i+1]+fatmask_S2\n",
    "            ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "            z_connection=fatconnectedparts_next\n",
    "   \n",
    "        elif i==(j-1):\n",
    "            fatcombined_prev=zcheck[i-1]+fatmask_S2\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "            z_connection=fatconnectedparts_prev\n",
    "   \n",
    "        else:\n",
    "            fatcombined_prev=zcheck[i-1]+fatmask_S2\n",
    "            fatcombined_next=fatmask_S2+zcheck[i+1]\n",
    "            ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "            ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "\n",
    "            z_connection=fatconnectedparts_prev+fatconnectedparts_next\n",
    "            ret, z_connection= cv2.threshold(z_connection,0,1,cv2.THRESH_BINARY) \n",
    "        \n",
    "        #find XY connections to Z connected parts\n",
    "        coordinates= np.argwhere(z_connection ==1) \n",
    "        \n",
    "        \n",
    "        im_ff=fatmask_S2.copy()\n",
    "        h, w = im_ff.shape[:2] \n",
    "        mask = np.zeros((h+2, w+2), np.uint8)\n",
    "        for item in range(len(coordinates)):\n",
    "            cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "        \n",
    "        #Remove small islands for Non-Z parts\n",
    "        nonZ =label(im_ff==1)\n",
    "        nonZ_keep = (morphology.remove_small_objects(nonZ,min_size=size, connectivity=1))\n",
    "        ret, nonZ_keep= cv2.threshold(np.uint8(nonZ_keep),0,1,cv2.THRESH_BINARY)\n",
    "\n",
    "        Z = (im_ff==2)\n",
    "  \n",
    "        \n",
    "        prefatseg1_S2=(Z+nonZ_keep) \n",
    "        fatseg1_S2=prefatseg1_S2*roivar[i]\n",
    "        \n",
    "        \n",
    "        #Fat and Muscle Quantification\n",
    "\n",
    "        preMuscSegP_S2=roivar[i]-fatseg1_S2\n",
    "        \n",
    "        MuscSegP_S2=np.ma.masked_where(preMuscSegP_S2 == 0, preMuscSegP_S2)\n",
    "        FatSegP_S2=np.ma.masked_where(fatseg1_S2==0,fatseg1_S2) \n",
    "        MuscSegI_S2=np.mean(MuscSegP_S2)\n",
    "        FatSegI_S2=np.mean(FatSegP_S2)\n",
    "        \n",
    "        \n",
    "        if type(FatSegI_S2)== np.ma.core.MaskedConstant:\n",
    "            ThRev_S2=ThPrev_S2\n",
    "        else:\n",
    "            ThRev_S2=(1+((FatSegI_S2-MuscSegI_S2)/FatSegI_S2))*MuscSegI_S2 \n",
    "        \n",
    "         \n",
    "        ThPrevlist.append(ThPrev_S2) \n",
    "        ThRevlist.append(ThRev_S2)\n",
    "        klist.append(k) \n",
    "        matchlist.append(\"No\")\n",
    "        \n",
    "       \n",
    "        FatInt_L.append(FatSegI_S2)\n",
    "        \n",
    "        MuscInt_L.append(MuscSegI_S2)\n",
    "\n",
    "        \n",
    "        k+=1\n",
    "        if k==50:\n",
    "            break\n",
    "            \n",
    "        if ThRev_S2==ThPrev_S2:\n",
    "            matchlist.append(\"Yes\")\n",
    "            table=QTable([klist,ThPrevlist,ThRevlist,matchlist],\n",
    "            names=('Iteration','ThPrev_S2','ThRev_S2','ThRev_S2=ThPrev_S2?'))\n",
    "\n",
    "    thresholds_S2=ThRev_S2\n",
    "    \n",
    "    return prefatseg1_S2, fatseg1_S2, thresholds_S2\n",
    "\n",
    "\n",
    "def apply_ITSA_w_Z(roivar, initial_th, zcheck,size):\n",
    "    '''\n",
    "    This function applies the ITSA with Z-connectivity check to all slices of the input image and returns the optimized threshold values and segmented fat regions\n",
    "    '''\n",
    "    fatseg_mask =np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg =np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8') \n",
    "\n",
    "    optimized_th_L =[] \n",
    "    for i in range(j):\n",
    "        optimized_th_L .append([])\n",
    "        fatseg_mask[i],fatseg[i], optimized_th_L[i]=ITSA_w_Z(i, roivar,initial_th,zcheck,size)  \n",
    "    return optimized_th_L,fatseg_mask,fatseg   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Z-Connectivity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_zcheck(i,th,zcheck,size): \n",
    "    '''\n",
    "    This function performs the final Z-connectivity check for slice i after applying the optimized threshold value th[i] and considering neighboring slices' fat masks represented by zcheck\n",
    "    '''\n",
    "    prefatmask_R3 = (roi[i]>th[i]) \n",
    "\n",
    "    fatmask_R3 = np.uint8(prefatmask_R3)\n",
    "    \n",
    "    if i==0:\n",
    "        fatcombined_next=zcheck[i+1]+fatmask_R3\n",
    "        ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "        z_connection=fatconnectedparts_next      \n",
    "    elif i==(j-1):\n",
    "        fatcombined_prev=zcheck[i-1]+fatmask_R3  \n",
    "        ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "        z_connection=fatconnectedparts_prev    \n",
    "    else:\n",
    "        fatcombined_prev=zcheck[i-1]+fatmask_R3\n",
    "        fatcombined_next=zcheck[i+1]+fatmask_R3 \n",
    "\n",
    "        ret, fatconnectedparts_prev= cv2.threshold(fatcombined_prev,1,1,cv2.THRESH_BINARY)\n",
    "        ret, fatconnectedparts_next= cv2.threshold(fatcombined_next,1,1,cv2.THRESH_BINARY)\n",
    "\n",
    "        z_connection=fatconnectedparts_prev+fatconnectedparts_next\n",
    "        ret, z_connection= cv2.threshold(z_connection,0,1,cv2.THRESH_BINARY)      \n",
    "\n",
    "        \n",
    "    coordinates= np.argwhere(z_connection ==1)      \n",
    "    im_ff=fatmask_R3.copy()\n",
    "    h, w = im_ff.shape[:2] \n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    for item in range(len(coordinates)):\n",
    "        cv2.floodFill(im_ff, mask, (coordinates[item][1],coordinates[item][0]), 2)\n",
    "\n",
    "    #Remove small islands for Non-Z parts\n",
    "    nonZ =label(im_ff==1)\n",
    "    nonZ_keep = (morphology.remove_small_objects(nonZ,min_size=size, connectivity=1))\n",
    "    ret, nonZ_keep= cv2.threshold(np.uint8(nonZ_keep),0,1,cv2.THRESH_BINARY)\n",
    "\n",
    "    Z = (im_ff==2)\n",
    "   \n",
    "    final_fat_mask=(Z+nonZ_keep) \n",
    "    final_fat=final_fat_mask*Ivol8c_roi[i] \n",
    "\n",
    "  \n",
    "    return final_fat_mask, final_fat\n",
    "\n",
    "def apply_final_zcheck(th,zcheck,size):\n",
    "    '''\n",
    "    This function applies the final Z-connectivity check to all slices using the optimized threshold values and Z-connectivity masks, resulting in the final segmented fat masks and fat regions\n",
    "    '''\n",
    "    fat_mask=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fat=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    for i in range(j):\n",
    "        fat_mask[i], fat[i]=final_zcheck(i,th,zcheck,size) \n",
    "\n",
    "    return  fat_mask, fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_fatsegs(fatfinal,th,fatfinal_mask,image):\n",
    "    '''\n",
    "    This function calculates the final segmented fat masks (fatseg_mask_final_R1 and fatseg_mask_final_R2) and fat regions (fatseg_final_R1 and fatseg_final_R2) based on the optimized threshold values th applied to the final fat segmentation result fatfinal. \n",
    "    It considers the 3D connectivity check and the difference between the final fat mask and the initial fat mask\n",
    "    '''\n",
    "    fatseg_mask_final_R1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg_final_R1=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    \n",
    "    fatseg_final_R2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "    fatseg_mask_final_R2=np.zeros([Ivol8c_roi.shape[0], Ivol8c_roi.shape[1], Ivol8c_roi.shape[2]], dtype='uint8')\n",
    "\n",
    "    for i in range(j):\n",
    "        fatseg_mask_final_R1[i]=fatfinal[i]>th[i] \n",
    "        fatseg_mask_final_R2[i]= (fatseg_mask_final_R1[i]!=fatfinal_mask[i])\n",
    "\n",
    "        fatseg_final_R1[i]=fatseg_mask_final_R1[i]*image[i]\n",
    "        fatseg_final_R2[i]=fatseg_mask_final_R2[i]*image[i]\n",
    "    \n",
    "    return fatseg_mask_final_R1,fatseg_final_R1,fatseg_mask_final_R2,fatseg_final_R2\n",
    "\n",
    "\n",
    "def overlay_TWO_SEP(f1,f2,image):\n",
    "    '''\n",
    "    This function overlays the segmented fat regions f1 and f2 on the original image image for visualization purposes. \n",
    "    It plots each slice of the image along with the overlaid fat regions in separate subplots\n",
    "    '''\n",
    "    def overlayTWO_1(image, f1,f2,x):    \n",
    "        overlay = np.ma.masked_where(f1 == 0, f1)\n",
    "        overlay2= np.ma.masked_where(f2 == 0, f2)\n",
    "        axs[x,1].imshow(image, cmap=\"bone\")\n",
    "        axs[x,1].imshow(overlay, cmap=\"autumn\", vmin=0, vmax=1)\n",
    "        axs[x,1].imshow(overlay2, cmap=\"bwr\", vmin=0, vmax=1, alpha=1)\n",
    "        axs[x, 1].set_title(f\"slice {i+1}\", fontsize=12)\n",
    "    fig, axs = plt.subplots(j, 2, figsize=(12, 100))\n",
    "    for i in range(j):\n",
    "        axs[i,0].imshow(image[i], cmap='bone')\n",
    "        overlayTWO_1(image[i],f1[i], f2[i],i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Quality check and tag export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_buttons(ID,slic):\n",
    "    '''\n",
    "    This function is used to create buttons to identify which masks need manual adjustments\n",
    "    '''\n",
    "    ID = ID\n",
    "    slic = slic\n",
    "\n",
    "    def record_click(button_clicked):\n",
    "        # Create a dictionary with the data to be recorded\n",
    "        new_entry = {\n",
    "            'ID': ID,\n",
    "            'slice': slic,\n",
    "            'Button Clicked': button_clicked\n",
    "        }\n",
    "\n",
    "        # Append the new entry to the DataFrame\n",
    "        data.loc[len(data)] = new_entry\n",
    "    # Create a button for each case\n",
    "    button_a = widgets.Button(description=\"Good\")\n",
    "    button_b = widgets.Button(description=\"Overshoot\")\n",
    "    button_c = widgets.Button(description=\"Undershoot\")\n",
    "    button_d = widgets.Button(description=\"Incorrect Thigh Cut\")\n",
    "\n",
    "    # Attach the click event handlers for buttons A and B\n",
    "    def button_a_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Good\"\n",
    "        record_click(button_clicked)\n",
    "\n",
    "    def button_b_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Overshoot\"\n",
    "        record_click(button_clicked)\n",
    "\n",
    "    def button_c_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Undershoot\"\n",
    "        record_click(button_clicked)\n",
    "\n",
    "    def button_d_click(_):\n",
    "        global button_clicked\n",
    "        button_clicked = \"Incorrect Thigh Cut\"\n",
    "        record_click(button_clicked)\n",
    "        \n",
    "    button_a.on_click(button_a_click)\n",
    "    button_b.on_click(button_b_click)\n",
    "    button_c.on_click(button_c_click)\n",
    "    button_d.on_click(button_d_click)\n",
    "\n",
    "    # Display the buttons\n",
    "    display(button_a)\n",
    "    display(button_b)\n",
    "    display(button_c)\n",
    "    display(button_d)\n",
    "\n",
    "    # Initialize the button_clicked variable\n",
    "    button_clicked = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check(image1, image2, ID):\n",
    "    '''\n",
    "    This function overlays 2 images to check the quality of the masks created and identify those that need manual edits\n",
    "    '''\n",
    "    def check(im, to_overlay):\n",
    "        overlay = np.ma.masked_where(to_overlay == 0, to_overlay)\n",
    "        plt.imshow(im, cmap=\"bone\")\n",
    "        plt.imshow(overlay, cmap=\"hsv\", vmin=0, vmax=1, alpha=0.5)\n",
    "        plt.title(f\"{ID}\", fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "    j = len(image1)  \n",
    "\n",
    "    for i in range(j):\n",
    "        check(image1[i], image2[i])\n",
    "\n",
    "        quality_buttons(ID,i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import errno \n",
    "import shutil\n",
    "\n",
    "def writetag():\n",
    "    '''\n",
    "    This function generates a tag file and saves it to a specified directory. \n",
    "    The tag file contains metadata and pixel data extracted from an input image array\n",
    "    '''\n",
    "    \n",
    "    volsitk.GetOrigin()\n",
    "    epais = 0.0 \n",
    "    org_x = volsitk.GetOrigin()[0]\n",
    "    org_y = volsitk.GetOrigin()[1]\n",
    "    org_z = 0 \n",
    "    org_x, org_y, org_z\n",
    "    dimx = volsitk.GetSize()[0]\n",
    "    dimy = volsitk.GetSize()[1]\n",
    "    dimz = 1\n",
    "    inc_x = inc_y = 1\n",
    "    \n",
    "    dir_h_x=1.0000\n",
    "    dir_h_y=0.0000\n",
    "    dir_h_z=0.0000\n",
    "    dir_v_x=0.0000\n",
    "    dir_v_y=1.0000\n",
    "    dir_v_z=0.0000\n",
    "\n",
    "    imfmscb = []\n",
    "    for j in range(imfbonemsc.shape[0]):\n",
    "        for i in range(imfbonemsc.shape[1]): \n",
    "            imfmscb.append(imfbonemsc[j,i])\n",
    "    imfmscbytes = bytes(np.uint8(np.array(imfmscb)))\n",
    "\n",
    "    serdesc = \"Exp_\"+stid\n",
    "    \n",
    "    drive = r'D:\\OAI_Costa\\Tags_need' #***change to directory you want images and tags saved to\n",
    "    outtag = os.path.join(drive, \"ToSegmentBW\", stid, \"OutputTags\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(outtag)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise   \n",
    "    file = open(outtag+\"\\\\\"+serdesc+\"_org\"+str(slc)+\".tag\", \"wb\")\n",
    "\n",
    "    header = \\\n",
    "    \"x:\"+str(dimx)+\" \"+ \\\n",
    "    \"y:\"+str(dimy)+\" \"+ \\\n",
    "    \"z:\"+str(dimz)+\" \"+ \\\n",
    "    \"type:BYTE \\n\" + \\\n",
    "    \"org_x:\"+str(org_x)+\" \"+ \\\n",
    "    \"org_y:\"+str(org_y)+\" \"+ \\\n",
    "    \"org_z:\"+str(org_z)+\" \\n\"+ \\\n",
    "    \"inc_x:\"+str(inc_x)+\" \"+ \\\n",
    "    \"inc_y:\"+str(inc_y)+\" \"+ \\\n",
    "    \"epais:\"+str(epais)+\" \\n\"+ \\\n",
    "    \"dir_h_x:1.0000     dir_h_y:0.0000     dir_h_z:0.0000     \\n\"+ \\\n",
    "    \"dir_v_x:0.0000     dir_v_y:1.0000     dir_v_z:0.0000     \\n\"+ \\\n",
    "    \"\\x0c\"\n",
    "\n",
    "    headerb = header.encode()\n",
    "    file.write(headerb)\n",
    "    file.write(imfmscbytes)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def writetofolder(output_filename):\n",
    "    '''\n",
    "    This function copies a target range of original DICOM images to a specified directory and renames them accordingly\n",
    "    '''\n",
    "    drive = r'D:\\OAI_Costa\\Tags_need'  #***change to directory you want images and tags saved to\n",
    "    root2 = os.path.join(drive, \"ToSegmentBW\", stid)\n",
    "    outpath2 = os.path.join(root2, \"OutputTags\")\n",
    "    try:\n",
    "        os.makedirs(outpath2)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    \n",
    "    origdcm_fn = output_filename\n",
    "    shutsrc = os.path.join(origdcm_fn)\n",
    "    serdesc = \"Exp_\"+stid\n",
    "    shutdst = os.path.join(outpath2, serdesc+\"_org\"+str(slc)+'.dcm')\n",
    "    shutil.copy(shutsrc, shutdst)\n",
    "        \n",
    "    return drive, root2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import corrected tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import logging\n",
    "import re\n",
    "import vtk\n",
    "import vtk.util.numpy_support as VN\n",
    "\n",
    "\n",
    "def tagtoarray(path):\n",
    "    '''\n",
    "    This function reads tag files from a specified directory, extracts metadata, and converts the voxel data into a NumPy array\n",
    "    '''\n",
    "    i = 0\n",
    "    count=0\n",
    "    imagetag= []\n",
    "    tagarray0 = []\n",
    "    tagsln0 = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.find('tag') > 0:\n",
    "            filename=os.path.join(path, file)\n",
    "\n",
    "            # get slice #\n",
    "            slpos = file.find(\".dcm.tag\")\n",
    "            if slpos > 1 and file[slpos-1].isdigit():\n",
    "                # Collect all consecutive digits preceding \".dcm.tag\"\n",
    "                digit_str = \"\"\n",
    "                index = slpos - 1\n",
    "\n",
    "                while index >= 0 and file[index].isdigit():\n",
    "                    digit_str = file[index] + digit_str\n",
    "                    index -= 1\n",
    "\n",
    "                slicenum = int(digit_str.replace(\"_\", \"\"))\n",
    "                tagsln0.append(slicenum)\n",
    "            \n",
    "            endOfHeaderChar = '\\x0c'\n",
    "\n",
    "            with open(filename) as f:\n",
    "                text = f.read(1000)  \n",
    "\n",
    "                if not endOfHeaderChar in text:\n",
    "                # end of header character is not found, it is not a valid tag file\n",
    "                   print(\"This is an invalid tag file.\")\n",
    "                else:\n",
    "                    header = text.split(endOfHeaderChar)[0]\n",
    "                    fields = re.split('[\\n\\t\\r ]+', header)\n",
    "\n",
    "                    dims = [0, 0, 0]\n",
    "                    origin = [0.0, 0.0, 0.0]\n",
    "                    spacing = [1.0, 1.0, 1.0]\n",
    "                    axisX = [1.0, 0.0, 0.0]\n",
    "                    axisY = [0.0, 1.0, 0.0]\n",
    "\n",
    "                    for field in fields:\n",
    "                      if not field:\n",
    "                        continue\n",
    "                      name, value = field.split(':')\n",
    "                      if name == 'x':\n",
    "                        dims[0] = int(value)\n",
    "                      elif name == 'y':\n",
    "                        dims[1] = int(value)\n",
    "                      elif name == 'z':\n",
    "                        dims[2] = int(value)\n",
    "                      elif name == 'org_x':\n",
    "                        origin[0] = float(value)\n",
    "                      elif name == 'org_y':\n",
    "                        origin[1] = float(value)\n",
    "                      elif name == 'org_z':\n",
    "                        origin[2] = float(value)\n",
    "                      elif name == 'inc_x':\n",
    "                        spacing[0] = float(value)\n",
    "                      elif name == 'inc_y':\n",
    "                        spacing[1] = float(value)\n",
    "                      elif name == 'epais':\n",
    "                        spacing[2] = float(value)\n",
    "                      elif name == 'dir_h_x':\n",
    "                        axisX[0] = float(value)\n",
    "                      elif name == 'dir_h_y':\n",
    "                        axisX[1] = float(value)\n",
    "                      elif name == 'dir_h_z':\n",
    "                        axisX[2] = float(value)\n",
    "                      elif name == 'dir_v_x':\n",
    "                        axisY[0] = float(value)\n",
    "                      elif name == 'dir_v_y':\n",
    "                        axisY[1] = float(value)\n",
    "                      elif name == 'dir_v_z':\n",
    "                        axisY[2] = float(value)\n",
    "                      elif name == 'type':\n",
    "                        # type is BYTE in tag files\n",
    "                        if value != 'BYTE':\n",
    "                          logging.warning('Voxel type in tag file is expected to be BYTE')\n",
    "                      elif name == 'uid':\n",
    "                        pass\n",
    "                      elif name == 'chksum':\n",
    "                        pass\n",
    "\n",
    "                    headerInfo = {\n",
    "                        'dims': dims,\n",
    "                        'origin': origin,\n",
    "                        'spacing': spacing,\n",
    "                        'axisX': axisX,\n",
    "                        'axisY': axisY,\n",
    "                        'headerSize': len(header)+1\n",
    "                        }\n",
    "\n",
    "\n",
    "                filePath=filename\n",
    "\n",
    "                scalarType = vtk.VTK_CHAR\n",
    "                numberOfComponents = 1\n",
    "                sliceSize = headerInfo['dims'][0] * headerInfo['dims'][1] * vtk.vtkDataArray.GetDataTypeSize(scalarType) * numberOfComponents\n",
    "                headerSize = headerInfo['headerSize']\n",
    "                totalFilesize = os.path.getsize(filePath)\n",
    "                voxelDataSize = totalFilesize - headerSize\n",
    "                maxNumberOfSlices = int(voxelDataSize/sliceSize)\n",
    "                if headerInfo['dims'][2] > maxNumberOfSlices:\n",
    "                    logging.error(f\"Tag file is expected to contain {headerInfo['dims'][2]} slices but it has only {maxNumberOfSlices}\")\n",
    "\n",
    "                reader = vtk.vtkImageReader2()\n",
    "                reader.SetFileName(filePath)\n",
    "                reader.SetFileDimensionality(3)\n",
    "                reader.SetDataExtent(0, headerInfo['dims'][0]-1, 0, headerInfo['dims'][1]-1, 0, headerInfo['dims'][2]-1)\n",
    "      \n",
    "                reader.SetDataScalarType(scalarType)\n",
    "                reader.SetNumberOfScalarComponents(numberOfComponents)\n",
    "                reader.SetHeaderSize(headerSize)\n",
    "                reader.SetFileLowerLeft(True) # to match input from NRRD reader\n",
    "                reader.Update()\n",
    "\n",
    "\n",
    "\n",
    "                imageout = reader.GetOutput()\n",
    "                rows, cols, sl = imageout.GetDimensions()\n",
    "\n",
    "                sc = imageout.GetPointData().GetScalars()\n",
    "                a = VN.vtk_to_numpy(sc)\n",
    "                a = a.reshape(sl,cols,rows)\n",
    "\n",
    "                imagetag.append([])\n",
    "\n",
    "                imagetag[count] = a[0]\n",
    "\n",
    "\n",
    "                \n",
    "                count+=1\n",
    "\n",
    "                \n",
    "    return imagetag, tagsln0, axisX, axisY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Running ITSA with corrected tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOG(filepath):\n",
    "    '''\n",
    "    This function reads a DICOM file from the specified filepath and returns the pixel data as a NumPy array\n",
    "    '''\n",
    "    dicom_data = pydicom.dcmread(filepath, force=True)\n",
    "    # Extract the pixel data as a NumPy array\n",
    "    pixel_array = dicom_data.pixel_array\n",
    "    return pixel_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 25px;\"> Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc2(F1_mask,F1_im,F2_mask,F2_im,BF_mask,BF_im,roi_mask,roi_im):\n",
    "    '''\n",
    "    This function calculates various metrics related to fat and muscle areas and volumes within specified regions of interest (ROIs). \n",
    "    It computes areas, volumes, percentages, and correction factors based on provided masks and intensity images, returning a comprehensive DataFrame containing the calculated metrics for each slice of the image data\n",
    "    '''\n",
    "    ROI_MuscFatAreaPix_L=[]\n",
    "    ROI_MuscFatAreaMM_L=[]\n",
    "    ROI_MuscFatVolMM_L=[]\n",
    "    F1_AreaPix_slice=[]\n",
    "    F1_AreaMM_slice=[]\n",
    "    Musc1AreaPix_slice=[]\n",
    "    Musc1AreaMM_slice=[]\n",
    "    F1_Perc_slice=[]\n",
    "    F1_VolMM_slice=[]\n",
    "    Musc1VolMM_slice=[]\n",
    "    F2_AreaPix_slice=[]\n",
    "    F2_AreaMM_slice=[]\n",
    "    Musc2AreaPix_slice=[]\n",
    "    Musc2AreaMM_slice=[]\n",
    "    F2Perc_slice=[]\n",
    "\n",
    "    F2VolMM_slice=[]\n",
    "    F2_MuscVolMMc=[]\n",
    "    Musc2VolMM_slice=[]\n",
    "    FatSegI_F1_slice=[]\n",
    "    FatSegI_F2_slice=[]\n",
    "    cfactor_slice=[]\n",
    "    FatVolCombined_slice=[]\n",
    "    F2_VolMM_c_slice=[]\n",
    "    FatVolCombined_C_slice=[] \n",
    "    F2_Perc_c_slice=[]\n",
    "    FatPercCombined_C_slice=[]\n",
    "    \n",
    "    BFAreaPix_slice=[]\n",
    "    BF_AreaMM_slice=[]\n",
    "    Musc3AreaPix_slice=[]\n",
    "    Musc3AreaMM_slice=[]\n",
    "    BF_Perc_NOTc_slice=[]\n",
    "    BF_VolMM_slice=[]\n",
    "    Musc3VolMM_slice=[]\n",
    "    Musc3VolMM_slice_c=[]\n",
    "  \n",
    "    FatVolCombined_C_all=[]\n",
    "    MuscVolCombined_all=[]\n",
    "    \n",
    "    FatPercAvgCombined_all=[] \n",
    "\n",
    "    for i in range(j):\n",
    "        ROI_MuscFatAreaPix_L.append([])\n",
    "        ROI_MuscFatAreaMM_L.append([])\n",
    "        ROI_MuscFatVolMM_L.append([])\n",
    "        F1_AreaPix_slice.append([])\n",
    "        F1_AreaMM_slice.append([])\n",
    "        Musc1AreaPix_slice.append([])\n",
    "        Musc1AreaMM_slice.append([])\n",
    "        F1_Perc_slice.append([])\n",
    "        F1_VolMM_slice.append([])\n",
    "        Musc1VolMM_slice.append([])\n",
    "        F2_AreaPix_slice.append([])\n",
    "        F2_AreaMM_slice.append([])\n",
    "        Musc2AreaPix_slice.append([])\n",
    "        Musc2AreaMM_slice.append([])\n",
    "        F2Perc_slice.append([])\n",
    "        FatPercCombined_C_slice.append([]) \n",
    "\n",
    "        F2VolMM_slice.append([])\n",
    "        F2_MuscVolMMc.append([])\n",
    "        Musc2VolMM_slice.append([])\n",
    "        FatSegI_F1_slice.append([])\n",
    "        FatSegI_F2_slice.append([])\n",
    "        cfactor_slice.append([])\n",
    "        FatVolCombined_slice.append([])\n",
    "        F2_VolMM_c_slice.append([])\n",
    "        FatVolCombined_C_slice.append([])\n",
    "        F2_Perc_c_slice.append([])\n",
    "\n",
    "        BFAreaPix_slice.append([])\n",
    "        BF_AreaMM_slice.append([])\n",
    "        Musc3AreaPix_slice.append([])\n",
    "        Musc3AreaMM_slice.append([])\n",
    "        BF_Perc_NOTc_slice.append([])\n",
    "        BF_VolMM_slice.append([])\n",
    "        Musc3VolMM_slice.append([])\n",
    "        Musc3VolMM_slice_c.append([])\n",
    "    \n",
    "        FatVolCombined_C_all.append([]) \n",
    "        MuscVolCombined_all.append([])\n",
    "        \n",
    "        FatPercAvgCombined_all.append([])\n",
    "    #MUSCLE + FAT AREA\n",
    "        ROI_MuscFatAreaPix=np.sum(roi_mask[i]>0)   \n",
    "        ROI_MuscFatAreaMM=ROI_MuscFatAreaPix*im_spacing[0]*im_spacing[1] \n",
    "        ROI_MuscFatVolMM=ROI_MuscFatAreaMM*im_spacing[2]\n",
    "        \n",
    "    #THRESHOLD 1 FAT\n",
    "        musc_no_F1=(roi_mask[i]-F1_mask[i])*roi_im[i] \n",
    "\n",
    "    \n",
    "        #FAT AREA\n",
    "        F1_AreaPix=np.sum(F1_mask[i]>0) \n",
    "        F1_AreaMM=F1_AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #MUSCLE AREA\n",
    "        Musc1AreaPix=np.sum(musc_no_F1>0)\n",
    "        Musc1AreaMM=Musc1AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #FAT PERCENTAGE\n",
    "        F1_Perc=F1_AreaPix*100/ROI_MuscFatAreaPix \n",
    "        #VOLUME OF EACH SLICE\n",
    "        F1_VolMM=F1_AreaMM*im_spacing[2] #multiply by z -slice thickness\n",
    "        Mus1cVolMM=Musc1AreaMM*im_spacing[2]\n",
    "\n",
    "    #THRESHOLD 2 FAT\n",
    "        #NOT including threshold 1 fat----------------------------------------------\n",
    "        musc_no_F2=(roi_mask[i]-F2_mask[i])*roi_im[i]  \n",
    "\n",
    "        \n",
    "        #FAT AREA\n",
    "        F2_AreaPix=np.sum(F2_mask[i] >0)\n",
    "        F2_AreaMM=F2_AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #MUSCLE AREA\n",
    "        Musc2AreaPix=np.sum(musc_no_F2>0)\n",
    "        Musc2AreaMM=Musc2AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        #FAT PERCENTAGE\n",
    "        F2Perc=F2_AreaPix*100/ROI_MuscFatAreaPix \n",
    "        #VOLUME OF EACH SLICE\n",
    "        F2VolMM=F2_AreaMM*im_spacing[2]\n",
    "        Musc2VolMM=Musc2AreaMM*im_spacing[2]\n",
    "        \n",
    "    #FINAL FAT using Threshold 2 ----------------------------------------------------\n",
    "        musc_no_BF=(roi_mask[i]-BF_mask[i])*roi_im[i]\n",
    "\n",
    "        \n",
    "        #FAT AREA -F2 here NOT CORRECTED \n",
    "        BFAreaPix=np.sum(BF_mask[i]>0) \n",
    "        BF_AreaMM=BFAreaPix*im_spacing[0]*im_spacing[1]\n",
    "        \n",
    "        #MUSCLE AREA\n",
    "        Musc3AreaPix=np.sum(musc_no_BF>0)\n",
    "        Musc3AreaMM=Musc3AreaPix*im_spacing[0]*im_spacing[1]\n",
    "        \n",
    "        #FAT PERCENTAGE -F2 here NOT CORRECTED \n",
    "        BF_Perc_NOTc=BFAreaPix*100/ROI_MuscFatAreaPix \n",
    "        \n",
    "        #VOLUME OF EACH SLICE\n",
    "        BF_VolMM=BF_AreaMM*im_spacing[2] \n",
    "        Musc3VolMM=Musc3AreaMM*im_spacing[2]\n",
    "        \n",
    "      \n",
    "    #FAT CORRECTION - break\n",
    "        if np.sum(F2_im[i] >0)==0: #if there is NO R2 refined fat just take th1 loop fat\n",
    "            print(f\"{ID} Slice {i+1} no R2 refined\")\n",
    "            #keep vars for final table\n",
    "            F1_im_masked=np.ma.masked_where(F1_im[i]==0,F1_im[i]) \n",
    "            F2_im_masked=np.ma.masked_where(F2_im[i] ==0,F2_im[i]) \n",
    "            FatSegI_F1=np.mean(F1_im_masked) \n",
    "            FatSegI_F2=np.mean(F2_im_masked)\n",
    "            cfactor=9999\n",
    "            FatVolCombined=9999\n",
    "            F2_VolMM_c=9999\n",
    "            F2_Perc_c=9999\n",
    "            \n",
    "            #take F1 values only\n",
    "            FatVolCombined_C=F1_VolMM \n",
    "            FatPercCombined_C=F1_Perc\n",
    "            \n",
    "            \n",
    "        else:\n",
    "\n",
    "            F1_im_masked=np.ma.masked_where(F1_im[i]==0,F1_im[i]) \n",
    "            F2_im_masked=np.ma.masked_where(F2_im[i] ==0,F2_im[i])\n",
    "            FatSegI_F1=np.mean(F1_im_masked) \n",
    "            FatSegI_F2=np.mean(F2_im_masked)\n",
    "            cfactor=(FatSegI_F2/FatSegI_F1) #fat correction factor\n",
    "    \n",
    "        \n",
    "            FatVolCombined=F1_VolMM+F2VolMM #final volume not corrected\n",
    "            F2_VolMM_c=F2VolMM*cfactor \n",
    "            FatVolCombined_C=F1_VolMM+F2_VolMM_c #final volume corrected\n",
    "            \n",
    "            F2_Perc_c=F2Perc*cfactor \n",
    "            FatPercCombined_C=F1_Perc+F2_Perc_c \n",
    "            \n",
    "        ROI_MuscFatAreaPix_L[i]=ROI_MuscFatAreaPix\n",
    "        ROI_MuscFatAreaMM_L[i]=ROI_MuscFatAreaMM\n",
    "        ROI_MuscFatVolMM_L[i]=ROI_MuscFatVolMM \n",
    "        F1_AreaPix_slice[i]=F1_AreaPix\n",
    "        F1_AreaMM_slice[i]=F1_AreaMM\n",
    "        Musc1AreaPix_slice[i]= Musc1AreaPix\n",
    "        Musc1AreaMM_slice[i]=Musc1AreaMM\n",
    "        F1_Perc_slice[i]=F1_Perc \n",
    "        F1_VolMM_slice[i]=F1_VolMM \n",
    "        Musc1VolMM_slice[i]=Mus1cVolMM\n",
    "        F2_AreaPix_slice[i]=F2_AreaPix\n",
    "        F2_AreaMM_slice[i]=F2_AreaMM\n",
    "        Musc2AreaPix_slice[i]=Musc2AreaPix\n",
    "        Musc2AreaMM_slice[i]=Musc2AreaMM\n",
    "        F2Perc_slice[i]=F2Perc\n",
    "        FatPercCombined_C_slice[i]=FatPercCombined_C \n",
    "        \n",
    "        F2VolMM_slice[i]=F2VolMM\n",
    "        F2_MuscVolMMc[i] = F2VolMM * (1-cfactor) \n",
    "        Musc2VolMM_slice[i]=Musc2VolMM\n",
    "        FatSegI_F1_slice[i]=FatSegI_F1\n",
    "        FatSegI_F2_slice[i]=FatSegI_F2\n",
    "        cfactor_slice[i]=cfactor\n",
    "        FatVolCombined_slice[i]=FatVolCombined\n",
    "        F2_VolMM_c_slice[i]=F2_VolMM_c\n",
    "        FatVolCombined_C_slice[i]=FatVolCombined_C \n",
    "        F2_Perc_c_slice[i]=F2_Perc_c\n",
    "        FatPercCombined_C_slice[i]=FatPercCombined_C\n",
    "\n",
    "        BFAreaPix_slice[i]=BFAreaPix\n",
    "        BF_AreaMM_slice[i]=BF_AreaMM\n",
    "        Musc3AreaPix_slice[i]=Musc3AreaPix\n",
    "        Musc3AreaMM_slice[i]=Musc3AreaMM\n",
    "        BF_Perc_NOTc_slice[i]=BF_Perc_NOTc\n",
    "        BF_VolMM_slice[i]=BF_VolMM\n",
    "        Musc3VolMM_slice[i]=Musc3VolMM #not corrected  \n",
    "        Musc3VolMM_slice_c[i]= Mus1cVolMM + (F2VolMM * (1-cfactor)) \n",
    "        \n",
    "        FatVolCombined_C_all[i]=sum(FatVolCombined_C_slice) \n",
    "        MuscVolCombined_all[i]=sum(Musc3VolMM_slice)\n",
    "        \n",
    "        FatPercAvgCombined_all[i]=mean(FatPercCombined_C_slice)\n",
    "        \n",
    "        \n",
    "    slice_num=[]\n",
    "    slice_num=list(range(1,j+1))  \n",
    "    \n",
    "    slice_num2=(list(reversed(slice_num)))  \n",
    "\n",
    "    OG_slice_num=slice_num\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #table for ALL data\n",
    "    data = {'ID': ID,'Slice': slice_num,'ROI_MuscFatAreaPix':ROI_MuscFatAreaPix_L, 'ROI_MuscFatAreaMM':ROI_MuscFatAreaMM_L, 'ROI_MuscFatVolMM': ROI_MuscFatVolMM_L,\n",
    "            'F1_AreaPix':F1_AreaPix_slice,'F1_AreaMM':F1_AreaMM_slice,'F1_MuscAreaPix':Musc1AreaPix_slice,'F1_MuscAreaMM':Musc1AreaMM_slice,\n",
    "            'F1_Perc':F1_Perc_slice,'F1_VolMM':F1_VolMM_slice,'F1_MuscVolMM':Musc1VolMM_slice, \n",
    "            'F2_AreaPix':F2_AreaPix_slice,'F2_AreaMM':F2_AreaMM_slice,'Musc_noF2_AreaPix':Musc2AreaPix_slice,'musc_no_F2_AreaMM':Musc2AreaMM_slice,\n",
    "            'F2_Perc_NOTc':F2Perc_slice,'F2_VolMM_NOTc':F2VolMM_slice,'F2_MuscVolMM':Musc2VolMM_slice,\n",
    "            'F1_Intensity':FatSegI_F1_slice,'F2_Intensity':FatSegI_F2_slice,\n",
    "            'F2_cfactor':cfactor_slice,'BF_FatVol_NOTc':FatVolCombined_slice,'F2_VolMM_c':F2_VolMM_c_slice,'F2_MuscVolMMc':F2_MuscVolMMc,\n",
    "            'BF_FatVol_c':FatVolCombined_C_slice,\n",
    "            'F2_Perc_c':F2_Perc_c_slice,'BF_Perc_c':FatPercCombined_C_slice,\n",
    "          \n",
    "            'BF_AreaPix_NOTc':BFAreaPix_slice,'BF_AreaMM^2_NOTc':BF_AreaMM_slice,'Musc_noBF_AreaPix_NOTc':Musc3AreaPix_slice,\n",
    "            'musc_no_BF_AreaMM_NOTc':Musc3AreaMM_slice,'BF_Perc_NOTc':BF_Perc_NOTc_slice,\n",
    "            'BF_VolMM_NOTc':BF_VolMM_slice,'Musc_noBF_VolMM_NOTc':Musc3VolMM_slice,\n",
    "            'TOTAL_FatVol_c':FatVolCombined_C_all,'TOTAL_MuscVol':MuscVolCombined_all,'TOTAL_MuscVol_c':Musc3VolMM_slice_c}  \n",
    "\n",
    "    data_table = pd.DataFrame(data, columns = ['ID','Slice','ROI_MuscFatAreaPix','ROI_MuscFatAreaMM', 'ROI_MuscFatVolMM',\n",
    "                                                    'F1_AreaPix','F1_AreaMM','F1_MuscAreaPix','F1_MuscAreaMM','F1_Perc','F1_VolMM','F1_MuscVolMM', \n",
    "                                                    'F2_AreaPix','F2_AreaMM','Musc_noF2_AreaPix','musc_no_F2_AreaMM','F2_Perc_NOTc','F2_VolMM_NOTc',\n",
    "                                                    'F1_Intensity','F2_Intensity','F2_cfactor','BF_FatVol_NOTc','F2_VolMM_c','F2_MuscVolMMc','BF_FatVol_c','F2_Perc_c','BF_Perc_c',\n",
    "                                                    \n",
    "                                                    'BF_AreaPix_NOTc','BF_AreaMM^2_NOTc','Musc_noBF_AreaPix_NOTc','musc_no_BF_AreaMM_NOTc','BF_Perc_NOTc','BF_VolMM_NOTc','Musc_noBF_VolMM_NOTc','TOTAL_FatVol_c','TOTAL_MuscVol_c'])\n",
    "\n",
    "\n",
    "    print(f'{ID} total fatvol= {sum(FatVolCombined_C_slice)}\\n')\n",
    "\n",
    "    \n",
    "    Total_FatVol=sum(FatVolCombined_C_slice) \n",
    "    Total_MuscVol=sum(Musc3VolMM_slice)\n",
    "    TotalMuscFatVol=Total_FatVol+Total_MuscVol #corrected  \n",
    "    Total_FatPerc=Total_FatVol/TotalMuscFatVol\n",
    "\n",
    "    \n",
    "    return data_table  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_sheet(to_append,excel_path,sheetname):\n",
    "    '''\n",
    "    This function reads a specific sheetname from an Excel file and concatenates the contents of this sheet with \"to_append\", ensuring that the index is ignored during concatenation to maintain a continuous index.\n",
    "    '''\n",
    "    df_excel = pd.read_excel((excel_path),sheet_name=sheetname) #read specific sheet name\n",
    "    result = pd.concat([df_excel,to_append], ignore_index=True) #concatenate sheet contents with new df\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
